{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"11_ukiyoe_revise.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1wSz85Yc6onwSyKDLjZz6byKUz1tQA-08","authorship_tag":"ABX9TyNdZZGdo6SdIuX5uVP6h5aj"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"_PJRTP-2iAZl","colab_type":"text"},"source":["### ukiyoe2novelモデル作成、保存"]},{"cell_type":"code","metadata":{"id":"edwMjQLSh-9C","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":350},"executionInfo":{"status":"ok","timestamp":1597540929736,"user_tz":-540,"elapsed":2448,"user":{"displayName":"Noboru Koike","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggp8njUb4jc54JrzfM5cQBkfiCdlz6nY17y8-1szg=s64","userId":"05156582812995850159"}},"outputId":"33b9e0af-b548-4459-8d70-587d5678906e"},"source":["!nvidia-smi"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Sun Aug 16 01:22:08 2020       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 450.57       Driver Version: 418.67       CUDA Version: 10.1     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   43C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n","|                               |                      |                 ERR! |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"m8Efiyf6iULe","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597540936446,"user_tz":-540,"elapsed":2544,"user":{"displayName":"Noboru Koike","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggp8njUb4jc54JrzfM5cQBkfiCdlz6nY17y8-1szg=s64","userId":"05156582812995850159"}}},"source":["from tensorflow_addons.layers import InstanceNormalization\n","from tensorflow.keras.layers import Input, Dropout, Concatenate\n","from tensorflow.keras.layers import LeakyReLU\n","from tensorflow.keras.layers import UpSampling2D, Conv2D\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.optimizers import Adam"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"K1TfyLsLiWrB","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597540936448,"user_tz":-540,"elapsed":1636,"user":{"displayName":"Noboru Koike","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggp8njUb4jc54JrzfM5cQBkfiCdlz6nY17y8-1szg=s64","userId":"05156582812995850159"}}},"source":["import matplotlib.pyplot as plt\n","import numpy as np\n","import pandas as pd\n","import datetime\n","import os"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"SajYHE7PiYKw","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597540936818,"user_tz":-540,"elapsed":1105,"user":{"displayName":"Noboru Koike","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggp8njUb4jc54JrzfM5cQBkfiCdlz6nY17y8-1szg=s64","userId":"05156582812995850159"}}},"source":["from glob import glob\n","import cv2\n","from matplotlib.pyplot import imread"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"Iu-b1TsDiZdu","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597540938240,"user_tz":-540,"elapsed":704,"user":{"displayName":"Noboru Koike","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggp8njUb4jc54JrzfM5cQBkfiCdlz6nY17y8-1szg=s64","userId":"05156582812995850159"}}},"source":["DATA_DIR_PATH = '/content/drive/My Drive/kikagaku/novelgan/data'\n","\n","OUTPUT_DIR_PATH = os.path.join(DATA_DIR_PATH, '11_out')"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"CoJ8-rDQi2ma","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597540940496,"user_tz":-540,"elapsed":1371,"user":{"displayName":"Noboru Koike","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggp8njUb4jc54JrzfM5cQBkfiCdlz6nY17y8-1szg=s64","userId":"05156582812995850159"}}},"source":["#os.makedirs(os.path.join(DATA_DIR_PATH, 'datasets'), exist_ok=True)\n","\n","os.makedirs(os.path.join(OUTPUT_DIR_PATH, 'images'), exist_ok=True)\n","os.makedirs(os.path.join(OUTPUT_DIR_PATH, 'saved_models'), exist_ok=True)"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"5dUQ35hMi46B","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597540940864,"user_tz":-540,"elapsed":762,"user":{"displayName":"Noboru Koike","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggp8njUb4jc54JrzfM5cQBkfiCdlz6nY17y8-1szg=s64","userId":"05156582812995850159"}}},"source":["class DataLoader():\n","    def __init__(self, dataset_name, img_res=(256, 256)):\n","        self.dataset_name = dataset_name\n","        self.img_res = img_res\n","        self.datasets_path = os.path.join(DATA_DIR_PATH, 'datasets')\n","\n","    def load_data(self, domain, batch_size=1, is_testing=False):\n","        data_type = \"train%s\" % domain if not is_testing else \"test%s\" % domain\n","        #path = glob('./datasets/%s/%s/*' % (self.dataset_name, data_type))\n","        path = glob(os.path.join(self.datasets_path, self.dataset_name, data_type, '*'))\n","\n","        batch_images = np.random.choice(path, size=batch_size)\n","\n","        imgs = []\n","        for img_path in batch_images:\n","            img = self.imread(img_path)\n","            if not is_testing:\n","                #img = scipy.misc.imresize(img, self.img_res)\n","                img = cv2.resize(img, self.img_res)\n","\n","                if np.random.random() > 0.5:\n","                    img = np.fliplr(img)\n","            else:\n","                #img = scipy.misc.imresize(img, self.img_res)\n","                img = cv2.resize(img, self.img_res)\n","            imgs.append(img)\n","\n","        imgs = np.array(imgs)/127.5 - 1.\n","\n","        return imgs\n","\n","    def load_batch(self, batch_size=1, is_testing=False):\n","        data_type = \"train\" if not is_testing else \"val\"\n","        #path_A = glob('./datasets/%s/%sA/*' % (self.dataset_name, data_type))\n","        #path_B = glob('./datasets/%s/%sB/*' % (self.dataset_name, data_type))\n","        path_A = glob(os.path.join(self.datasets_path, self.dataset_name, '{}A'.format(data_type), '*'))\n","        path_B = glob(os.path.join(self.datasets_path, self.dataset_name, '{}B'.format(data_type), '*'))\n","\n","        self.n_batches = int(min(len(path_A), len(path_B)) / batch_size)\n","        total_samples = self.n_batches * batch_size\n","\n","        # Sample n_batches * batch_size from each path list so that model sees all\n","        # samples from both domains\n","        path_A = np.random.choice(path_A, total_samples, replace=False)\n","        path_B = np.random.choice(path_B, total_samples, replace=False)\n","\n","        #for i in range(self.n_batches-1):\n","        for i in range(self.n_batches):\n","            batch_A = path_A[i*batch_size:(i+1)*batch_size]\n","            batch_B = path_B[i*batch_size:(i+1)*batch_size]\n","            imgs_A, imgs_B = [], []\n","\n","            for img_A, img_B in zip(batch_A, batch_B):\n","                img_A = self.imread(img_A)\n","                img_B = self.imread(img_B)\n","\n","                #img_A = scipy.misc.imresize(img_A, self.img_res)\n","                img_A = cv2.resize(img_A, self.img_res)\n","                #img_B = scipy.misc.imresize(img_B, self.img_res)\n","                img_B = cv2.resize(img_B, self.img_res)\n","\n","                if not is_testing and np.random.random() > 0.5:\n","                    img_A = np.fliplr(img_A)\n","                    img_B = np.fliplr(img_B)\n","\n","                imgs_A.append(img_A)\n","                imgs_B.append(img_B)\n","\n","            imgs_A = np.array(imgs_A)/127.5 - 1.\n","            imgs_B = np.array(imgs_B)/127.5 - 1.\n","\n","            yield imgs_A, imgs_B\n","\n","    def load_img(self, path):\n","        img = self.imread(path)\n","        #img = scipy.misc.imresize(img, self.img_res)\n","        img = cv2.resize(img, self.img_res)\n","        img = img/127.5 - 1.\n","        return img[np.newaxis, :, :, :]\n","\n","    def imread(self, path):\n","        #return scipy.misc.imread(path, mode='RGB').astype(np.float)\n","        return imread(path).astype(np.float)"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"McSlIOeQi7SP","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597540941599,"user_tz":-540,"elapsed":503,"user":{"displayName":"Noboru Koike","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggp8njUb4jc54JrzfM5cQBkfiCdlz6nY17y8-1szg=s64","userId":"05156582812995850159"}}},"source":["IMG_ROWS = 256\n","IMG_COLS = 256\n","\n","data_loader = DataLoader('ukiyoe2novel', img_res=(IMG_ROWS, IMG_COLS))"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"mILxUaffjb7S","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597540944189,"user_tz":-540,"elapsed":1626,"user":{"displayName":"Noboru Koike","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggp8njUb4jc54JrzfM5cQBkfiCdlz6nY17y8-1szg=s64","userId":"05156582812995850159"}}},"source":["class CycleGAN:\n","    def __init__(self):\n","        self.history = pd.DataFrame({}, columns=[\n","            'epoch', 'epochs', 'batch_idx', 'batch_num', 'd_loss', 'acc', 'g_loss',\n","            'adv', 'recon', 'id', 'elapsed_time'])\n","\n","        self.img_save_dir = os.path.join(OUTPUT_DIR_PATH, 'images')\n","        self.model_save_dir = os.path.join(OUTPUT_DIR_PATH, 'saved_models')\n","        self.combined_name = 'combined_model'\n","        self.g_AB_name = 'g_AB_model'\n","        self.g_BA_name = 'g_BA_model'\n","\n","        self.train_cnt = 0\n","\n","        # Input shape\n","        self.img_rows = IMG_ROWS\n","        self.img_cols = IMG_COLS\n","        self.channels = 3\n","        self.img_shape = (self.img_rows, self.img_cols, self.channels)\n","\n","        self.d_A = None\n","        self.d_B = None\n","        self.g_AB = None\n","        self.g_BA = None\n","        self.combined = None\n","\n","    def init(self, data_loader=None):\n","        # Configure data loader\n","        #self.dataset_name = 'apple2orange'\n","        #self.data_loader = DataLoader(dataset_name=self.dataset_name,\n","        #                              img_res=(self.img_rows, self.img_cols))\n","        if data_loader:\n","            self.data_loader = data_loader\n","            self.dataset_name = self.data_loader.dataset_name \n","\n","        # Calculate output shape of D (PatchGAN)\n","        patch = int(self.img_rows / 2**4)\n","        self.disc_patch = (patch, patch, 1)\n","\n","        # Number of filters in the first layer of G and D\n","        #self.gf = 32 # U-Net, 128\n","        self.gf = 64\n","        self.df = 64\n","\n","        # Loss weights\n","        self.lambda_cycle = 10.0                    # Cycle-consistency loss\n","        self.lambda_id = 0.1 * self.lambda_cycle    # Identity loss\n","\n","        optimizer = Adam(0.0002, 0.5)\n","\n","        # Build and compile the discriminators\n","        self.d_A = self.build_discriminator()\n","        self.d_B = self.build_discriminator()\n","        self.d_A.compile(loss='mse',\n","                         optimizer=optimizer,\n","                         metrics=['accuracy'])\n","        self.d_B.compile(loss='mse',\n","                         optimizer=optimizer,\n","                         metrics=['accuracy'])\n","\n","        # Build the generators\n","        self.g_AB = self.build_generator()\n","        self.g_BA = self.build_generator()\n","\n","        # Input images from both domains\n","        img_A = Input(shape=self.img_shape)\n","        img_B = Input(shape=self.img_shape)\n","\n","        # Translate images to the other domain\n","        fake_B = self.g_AB(img_A)\n","        fake_A = self.g_BA(img_B)\n","\n","        # Translate images back to original domain\n","        reconstr_A = self.g_BA(fake_B)\n","        reconstr_B = self.g_AB(fake_A)\n","\n","        # Identity mapping of images\n","        img_A_id = self.g_BA(img_A)\n","        img_B_id = self.g_AB(img_B)\n","\n","        # For the combined model we will only train the generators\n","        self.d_A.trainable = False\n","        self.d_B.trainable = False\n","\n","        # Discriminators determines validity of translated images\n","        valid_A = self.d_A(fake_A)\n","        valid_B = self.d_B(fake_B)\n","\n","        # Combined model trains generators to fool discriminators\n","        self.combined = Model(inputs=[img_A, img_B],\n","                              outputs=[valid_A, valid_B,\n","                                       reconstr_A, reconstr_B,\n","                                       img_A_id, img_B_id ])\n","        self.combined.compile(loss=['mse', 'mse',\n","                                    'mae', 'mae',\n","                                    'mae', 'mae'],\n","                              loss_weights=[1, 1,\n","                                            self.lambda_cycle, self.lambda_cycle,\n","                                            self.lambda_id, self.lambda_id ],\n","                              optimizer=optimizer)\n","\n","    def build_generator(self):\n","        \"\"\"U-Net Generator\"\"\"\n","\n","        def conv2d(layer_input, filters, f_size=4):\n","            \"\"\"Layers used during downsampling\"\"\"\n","            d = Conv2D(filters, kernel_size=f_size, strides=2, padding='same')(layer_input)\n","            d = LeakyReLU(alpha=0.2)(d)\n","            d = InstanceNormalization()(d)\n","            return d\n","\n","        def deconv2d(layer_input, skip_input, filters, f_size=4, dropout_rate=0):\n","            \"\"\"Layers used during upsampling\"\"\"\n","            u = UpSampling2D(size=2)(layer_input)\n","            u = Conv2D(filters, kernel_size=f_size, strides=1, padding='same', activation='relu')(u)\n","            if dropout_rate:\n","                u = Dropout(dropout_rate)(u)\n","            u = InstanceNormalization()(u)\n","            u = Concatenate()([u, skip_input])\n","            return u\n","\n","        # Image input\n","        d0 = Input(shape=self.img_shape)\n","\n","        # U-Net, 12\n","        ## Downsampling\n","        #d1 = conv2d(d0, self.gf)\n","        #d2 = conv2d(d1, self.gf*2)\n","        #d3 = conv2d(d2, self.gf*4)\n","        #d4 = conv2d(d3, self.gf*8)\n","        #\n","        ## Upsampling\n","        #u1 = deconv2d(d4, d3, self.gf*4)\n","        #u2 = deconv2d(u1, d2, self.gf*2)\n","        #u3 = deconv2d(u2, d1, self.gf)\n","        #\n","        #u4 = UpSampling2D(size=2)(u3)\n","        #output_img = Conv2D(self.channels, kernel_size=4, strides=1, padding='same', activation='tanh')(u4)\n","\n","        # Downsampling\n","        d1 = conv2d(d0, self.gf)\n","        d2 = conv2d(d1, self.gf*2)\n","        d3 = conv2d(d2, self.gf*4)\n","        d4 = conv2d(d3, self.gf*8)\n","        d5 = conv2d(d4, self.gf*8)\n","        d6 = conv2d(d5, self.gf*8)\n","        d7 = conv2d(d6, self.gf*8)\n","\n","        # Upsampling\n","        u1 = deconv2d(d7, d6, self.gf*8)\n","        u2 = deconv2d(u1, d5, self.gf*8)\n","        u3 = deconv2d(u2, d4, self.gf*8)\n","        u4 = deconv2d(u3, d3, self.gf*4)\n","        u5 = deconv2d(u4, d2, self.gf*2)\n","        u6 = deconv2d(u5, d1, self.gf)\n","\n","        u7 = UpSampling2D(size=2)(u6)\n","        output_img = Conv2D(self.channels, kernel_size=4, strides=1, padding='same', activation='tanh')(u7)\n","\n","        return Model(d0, output_img)\n","\n","    def build_discriminator(self):\n","\n","        def d_layer(layer_input, filters, f_size=4, normalization=True):\n","            \"\"\"Discriminator layer\"\"\"\n","            d = Conv2D(filters, kernel_size=f_size, strides=2, padding='same')(layer_input)\n","            d = LeakyReLU(alpha=0.2)(d)\n","            if normalization:\n","                d = InstanceNormalization()(d)\n","            return d\n","\n","        img = Input(shape=self.img_shape)\n","\n","        d1 = d_layer(img, self.df, normalization=False)\n","        d2 = d_layer(d1, self.df*2)\n","        d3 = d_layer(d2, self.df*4)\n","        d4 = d_layer(d3, self.df*8)\n","\n","        validity = Conv2D(1, kernel_size=4, strides=1, padding='same')(d4)\n","\n","        return Model(img, validity)\n","\n","    def train(self, epochs, batch_size=1, sample_interval=-1, save_interval=-1):\n","        self.train_cnt += 1\n","\n","        print(datetime.datetime.now().isoformat(), 'Start', self.train_cnt)\n","\n","        start_time = datetime.datetime.now()\n","\n","        # Adversarial loss ground truths\n","        valid = np.ones((batch_size,) + self.disc_patch)\n","        fake = np.zeros((batch_size,) + self.disc_patch)\n","\n","        step_cnt = 1\n","\n","        #for epoch in range(epochs):\n","        for epoch in range(1, epochs+1):\n","            #for batch_i, (imgs_A, imgs_B) in enumerate(self.data_loader.load_batch(batch_size)):\n","            for batch_i, (imgs_A, imgs_B) in enumerate(self.data_loader.load_batch(batch_size), 1):\n","\n","                # Translate images to opposite domain\n","                fake_B = self.g_AB.predict(imgs_A)\n","                fake_A = self.g_BA.predict(imgs_B)\n","\n","                # Train the discriminators (original images = real / translated = Fake)\n","                dA_loss_real = self.d_A.train_on_batch(imgs_A, valid)\n","                dA_loss_fake = self.d_A.train_on_batch(fake_A, fake)\n","                dA_loss = 0.5 * np.add(dA_loss_real, dA_loss_fake)\n","\n","                dB_loss_real = self.d_B.train_on_batch(imgs_B, valid)\n","                dB_loss_fake = self.d_B.train_on_batch(fake_B, fake)\n","                dB_loss = 0.5 * np.add(dB_loss_real, dB_loss_fake)\n","\n","                # Total disciminator loss\n","                d_loss = 0.5 * np.add(dA_loss, dB_loss)\n","\n","                # Train the generators\n","                g_loss = self.combined.train_on_batch([imgs_A, imgs_B],\n","                                                      [valid, valid,\n","                                                       imgs_A, imgs_B,\n","                                                       imgs_A, imgs_B])\n","\n","                elapsed_time = datetime.datetime.now() - start_time\n","\n","                # Plot the progress\n","                # print(\"[Epoch %d/%d] [Batch %d/%d] [D loss: %f, acc: %3d%%] [G loss: %05f, adv: %05f, recon: %05f, id: %05f] time: %s \" % (\n","                #     epoch, epochs,\n","                #     batch_i, self.data_loader.n_batches,\n","                #     d_loss[0], 100*d_loss[1],\n","                #     g_loss[0],\n","                #     np.mean(g_loss[1:3]),\n","                #     np.mean(g_loss[3:5]),\n","                #     np.mean(g_loss[5:6]),\n","                #     elapsed_time))\n","                self.history = self.history.append({\n","                    'epoch': epoch,\n","                    'epochs': epochs,\n","                    'batch_idx': batch_i,\n","                    'batch_num': self.data_loader.n_batches,\n","                    'd_loss': d_loss[0],\n","                    'acc': d_loss[1],\n","                    'g_loss': g_loss[0],\n","                    'adv': np.mean(g_loss[1:3]),\n","                    'recon': np.mean(g_loss[3:5]),\n","                    'id': np.mean(g_loss[5:6]),\n","                    'elapsed_time': elapsed_time\n","                }, ignore_index=True)\n","\n","                # If at save interval => save generated image samples\n","                #if sample_interval > 0 and batch_i % sample_interval == 0:\n","                if sample_interval > 0 and step_cnt % sample_interval == 0:\n","                    print(\"[Epoch %d/%d] [Batch %d/%d] [D loss: %f, acc: %3d%%] [G loss: %05f, adv: %05f, recon: %05f, id: %05f] time: %s \" % (\n","                        epoch, epochs,\n","                        batch_i, self.data_loader.n_batches,\n","                        d_loss[0], 100*d_loss[1],\n","                        g_loss[0],\n","                        np.mean(g_loss[1:3]),\n","                        np.mean(g_loss[3:5]),\n","                        np.mean(g_loss[5:6]),\n","                        elapsed_time))\n","\n","                    self.sample_images(epoch, batch_i)\n","\n","                #if save_interval > 0 and batch_i != 1 and (batch_i % save_interval) == 0:\n","                if save_interval > 0 and step_cnt % save_interval == 0:\n","                    file_suffix = '{}_{}_{}'.format(self.train_cnt, epoch, batch_i)\n","                    self.save_model_weights(self.combined, self.combined_name, file_suffix)\n","\n","                step_cnt += 1\n","\n","        print(datetime.datetime.now().isoformat(), 'End')\n","\n","    def generate_image_A(self, img):\n","        return self.g_AB.predict(img)\n","\n","    def generate_image_B(self, img):\n","        return self.g_BA.predict(img)\n","\n","    def sample_images(self, epoch, batch_i):\n","        dir_path = os.path.join(self.img_save_dir, self.dataset_name)\n","\n","        #os.makedirs('images/%s' % self.dataset_name, exist_ok=True)\n","        os.makedirs(dir_path, exist_ok=True)\n","\n","        r, c = 2, 3\n","\n","        imgs_A = self.data_loader.load_data(domain=\"A\", batch_size=1, is_testing=True)\n","        imgs_B = self.data_loader.load_data(domain=\"B\", batch_size=1, is_testing=True)\n","\n","        # Demo (for GIF)\n","        #imgs_A = self.data_loader.load_img('datasets/apple2orange/testA/n07740461_1541.jpg')\n","        #imgs_B = self.data_loader.load_img('datasets/apple2orange/testB/n07749192_4241.jpg')\n","\n","        # Translate images to the other domain\n","        fake_B = self.g_AB.predict(imgs_A)\n","        fake_A = self.g_BA.predict(imgs_B)\n","\n","        # Translate back to original domain\n","        reconstr_A = self.g_BA.predict(fake_B)\n","        reconstr_B = self.g_AB.predict(fake_A)\n","\n","        gen_imgs = np.concatenate([imgs_A, fake_B, reconstr_A, imgs_B, fake_A, reconstr_B])\n","\n","        # Rescale images 0 - 1\n","        gen_imgs = 0.5 * gen_imgs + 0.5\n","\n","        titles = ['Original', 'Translated', 'Reconstructed']\n","        fig, axs = plt.subplots(r, c)\n","        cnt = 0\n","\n","        for i in range(r):\n","            for j in range(c):\n","                axs[i, j].imshow(gen_imgs[cnt])\n","                axs[i, j].set_title(titles[j])\n","                axs[i, j].axis('off')\n","                cnt += 1\n","\n","        #fig.savefig(\"images/%s/%d_%d.png\" % (self.dataset_name, epoch, batch_i))\n","        file_path = os.path.join(dir_path, '{}_{}_{}.png'.format(self.train_cnt, epoch, batch_i))\n","        fig.savefig(file_path)\n","\n","        plt.close()\n","\n","    def plot_hisotry(self, columns=[]):\n","        if len(columns) == 0:\n","            columns = ['d_loss', 'g_loss']\n","            #columns = ['d_loss', 'acc', 'g_loss', 'adv', 'recon', 'id',]\n","        self.history[columns].plot()\n","\n","    def save_models(self, file_suffix=None):\n","        self.save_model_weights(self.combined, self.combined_name, file_suffix)\n","        #self.save_model_weights(self.g_AB, self.g_AB_name, file_suffix)\n","        #self.save_model_weights(self.g_BA, self.g_BA_name, file_suffix)\n","\n","    def save_model_weights(self, model, model_name, file_suffix=None):\n","        file_path = os.path.join(self.model_save_dir, self._create_h5_file_name(model_name, file_suffix))\n","        model.save_weights(file_path)\n","\n","        print('Model weights saved.', model_name)\n","\n","    def load_models(self, file_suffix=None):\n","        self.load_model_weights(self.combined_name, file_suffix)\n","        self.load_model_weights(self.g_AB_name, file_suffix)\n","        self.load_model_weights(self.g_BA_name, file_suffix)\n","\n","    def load_model_weights(self, model_name, file_suffix=None):\n","        model = None\n","\n","        if model_name == self.combined_name:\n","            model = self.combined\n","        elif model_name == self.g_AB_name:\n","            model = self.g_AB\n","        elif model_name == self.g_BA_name:\n","            model = self.g_BA\n","        else:\n","            print('Unsupported.', model_name)\n","            return\n","\n","        if not model:\n","            print('Not initialized.', model_name)\n","            return\n","\n","        file_path = os.path.join(self.model_save_dir, self._create_h5_file_name(model_name, file_suffix))\n","\n","        if not os.path.exists(file_path):\n","            print('File Not found.', model_name)\n","            return\n","\n","        model.load_weights(file_path)\n","\n","        print('Model weights loaded.', model_name)\n","\n","    def _create_h5_file_name(self, model_name, suffix=None):\n","        if suffix:\n","            return '{}_{}.h5'.format(model_name, suffix)\n","        else:\n","            return '{}.h5'.format(model_name)"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"EeoABrtU3EJ3","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1597555636968,"user_tz":-540,"elapsed":14600642,"user":{"displayName":"Noboru Koike","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggp8njUb4jc54JrzfM5cQBkfiCdlz6nY17y8-1szg=s64","userId":"05156582812995850159"}},"outputId":"202fb679-3c93-45d7-be89-02945f8a4d6d"},"source":["gan = CycleGAN()\n","gan.init(data_loader=data_loader)\n","\n","# Image A Count: 560, BatchSize:8, 560/8=70\n","gan.train(epochs=100, batch_size=8, sample_interval=70, save_interval=70*5)\n","\n","gan.history.to_csv(os.path.join(OUTPUT_DIR_PATH, 'history.csv'))"],"execution_count":10,"outputs":[{"output_type":"stream","text":["2020-08-16T01:24:06.852182 Start 1\n","[Epoch 1/100] [Batch 70/70] [D loss: 0.318825, acc:  59%] [G loss: 8.521837, adv: 0.581014, recon: 0.316834, id: 0.515466] time: 0:09:24.889548 \n","[Epoch 2/100] [Batch 70/70] [D loss: 0.245689, acc:  62%] [G loss: 7.354591, adv: 0.474042, recon: 0.281496, id: 0.360832] time: 0:14:49.002705 \n","[Epoch 3/100] [Batch 70/70] [D loss: 0.277087, acc:  57%] [G loss: 6.804832, adv: 0.395127, recon: 0.268902, id: 0.295068] time: 0:19:28.135314 \n","[Epoch 4/100] [Batch 70/70] [D loss: 0.287802, acc:  54%] [G loss: 6.161032, adv: 0.401650, recon: 0.235612, id: 0.346725] time: 0:23:34.105621 \n","[Epoch 5/100] [Batch 70/70] [D loss: 0.209363, acc:  67%] [G loss: 7.143202, adv: 0.414517, recon: 0.280726, id: 0.331588] time: 0:27:27.140289 \n","Model weights saved. combined_model\n","[Epoch 6/100] [Batch 70/70] [D loss: 0.387262, acc:  57%] [G loss: 6.455834, adv: 0.702030, recon: 0.223316, id: 0.234907] time: 0:30:53.747993 \n","[Epoch 7/100] [Batch 70/70] [D loss: 0.234861, acc:  62%] [G loss: 6.365351, adv: 0.420827, recon: 0.245497, id: 0.230650] time: 0:34:03.170436 \n","[Epoch 8/100] [Batch 70/70] [D loss: 0.203902, acc:  73%] [G loss: 6.160327, adv: 0.506029, recon: 0.227245, id: 0.247948] time: 0:37:02.458900 \n","[Epoch 9/100] [Batch 70/70] [D loss: 0.226014, acc:  63%] [G loss: 6.300107, adv: 0.466756, recon: 0.239204, id: 0.231469] time: 0:39:50.280712 \n","[Epoch 10/100] [Batch 70/70] [D loss: 0.149009, acc:  80%] [G loss: 6.425917, adv: 0.575277, recon: 0.235577, id: 0.243499] time: 0:42:30.680196 \n","Model weights saved. combined_model\n","[Epoch 11/100] [Batch 70/70] [D loss: 0.192063, acc:  72%] [G loss: 6.287950, adv: 0.559081, recon: 0.229248, id: 0.275352] time: 0:45:06.978607 \n","[Epoch 12/100] [Batch 70/70] [D loss: 0.174756, acc:  77%] [G loss: 7.076870, adv: 0.646865, recon: 0.256488, id: 0.281018] time: 0:47:39.310721 \n","[Epoch 13/100] [Batch 70/70] [D loss: 0.174011, acc:  75%] [G loss: 6.065646, adv: 0.602080, recon: 0.211139, id: 0.296887] time: 0:50:07.255614 \n","[Epoch 14/100] [Batch 70/70] [D loss: 0.139958, acc:  82%] [G loss: 7.118735, adv: 0.803043, recon: 0.246673, id: 0.267751] time: 0:52:25.241598 \n","[Epoch 15/100] [Batch 70/70] [D loss: 0.132777, acc:  83%] [G loss: 5.723608, adv: 0.696109, recon: 0.190503, id: 0.229496] time: 0:54:48.029710 \n","Model weights saved. combined_model\n","[Epoch 16/100] [Batch 70/70] [D loss: 0.131263, acc:  87%] [G loss: 6.703878, adv: 0.747555, recon: 0.229071, id: 0.223120] time: 0:57:07.043772 \n","[Epoch 17/100] [Batch 70/70] [D loss: 0.140178, acc:  81%] [G loss: 6.170047, adv: 0.814986, recon: 0.200370, id: 0.226925] time: 0:59:25.863519 \n","[Epoch 18/100] [Batch 70/70] [D loss: 0.124178, acc:  84%] [G loss: 6.247673, adv: 0.766883, recon: 0.208420, id: 0.245073] time: 1:01:40.097109 \n","[Epoch 19/100] [Batch 70/70] [D loss: 0.131450, acc:  83%] [G loss: 6.102455, adv: 0.807499, recon: 0.200398, id: 0.197775] time: 1:03:55.244996 \n","[Epoch 20/100] [Batch 70/70] [D loss: 0.095845, acc:  90%] [G loss: 6.074277, adv: 0.792793, recon: 0.196183, id: 0.222548] time: 1:06:09.738326 \n","Model weights saved. combined_model\n","[Epoch 21/100] [Batch 70/70] [D loss: 0.089098, acc:  90%] [G loss: 5.417587, adv: 0.813208, recon: 0.165247, id: 0.226407] time: 1:08:24.405615 \n","[Epoch 22/100] [Batch 70/70] [D loss: 0.111597, acc:  87%] [G loss: 5.722377, adv: 0.773227, recon: 0.182239, id: 0.220001] time: 1:10:35.967277 \n","[Epoch 23/100] [Batch 70/70] [D loss: 0.106462, acc:  87%] [G loss: 6.182508, adv: 0.875832, recon: 0.192338, id: 0.233959] time: 1:12:48.897614 \n","[Epoch 24/100] [Batch 70/70] [D loss: 0.191221, acc:  77%] [G loss: 6.152228, adv: 0.994234, recon: 0.182096, id: 0.206724] time: 1:15:02.858203 \n","[Epoch 25/100] [Batch 70/70] [D loss: 0.088992, acc:  91%] [G loss: 5.651982, adv: 0.892403, recon: 0.168585, id: 0.187946] time: 1:17:15.495649 \n","Model weights saved. combined_model\n","[Epoch 26/100] [Batch 70/70] [D loss: 0.086528, acc:  91%] [G loss: 5.975770, adv: 0.912983, recon: 0.181211, id: 0.225076] time: 1:19:29.879677 \n","[Epoch 27/100] [Batch 70/70] [D loss: 0.147888, acc:  81%] [G loss: 5.803874, adv: 0.778554, recon: 0.183777, id: 0.263873] time: 1:21:42.000690 \n","[Epoch 28/100] [Batch 70/70] [D loss: 0.085418, acc:  91%] [G loss: 6.919192, adv: 1.000342, recon: 0.217744, id: 0.254891] time: 1:23:54.521107 \n","[Epoch 29/100] [Batch 70/70] [D loss: 0.102939, acc:  89%] [G loss: 6.393651, adv: 0.966022, recon: 0.195923, id: 0.228786] time: 1:26:06.515770 \n","[Epoch 30/100] [Batch 70/70] [D loss: 0.112789, acc:  86%] [G loss: 6.219597, adv: 0.898162, recon: 0.194706, id: 0.215980] time: 1:28:18.632759 \n","Model weights saved. combined_model\n","[Epoch 31/100] [Batch 70/70] [D loss: 0.164921, acc:  77%] [G loss: 5.513529, adv: 0.779152, recon: 0.170879, id: 0.218335] time: 1:30:33.806530 \n","[Epoch 32/100] [Batch 70/70] [D loss: 0.115065, acc:  86%] [G loss: 6.418616, adv: 0.906567, recon: 0.202042, id: 0.233248] time: 1:32:46.940127 \n","[Epoch 33/100] [Batch 70/70] [D loss: 0.208873, acc:  69%] [G loss: 5.685342, adv: 0.928343, recon: 0.167426, id: 0.224187] time: 1:34:58.765135 \n","[Epoch 34/100] [Batch 70/70] [D loss: 0.101120, acc:  89%] [G loss: 6.186432, adv: 0.914670, recon: 0.192584, id: 0.213254] time: 1:37:10.756915 \n","[Epoch 35/100] [Batch 70/70] [D loss: 0.157240, acc:  80%] [G loss: 6.206722, adv: 0.917486, recon: 0.193317, id: 0.245274] time: 1:39:22.873548 \n","Model weights saved. combined_model\n","[Epoch 36/100] [Batch 70/70] [D loss: 0.104339, acc:  87%] [G loss: 5.447055, adv: 0.934627, recon: 0.155825, id: 0.193131] time: 1:41:37.152355 \n","[Epoch 37/100] [Batch 70/70] [D loss: 0.097634, acc:  89%] [G loss: 5.648207, adv: 0.893254, recon: 0.168748, id: 0.222805] time: 1:43:49.227142 \n","[Epoch 38/100] [Batch 70/70] [D loss: 0.135383, acc:  81%] [G loss: 5.875743, adv: 0.877268, recon: 0.182922, id: 0.214564] time: 1:46:00.953729 \n","[Epoch 39/100] [Batch 70/70] [D loss: 0.164844, acc:  77%] [G loss: 5.775126, adv: 0.980526, recon: 0.166412, id: 0.207964] time: 1:48:13.112626 \n","[Epoch 40/100] [Batch 70/70] [D loss: 0.082462, acc:  93%] [G loss: 5.909832, adv: 0.948536, recon: 0.173248, id: 0.211055] time: 1:50:25.268744 \n","Model weights saved. combined_model\n","[Epoch 41/100] [Batch 70/70] [D loss: 0.122313, acc:  85%] [G loss: 5.775913, adv: 0.982441, recon: 0.168242, id: 0.213103] time: 1:52:39.193314 \n","[Epoch 42/100] [Batch 70/70] [D loss: 0.114424, acc:  86%] [G loss: 6.139220, adv: 0.936854, recon: 0.185839, id: 0.240962] time: 1:54:50.445494 \n","[Epoch 43/100] [Batch 70/70] [D loss: 0.116740, acc:  87%] [G loss: 6.205518, adv: 0.989862, recon: 0.186577, id: 0.234317] time: 1:57:01.976725 \n","[Epoch 44/100] [Batch 70/70] [D loss: 0.076401, acc:  93%] [G loss: 6.368467, adv: 1.009200, recon: 0.192421, id: 0.226449] time: 1:59:13.184771 \n","[Epoch 45/100] [Batch 70/70] [D loss: 0.116091, acc:  88%] [G loss: 6.076897, adv: 0.984058, recon: 0.179701, id: 0.232372] time: 2:01:24.820594 \n","Model weights saved. combined_model\n","[Epoch 46/100] [Batch 70/70] [D loss: 0.069525, acc:  94%] [G loss: 5.889197, adv: 0.972949, recon: 0.172892, id: 0.205658] time: 2:03:38.095388 \n","[Epoch 47/100] [Batch 70/70] [D loss: 0.099913, acc:  87%] [G loss: 5.730986, adv: 0.910174, recon: 0.171771, id: 0.195082] time: 2:05:50.114404 \n","[Epoch 48/100] [Batch 70/70] [D loss: 0.116515, acc:  86%] [G loss: 6.259629, adv: 1.029982, recon: 0.183961, id: 0.242400] time: 2:08:02.545447 \n","[Epoch 49/100] [Batch 70/70] [D loss: 0.081015, acc:  93%] [G loss: 5.943433, adv: 1.081058, recon: 0.165547, id: 0.184320] time: 2:10:14.969148 \n","[Epoch 50/100] [Batch 70/70] [D loss: 0.092267, acc:  90%] [G loss: 5.857302, adv: 1.006006, recon: 0.168143, id: 0.204218] time: 2:12:27.456478 \n","Model weights saved. combined_model\n","[Epoch 51/100] [Batch 70/70] [D loss: 0.115690, acc:  85%] [G loss: 5.877070, adv: 1.004656, recon: 0.166206, id: 0.249705] time: 2:14:41.506326 \n","[Epoch 52/100] [Batch 70/70] [D loss: 0.106063, acc:  88%] [G loss: 5.936268, adv: 1.016794, recon: 0.171154, id: 0.189062] time: 2:16:54.006337 \n","[Epoch 53/100] [Batch 70/70] [D loss: 0.090907, acc:  90%] [G loss: 5.783392, adv: 0.987679, recon: 0.166413, id: 0.222519] time: 2:19:05.722034 \n","[Epoch 54/100] [Batch 70/70] [D loss: 0.098352, acc:  89%] [G loss: 5.666290, adv: 1.074579, recon: 0.153821, id: 0.192250] time: 2:21:17.179457 \n","[Epoch 55/100] [Batch 70/70] [D loss: 0.059266, acc:  95%] [G loss: 5.870924, adv: 1.004234, recon: 0.170349, id: 0.223066] time: 2:23:28.849349 \n","Model weights saved. combined_model\n","[Epoch 56/100] [Batch 70/70] [D loss: 0.087240, acc:  93%] [G loss: 6.176202, adv: 0.980197, recon: 0.184969, id: 0.237370] time: 2:25:42.673414 \n","[Epoch 57/100] [Batch 70/70] [D loss: 0.074729, acc:  95%] [G loss: 6.086513, adv: 1.050570, recon: 0.175563, id: 0.207106] time: 2:27:54.309466 \n","[Epoch 58/100] [Batch 70/70] [D loss: 0.140183, acc:  85%] [G loss: 6.278415, adv: 1.028131, recon: 0.186461, id: 0.225919] time: 2:30:06.134971 \n","[Epoch 59/100] [Batch 70/70] [D loss: 0.083776, acc:  92%] [G loss: 6.704578, adv: 1.016334, recon: 0.207954, id: 0.244949] time: 2:32:18.670872 \n","[Epoch 60/100] [Batch 70/70] [D loss: 0.079342, acc:  92%] [G loss: 5.456802, adv: 1.016737, recon: 0.147740, id: 0.205126] time: 2:34:31.423570 \n","Model weights saved. combined_model\n","[Epoch 61/100] [Batch 70/70] [D loss: 0.065215, acc:  95%] [G loss: 6.446092, adv: 1.093678, recon: 0.185386, id: 0.228134] time: 2:36:44.786210 \n","[Epoch 62/100] [Batch 70/70] [D loss: 0.044252, acc:  97%] [G loss: 5.945789, adv: 1.078946, recon: 0.166602, id: 0.182191] time: 2:38:57.369879 \n","[Epoch 63/100] [Batch 70/70] [D loss: 0.078165, acc:  93%] [G loss: 5.956108, adv: 1.106898, recon: 0.163872, id: 0.232195] time: 2:41:08.868463 \n","[Epoch 64/100] [Batch 70/70] [D loss: 0.050780, acc:  97%] [G loss: 6.202037, adv: 1.020908, recon: 0.185042, id: 0.220032] time: 2:43:20.563213 \n","[Epoch 65/100] [Batch 70/70] [D loss: 0.087731, acc:  92%] [G loss: 5.937669, adv: 1.088714, recon: 0.166018, id: 0.183117] time: 2:45:32.573589 \n","Model weights saved. combined_model\n","[Epoch 66/100] [Batch 70/70] [D loss: 0.073677, acc:  93%] [G loss: 5.359361, adv: 1.060200, recon: 0.140847, id: 0.187831] time: 2:47:46.347019 \n","[Epoch 67/100] [Batch 70/70] [D loss: 0.072081, acc:  93%] [G loss: 5.595404, adv: 1.047768, recon: 0.152432, id: 0.207652] time: 2:49:58.340351 \n","[Epoch 68/100] [Batch 70/70] [D loss: 0.063680, acc:  95%] [G loss: 6.214478, adv: 1.080714, recon: 0.177247, id: 0.244663] time: 2:52:10.600696 \n","[Epoch 69/100] [Batch 70/70] [D loss: 0.070839, acc:  94%] [G loss: 5.682134, adv: 1.030638, recon: 0.156723, id: 0.233363] time: 2:54:23.240760 \n","[Epoch 70/100] [Batch 70/70] [D loss: 0.099476, acc:  88%] [G loss: 5.869086, adv: 1.139935, recon: 0.157088, id: 0.167056] time: 2:56:35.953907 \n","Model weights saved. combined_model\n","[Epoch 71/100] [Batch 70/70] [D loss: 0.109550, acc:  87%] [G loss: 5.702770, adv: 1.003213, recon: 0.160691, id: 0.196245] time: 2:58:49.858973 \n","[Epoch 72/100] [Batch 70/70] [D loss: 0.051535, acc:  97%] [G loss: 5.560233, adv: 1.109600, recon: 0.145835, id: 0.167543] time: 3:01:01.753321 \n","[Epoch 73/100] [Batch 70/70] [D loss: 0.047310, acc:  96%] [G loss: 5.354621, adv: 1.010236, recon: 0.144300, id: 0.173284] time: 3:03:13.000895 \n","[Epoch 74/100] [Batch 70/70] [D loss: 0.048713, acc:  97%] [G loss: 5.620205, adv: 1.121597, recon: 0.149205, id: 0.162787] time: 3:05:25.218083 \n","[Epoch 75/100] [Batch 70/70] [D loss: 0.146204, acc:  85%] [G loss: 5.604721, adv: 1.068609, recon: 0.150291, id: 0.180200] time: 3:07:37.612340 \n","Model weights saved. combined_model\n","[Epoch 76/100] [Batch 70/70] [D loss: 0.054375, acc:  94%] [G loss: 5.500056, adv: 1.008882, recon: 0.152291, id: 0.197845] time: 3:09:52.321190 \n","[Epoch 77/100] [Batch 70/70] [D loss: 0.057023, acc:  96%] [G loss: 6.185248, adv: 0.974547, recon: 0.188166, id: 0.190075] time: 3:12:04.686799 \n","[Epoch 78/100] [Batch 70/70] [D loss: 0.067860, acc:  95%] [G loss: 5.618865, adv: 1.039083, recon: 0.153866, id: 0.204186] time: 3:14:17.477518 \n","[Epoch 79/100] [Batch 70/70] [D loss: 0.051553, acc:  97%] [G loss: 5.744334, adv: 0.952262, recon: 0.169010, id: 0.192508] time: 3:16:30.484974 \n","[Epoch 80/100] [Batch 70/70] [D loss: 0.041675, acc:  97%] [G loss: 5.793634, adv: 1.094142, recon: 0.154980, id: 0.172459] time: 3:18:43.874301 \n","Model weights saved. combined_model\n","[Epoch 81/100] [Batch 70/70] [D loss: 0.107850, acc:  88%] [G loss: 5.603244, adv: 1.131551, recon: 0.143545, id: 0.208707] time: 3:20:58.201189 \n","[Epoch 82/100] [Batch 70/70] [D loss: 0.030764, acc:  99%] [G loss: 5.544329, adv: 1.047755, recon: 0.150182, id: 0.185074] time: 3:23:11.697826 \n","[Epoch 83/100] [Batch 70/70] [D loss: 0.041421, acc:  98%] [G loss: 5.776705, adv: 1.103646, recon: 0.154747, id: 0.230001] time: 3:25:24.341799 \n","[Epoch 84/100] [Batch 70/70] [D loss: 0.034397, acc:  99%] [G loss: 5.938555, adv: 1.108131, recon: 0.162622, id: 0.198983] time: 3:27:37.202963 \n","[Epoch 85/100] [Batch 70/70] [D loss: 0.049208, acc:  97%] [G loss: 5.773868, adv: 1.031985, recon: 0.162080, id: 0.224981] time: 3:29:50.754377 \n","Model weights saved. combined_model\n","[Epoch 86/100] [Batch 70/70] [D loss: 0.045804, acc:  99%] [G loss: 5.466637, adv: 1.092326, recon: 0.141550, id: 0.191489] time: 3:32:05.423474 \n","[Epoch 87/100] [Batch 70/70] [D loss: 0.082335, acc:  90%] [G loss: 6.258050, adv: 1.451267, recon: 0.146733, id: 0.188067] time: 3:34:18.211422 \n","[Epoch 88/100] [Batch 70/70] [D loss: 0.115579, acc:  83%] [G loss: 4.664979, adv: 0.774593, recon: 0.134274, id: 0.177701] time: 3:36:30.726860 \n","[Epoch 89/100] [Batch 70/70] [D loss: 0.118290, acc:  83%] [G loss: 4.587328, adv: 0.815060, recon: 0.127336, id: 0.138522] time: 3:38:43.419299 \n","[Epoch 90/100] [Batch 70/70] [D loss: 0.107368, acc:  86%] [G loss: 4.429786, adv: 0.766846, recon: 0.123280, id: 0.187939] time: 3:40:55.826663 \n","Model weights saved. combined_model\n","[Epoch 91/100] [Batch 70/70] [D loss: 0.098875, acc:  87%] [G loss: 4.550964, adv: 0.757159, recon: 0.127170, id: 0.198831] time: 3:43:10.070448 \n","[Epoch 92/100] [Batch 70/70] [D loss: 0.060623, acc:  95%] [G loss: 5.173244, adv: 0.923421, recon: 0.143850, id: 0.183904] time: 3:45:22.900835 \n","[Epoch 93/100] [Batch 70/70] [D loss: 0.082674, acc:  91%] [G loss: 4.948460, adv: 0.885009, recon: 0.138079, id: 0.141288] time: 3:47:35.771764 \n","[Epoch 94/100] [Batch 70/70] [D loss: 0.081547, acc:  94%] [G loss: 5.494621, adv: 1.024680, recon: 0.149441, id: 0.181422] time: 3:49:48.380105 \n","[Epoch 95/100] [Batch 70/70] [D loss: 0.052547, acc:  95%] [G loss: 5.438168, adv: 1.028545, recon: 0.145594, id: 0.235996] time: 3:52:00.708263 \n","Model weights saved. combined_model\n","[Epoch 96/100] [Batch 70/70] [D loss: 0.034632, acc:  98%] [G loss: 5.441697, adv: 1.057791, recon: 0.145941, id: 0.182463] time: 3:54:14.877744 \n","[Epoch 97/100] [Batch 70/70] [D loss: 0.086124, acc:  93%] [G loss: 5.524442, adv: 1.211372, recon: 0.134158, id: 0.192817] time: 3:56:27.810352 \n","[Epoch 98/100] [Batch 70/70] [D loss: 0.058202, acc:  96%] [G loss: 5.485017, adv: 1.088984, recon: 0.144570, id: 0.195961] time: 3:58:40.115382 \n","[Epoch 99/100] [Batch 70/70] [D loss: 0.085527, acc:  92%] [G loss: 5.787488, adv: 1.093844, recon: 0.157953, id: 0.196107] time: 4:00:52.726894 \n","[Epoch 100/100] [Batch 70/70] [D loss: 0.034253, acc:  99%] [G loss: 5.443715, adv: 1.069647, recon: 0.144229, id: 0.168042] time: 4:03:05.488104 \n","Model weights saved. combined_model\n","2020-08-16T05:27:15.024278 End\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"2l2s5CmG3bBx","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1597595279277,"user_tz":-540,"elapsed":23332309,"user":{"displayName":"Noboru Koike","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggp8njUb4jc54JrzfM5cQBkfiCdlz6nY17y8-1szg=s64","userId":"05156582812995850159"}},"outputId":"cb5caca9-e173-493f-cecc-38ec7e10fefb"},"source":["# Image A Count: 560, BatchSize:8, 560/8=70\n","gan.train(epochs=300, batch_size=8, sample_interval=70, save_interval=70*20)\n","\n","gan.history.to_csv(os.path.join(OUTPUT_DIR_PATH, 'history_2.csv'))"],"execution_count":11,"outputs":[{"output_type":"stream","text":["2020-08-16T05:28:56.032172 Start 2\n","[Epoch 1/300] [Batch 70/70] [D loss: 0.028047, acc:  99%] [G loss: 5.148228, adv: 1.047114, recon: 0.128531, id: 0.194858] time: 0:02:11.586903 \n","[Epoch 2/300] [Batch 70/70] [D loss: 0.030160, acc:  99%] [G loss: 5.583652, adv: 1.010215, recon: 0.154389, id: 0.209465] time: 0:04:24.537896 \n","[Epoch 3/300] [Batch 70/70] [D loss: 0.019536, acc:  99%] [G loss: 5.882468, adv: 1.149963, recon: 0.155162, id: 0.217621] time: 0:06:37.063203 \n","[Epoch 4/300] [Batch 70/70] [D loss: 0.053136, acc:  97%] [G loss: 5.703804, adv: 0.976514, recon: 0.167140, id: 0.178208] time: 0:08:49.988192 \n","[Epoch 5/300] [Batch 70/70] [D loss: 0.032087, acc:  99%] [G loss: 5.170218, adv: 0.955817, recon: 0.139115, id: 0.192888] time: 0:11:03.249646 \n","[Epoch 6/300] [Batch 70/70] [D loss: 0.049903, acc:  97%] [G loss: 5.109949, adv: 1.024866, recon: 0.132591, id: 0.144947] time: 0:13:15.727156 \n","[Epoch 7/300] [Batch 70/70] [D loss: 0.164570, acc:  82%] [G loss: 5.519689, adv: 0.956656, recon: 0.157860, id: 0.191129] time: 0:15:28.866609 \n","[Epoch 8/300] [Batch 70/70] [D loss: 0.020875, acc:  99%] [G loss: 5.751134, adv: 0.983477, recon: 0.167992, id: 0.171251] time: 0:17:41.774630 \n","[Epoch 9/300] [Batch 70/70] [D loss: 0.035561, acc:  98%] [G loss: 5.177278, adv: 1.009796, recon: 0.136994, id: 0.164119] time: 0:19:54.455346 \n","[Epoch 10/300] [Batch 70/70] [D loss: 0.033909, acc:  98%] [G loss: 5.437482, adv: 1.064024, recon: 0.143823, id: 0.176392] time: 0:22:07.320800 \n","[Epoch 11/300] [Batch 70/70] [D loss: 0.049838, acc:  96%] [G loss: 5.215144, adv: 0.978868, recon: 0.140147, id: 0.190975] time: 0:24:20.189231 \n","[Epoch 12/300] [Batch 70/70] [D loss: 0.039074, acc:  98%] [G loss: 5.675313, adv: 1.170503, recon: 0.144702, id: 0.167650] time: 0:26:33.110657 \n","[Epoch 13/300] [Batch 70/70] [D loss: 0.028484, acc:  98%] [G loss: 5.339906, adv: 0.964716, recon: 0.149153, id: 0.164581] time: 0:28:45.878722 \n","[Epoch 14/300] [Batch 70/70] [D loss: 0.037560, acc:  97%] [G loss: 5.069680, adv: 0.964550, recon: 0.133627, id: 0.208295] time: 0:30:58.399640 \n","[Epoch 15/300] [Batch 70/70] [D loss: 0.064244, acc:  96%] [G loss: 5.327985, adv: 1.012341, recon: 0.141253, id: 0.207959] time: 0:33:11.488914 \n","[Epoch 16/300] [Batch 70/70] [D loss: 0.028948, acc:  99%] [G loss: 5.146837, adv: 1.008947, recon: 0.136434, id: 0.154252] time: 0:35:25.559719 \n","[Epoch 17/300] [Batch 70/70] [D loss: 0.102415, acc:  85%] [G loss: 5.815162, adv: 1.196841, recon: 0.149474, id: 0.205836] time: 0:37:38.316170 \n","[Epoch 18/300] [Batch 70/70] [D loss: 0.062756, acc:  93%] [G loss: 5.760401, adv: 1.239037, recon: 0.143921, id: 0.163743] time: 0:39:51.184797 \n","[Epoch 19/300] [Batch 70/70] [D loss: 0.030841, acc:  99%] [G loss: 5.298260, adv: 1.061397, recon: 0.137187, id: 0.177523] time: 0:42:03.913719 \n","[Epoch 20/300] [Batch 70/70] [D loss: 0.022359, acc:  99%] [G loss: 4.970119, adv: 1.032578, recon: 0.126056, id: 0.159774] time: 0:44:16.688038 \n","Model weights saved. combined_model\n","[Epoch 21/300] [Batch 70/70] [D loss: 0.037128, acc:  98%] [G loss: 5.199268, adv: 1.098607, recon: 0.131177, id: 0.169963] time: 0:46:31.210851 \n","[Epoch 22/300] [Batch 70/70] [D loss: 0.028041, acc:  99%] [G loss: 5.632975, adv: 1.043862, recon: 0.153401, id: 0.232131] time: 0:48:43.523064 \n","[Epoch 23/300] [Batch 70/70] [D loss: 0.139188, acc:  78%] [G loss: 4.358275, adv: 0.657967, recon: 0.130340, id: 0.177769] time: 0:50:56.189434 \n","[Epoch 24/300] [Batch 70/70] [D loss: 0.142951, acc:  78%] [G loss: 4.415879, adv: 0.757961, recon: 0.124837, id: 0.191386] time: 0:53:07.779550 \n","[Epoch 25/300] [Batch 70/70] [D loss: 0.080019, acc:  91%] [G loss: 4.573441, adv: 0.763669, recon: 0.130907, id: 0.153137] time: 0:55:19.546683 \n","[Epoch 26/300] [Batch 70/70] [D loss: 0.070376, acc:  93%] [G loss: 5.381792, adv: 0.873829, recon: 0.158696, id: 0.197841] time: 0:57:31.974614 \n","[Epoch 27/300] [Batch 70/70] [D loss: 0.058668, acc:  95%] [G loss: 4.630969, adv: 0.939731, recon: 0.118975, id: 0.133977] time: 0:59:43.978273 \n","[Epoch 28/300] [Batch 70/70] [D loss: 0.085465, acc:  89%] [G loss: 5.078784, adv: 1.035377, recon: 0.129640, id: 0.180090] time: 1:01:56.433405 \n","[Epoch 29/300] [Batch 70/70] [D loss: 0.060129, acc:  95%] [G loss: 5.207013, adv: 1.013954, recon: 0.137096, id: 0.175709] time: 1:04:08.190922 \n","[Epoch 30/300] [Batch 70/70] [D loss: 0.023236, acc:  99%] [G loss: 5.218090, adv: 1.018484, recon: 0.135920, id: 0.178338] time: 1:06:20.462637 \n","[Epoch 31/300] [Batch 70/70] [D loss: 0.022385, acc:  99%] [G loss: 5.296148, adv: 1.051201, recon: 0.140822, id: 0.154989] time: 1:08:32.375602 \n","[Epoch 32/300] [Batch 70/70] [D loss: 0.023904, acc:  99%] [G loss: 5.708145, adv: 1.044926, recon: 0.159108, id: 0.160437] time: 1:10:44.821286 \n","[Epoch 33/300] [Batch 70/70] [D loss: 0.025899, acc:  99%] [G loss: 5.245494, adv: 1.069787, recon: 0.133194, id: 0.208595] time: 1:12:57.383103 \n","[Epoch 34/300] [Batch 70/70] [D loss: 0.049164, acc:  96%] [G loss: 5.545894, adv: 1.062217, recon: 0.149878, id: 0.175941] time: 1:15:10.259073 \n","[Epoch 35/300] [Batch 70/70] [D loss: 0.018668, acc: 100%] [G loss: 5.232631, adv: 1.053071, recon: 0.133113, id: 0.193991] time: 1:17:22.685344 \n","[Epoch 36/300] [Batch 70/70] [D loss: 0.035303, acc:  97%] [G loss: 5.184413, adv: 1.043908, recon: 0.131605, id: 0.208276] time: 1:19:35.329386 \n","[Epoch 37/300] [Batch 70/70] [D loss: 0.023836, acc:  99%] [G loss: 5.233510, adv: 1.040379, recon: 0.135578, id: 0.190820] time: 1:21:47.707965 \n","[Epoch 38/300] [Batch 70/70] [D loss: 0.032174, acc:  97%] [G loss: 5.224506, adv: 1.061445, recon: 0.134244, id: 0.187402] time: 1:24:00.035591 \n","[Epoch 39/300] [Batch 70/70] [D loss: 0.026424, acc:  98%] [G loss: 4.989520, adv: 1.002330, recon: 0.129296, id: 0.171401] time: 1:26:13.225893 \n","[Epoch 40/300] [Batch 70/70] [D loss: 0.018043, acc: 100%] [G loss: 5.236142, adv: 0.976476, recon: 0.142117, id: 0.185747] time: 1:28:24.617878 \n","Model weights saved. combined_model\n","[Epoch 41/300] [Batch 70/70] [D loss: 0.030363, acc:  97%] [G loss: 5.022003, adv: 1.060000, recon: 0.124405, id: 0.159598] time: 1:30:37.773345 \n","[Epoch 42/300] [Batch 70/70] [D loss: 0.122051, acc:  80%] [G loss: 4.421392, adv: 0.707693, recon: 0.129683, id: 0.173054] time: 1:32:48.802877 \n","[Epoch 43/300] [Batch 70/70] [D loss: 0.052040, acc:  96%] [G loss: 5.120602, adv: 0.878984, recon: 0.142882, id: 0.203826] time: 1:35:00.603504 \n","[Epoch 44/300] [Batch 70/70] [D loss: 0.031565, acc:  99%] [G loss: 5.020762, adv: 1.032680, recon: 0.126400, id: 0.170307] time: 1:37:11.581081 \n","[Epoch 45/300] [Batch 70/70] [D loss: 0.034272, acc:  99%] [G loss: 5.091984, adv: 1.016599, recon: 0.132742, id: 0.183005] time: 1:39:22.592620 \n","[Epoch 46/300] [Batch 70/70] [D loss: 0.035890, acc:  97%] [G loss: 4.888326, adv: 0.961790, recon: 0.126977, id: 0.173034] time: 1:41:33.615747 \n","[Epoch 47/300] [Batch 70/70] [D loss: 0.021427, acc: 100%] [G loss: 5.345652, adv: 1.051218, recon: 0.140381, id: 0.161327] time: 1:43:44.505434 \n","[Epoch 48/300] [Batch 70/70] [D loss: 0.021786, acc:  99%] [G loss: 5.059560, adv: 0.962525, recon: 0.133579, id: 0.190293] time: 1:45:56.120122 \n","[Epoch 49/300] [Batch 70/70] [D loss: 0.063068, acc:  95%] [G loss: 5.673362, adv: 1.195533, recon: 0.137969, id: 0.239352] time: 1:48:06.962797 \n","[Epoch 50/300] [Batch 70/70] [D loss: 0.041961, acc:  96%] [G loss: 4.996057, adv: 0.988047, recon: 0.131265, id: 0.156918] time: 1:50:19.066657 \n","[Epoch 51/300] [Batch 70/70] [D loss: 0.017484, acc:  99%] [G loss: 5.285970, adv: 1.110263, recon: 0.131027, id: 0.157080] time: 1:52:30.040783 \n","[Epoch 52/300] [Batch 70/70] [D loss: 0.033416, acc:  98%] [G loss: 5.570458, adv: 1.135502, recon: 0.142151, id: 0.229744] time: 1:54:41.252146 \n","[Epoch 53/300] [Batch 70/70] [D loss: 0.019091, acc:  99%] [G loss: 4.977569, adv: 1.078551, recon: 0.119526, id: 0.202574] time: 1:56:52.547582 \n","[Epoch 54/300] [Batch 70/70] [D loss: 0.020501, acc:  99%] [G loss: 5.477272, adv: 1.035775, recon: 0.146163, id: 0.183359] time: 1:59:03.534664 \n","[Epoch 55/300] [Batch 70/70] [D loss: 0.014669, acc:  99%] [G loss: 5.491596, adv: 1.034558, recon: 0.149689, id: 0.171328] time: 2:01:15.539194 \n","[Epoch 56/300] [Batch 70/70] [D loss: 0.020527, acc:  99%] [G loss: 5.230995, adv: 1.069196, recon: 0.132888, id: 0.194115] time: 2:03:26.681027 \n","[Epoch 57/300] [Batch 70/70] [D loss: 0.078757, acc:  89%] [G loss: 5.636046, adv: 1.300250, recon: 0.131538, id: 0.176099] time: 2:05:37.943641 \n","[Epoch 58/300] [Batch 70/70] [D loss: 0.058113, acc:  94%] [G loss: 5.109975, adv: 1.046639, recon: 0.129797, id: 0.167268] time: 2:07:49.095874 \n","[Epoch 59/300] [Batch 70/70] [D loss: 0.023873, acc:  99%] [G loss: 5.482206, adv: 1.093579, recon: 0.143660, id: 0.160660] time: 2:10:00.310135 \n","[Epoch 60/300] [Batch 70/70] [D loss: 0.062977, acc:  95%] [G loss: 5.154121, adv: 1.097479, recon: 0.127818, id: 0.144360] time: 2:12:24.449772 \n","Model weights saved. combined_model\n","[Epoch 61/300] [Batch 70/70] [D loss: 0.017848, acc:  99%] [G loss: 5.083268, adv: 1.034097, recon: 0.129415, id: 0.186916] time: 2:14:37.305701 \n","[Epoch 62/300] [Batch 70/70] [D loss: 0.028740, acc:  98%] [G loss: 5.614602, adv: 1.136314, recon: 0.145569, id: 0.199109] time: 2:16:48.579343 \n","[Epoch 63/300] [Batch 70/70] [D loss: 0.013244, acc: 100%] [G loss: 5.194751, adv: 1.051209, recon: 0.135276, id: 0.134040] time: 2:18:59.511884 \n","[Epoch 64/300] [Batch 70/70] [D loss: 0.022466, acc:  99%] [G loss: 5.265934, adv: 1.142997, recon: 0.127489, id: 0.194481] time: 2:21:16.380544 \n","[Epoch 65/300] [Batch 70/70] [D loss: 0.104616, acc:  89%] [G loss: 5.428514, adv: 1.113191, recon: 0.138375, id: 0.184672] time: 2:23:27.463933 \n","[Epoch 66/300] [Batch 70/70] [D loss: 0.016214, acc:  99%] [G loss: 5.268576, adv: 1.070895, recon: 0.136291, id: 0.137979] time: 2:25:40.124722 \n","[Epoch 67/300] [Batch 70/70] [D loss: 0.261523, acc:  84%] [G loss: 6.540760, adv: 1.758213, recon: 0.132101, id: 0.164461] time: 2:27:51.689512 \n","[Epoch 68/300] [Batch 70/70] [D loss: 0.078162, acc:  89%] [G loss: 4.720399, adv: 0.810280, recon: 0.133302, id: 0.189719] time: 2:30:02.874466 \n","[Epoch 69/300] [Batch 70/70] [D loss: 0.030704, acc:  98%] [G loss: 5.096279, adv: 0.908740, recon: 0.141818, id: 0.191557] time: 2:32:14.252144 \n","[Epoch 70/300] [Batch 70/70] [D loss: 0.010991, acc:  99%] [G loss: 4.865638, adv: 0.980582, recon: 0.124969, id: 0.148557] time: 2:34:25.499609 \n","[Epoch 71/300] [Batch 70/70] [D loss: 0.024626, acc:  99%] [G loss: 5.111938, adv: 1.003327, recon: 0.133382, id: 0.195186] time: 2:36:36.545231 \n","[Epoch 72/300] [Batch 70/70] [D loss: 0.012267, acc:  99%] [G loss: 4.981261, adv: 0.994233, recon: 0.130888, id: 0.153916] time: 2:38:47.339529 \n","[Epoch 73/300] [Batch 70/70] [D loss: 0.011592, acc:  99%] [G loss: 5.783273, adv: 0.998249, recon: 0.168330, id: 0.207802] time: 2:40:59.198499 \n","[Epoch 74/300] [Batch 70/70] [D loss: 0.011909, acc: 100%] [G loss: 4.970572, adv: 0.997829, recon: 0.127516, id: 0.178159] time: 2:43:10.171247 \n","[Epoch 75/300] [Batch 70/70] [D loss: 0.010767, acc:  99%] [G loss: 5.522530, adv: 1.010609, recon: 0.149850, id: 0.226425] time: 2:45:20.743374 \n","[Epoch 76/300] [Batch 70/70] [D loss: 0.066007, acc:  92%] [G loss: 5.309024, adv: 1.122658, recon: 0.130807, id: 0.220988] time: 2:47:32.756606 \n","[Epoch 77/300] [Batch 70/70] [D loss: 0.014722, acc:  99%] [G loss: 5.159439, adv: 1.029468, recon: 0.135624, id: 0.162696] time: 2:49:43.984156 \n","[Epoch 78/300] [Batch 70/70] [D loss: 0.011439, acc: 100%] [G loss: 5.094540, adv: 1.024891, recon: 0.130366, id: 0.179778] time: 2:51:54.688687 \n","[Epoch 79/300] [Batch 70/70] [D loss: 0.021234, acc:  99%] [G loss: 4.883008, adv: 0.941348, recon: 0.126095, id: 0.208293] time: 2:54:06.266241 \n","[Epoch 80/300] [Batch 70/70] [D loss: 0.039858, acc:  97%] [G loss: 4.808942, adv: 1.092325, recon: 0.109505, id: 0.174257] time: 2:56:18.089632 \n","Model weights saved. combined_model\n","[Epoch 81/300] [Batch 70/70] [D loss: 0.010241, acc: 100%] [G loss: 4.864839, adv: 1.017824, recon: 0.119000, id: 0.178894] time: 2:58:31.114038 \n","[Epoch 82/300] [Batch 70/70] [D loss: 0.014812, acc:  99%] [G loss: 5.468442, adv: 1.121190, recon: 0.136463, id: 0.271354] time: 3:00:42.246674 \n","[Epoch 83/300] [Batch 70/70] [D loss: 0.010545, acc: 100%] [G loss: 4.924559, adv: 1.002558, recon: 0.124823, id: 0.171668] time: 3:02:53.993068 \n","[Epoch 84/300] [Batch 70/70] [D loss: 0.013204, acc: 100%] [G loss: 5.070876, adv: 1.024498, recon: 0.129792, id: 0.186032] time: 3:05:05.678365 \n","[Epoch 85/300] [Batch 70/70] [D loss: 0.023454, acc:  99%] [G loss: 5.095410, adv: 1.110294, recon: 0.122138, id: 0.175431] time: 3:07:17.194449 \n","[Epoch 86/300] [Batch 70/70] [D loss: 0.008391, acc: 100%] [G loss: 4.672489, adv: 1.044420, recon: 0.109627, id: 0.157477] time: 3:09:28.401181 \n","[Epoch 87/300] [Batch 70/70] [D loss: 0.008209, acc: 100%] [G loss: 4.798693, adv: 1.048771, recon: 0.111233, id: 0.201859] time: 3:11:39.663585 \n","[Epoch 88/300] [Batch 70/70] [D loss: 0.011024, acc:  99%] [G loss: 4.881223, adv: 1.036834, recon: 0.120207, id: 0.152051] time: 3:13:50.655507 \n","[Epoch 89/300] [Batch 70/70] [D loss: 0.008964, acc: 100%] [G loss: 4.793064, adv: 1.038464, recon: 0.114446, id: 0.166393] time: 3:16:01.850451 \n","[Epoch 90/300] [Batch 70/70] [D loss: 0.014169, acc:  99%] [G loss: 5.212878, adv: 1.167364, recon: 0.122035, id: 0.198325] time: 3:18:13.547353 \n","[Epoch 91/300] [Batch 70/70] [D loss: 0.011319, acc: 100%] [G loss: 4.643369, adv: 0.992872, recon: 0.112904, id: 0.155336] time: 3:20:24.289720 \n","[Epoch 92/300] [Batch 70/70] [D loss: 0.077720, acc:  91%] [G loss: 4.644116, adv: 0.856742, recon: 0.124493, id: 0.176016] time: 3:22:35.790583 \n","[Epoch 93/300] [Batch 70/70] [D loss: 0.024082, acc:  99%] [G loss: 4.578462, adv: 0.975143, recon: 0.109191, id: 0.182075] time: 3:24:47.686984 \n","[Epoch 94/300] [Batch 70/70] [D loss: 0.044343, acc:  95%] [G loss: 4.720860, adv: 0.932600, recon: 0.120743, id: 0.151432] time: 3:26:59.355980 \n","[Epoch 95/300] [Batch 70/70] [D loss: 0.019936, acc:  99%] [G loss: 4.890067, adv: 1.036973, recon: 0.119629, id: 0.166641] time: 3:29:10.593566 \n","[Epoch 96/300] [Batch 70/70] [D loss: 0.022698, acc:  99%] [G loss: 4.860059, adv: 1.088842, recon: 0.115922, id: 0.134943] time: 3:31:21.451775 \n","[Epoch 97/300] [Batch 70/70] [D loss: 0.010335, acc: 100%] [G loss: 5.005342, adv: 1.007842, recon: 0.128213, id: 0.177747] time: 3:33:33.411588 \n","[Epoch 98/300] [Batch 70/70] [D loss: 0.023741, acc:  99%] [G loss: 4.904693, adv: 1.015523, recon: 0.123712, id: 0.164854] time: 3:35:44.484165 \n","[Epoch 99/300] [Batch 70/70] [D loss: 0.019994, acc:  99%] [G loss: 5.382281, adv: 1.136887, recon: 0.133684, id: 0.192184] time: 3:37:55.652777 \n","[Epoch 100/300] [Batch 70/70] [D loss: 0.015653, acc:  99%] [G loss: 4.809872, adv: 1.093451, recon: 0.113400, id: 0.127647] time: 3:40:06.988266 \n","Model weights saved. combined_model\n","[Epoch 101/300] [Batch 70/70] [D loss: 0.017189, acc:  98%] [G loss: 4.730634, adv: 0.998123, recon: 0.115812, id: 0.163288] time: 3:42:20.058251 \n","[Epoch 102/300] [Batch 70/70] [D loss: 0.009016, acc:  99%] [G loss: 5.054721, adv: 1.038229, recon: 0.125249, id: 0.193953] time: 3:44:31.883121 \n","[Epoch 103/300] [Batch 70/70] [D loss: 0.017839, acc:  99%] [G loss: 5.069326, adv: 1.164605, recon: 0.115212, id: 0.198254] time: 3:46:42.727638 \n","[Epoch 104/300] [Batch 70/70] [D loss: 0.009356, acc:  99%] [G loss: 5.188739, adv: 1.040507, recon: 0.134277, id: 0.178005] time: 3:48:54.118238 \n","[Epoch 105/300] [Batch 70/70] [D loss: 0.019309, acc:  99%] [G loss: 4.708117, adv: 1.018538, recon: 0.113319, id: 0.172675] time: 3:51:05.130201 \n","[Epoch 106/300] [Batch 70/70] [D loss: 0.013860, acc: 100%] [G loss: 4.824430, adv: 1.027479, recon: 0.117420, id: 0.153822] time: 3:53:16.986289 \n","[Epoch 107/300] [Batch 70/70] [D loss: 0.017787, acc:  99%] [G loss: 4.718527, adv: 1.087067, recon: 0.109784, id: 0.141994] time: 3:55:28.126900 \n","[Epoch 108/300] [Batch 70/70] [D loss: 0.023423, acc:  99%] [G loss: 4.769633, adv: 1.040528, recon: 0.113713, id: 0.181622] time: 3:57:39.070240 \n","[Epoch 109/300] [Batch 70/70] [D loss: 0.009662, acc: 100%] [G loss: 4.838319, adv: 1.011035, recon: 0.119428, id: 0.160077] time: 3:59:50.469789 \n","[Epoch 110/300] [Batch 70/70] [D loss: 0.012545, acc:  99%] [G loss: 4.555665, adv: 1.033548, recon: 0.106120, id: 0.151646] time: 4:02:02.170285 \n","[Epoch 111/300] [Batch 70/70] [D loss: 0.008975, acc: 100%] [G loss: 4.897530, adv: 1.050704, recon: 0.118345, id: 0.182054] time: 4:04:13.747123 \n","[Epoch 112/300] [Batch 70/70] [D loss: 0.009423, acc: 100%] [G loss: 4.491201, adv: 1.030254, recon: 0.101838, id: 0.169244] time: 4:06:25.492264 \n","[Epoch 113/300] [Batch 70/70] [D loss: 0.009159, acc: 100%] [G loss: 4.876203, adv: 1.050734, recon: 0.121034, id: 0.153800] time: 4:08:36.409947 \n","[Epoch 114/300] [Batch 70/70] [D loss: 0.011904, acc: 100%] [G loss: 4.996577, adv: 1.097979, recon: 0.119693, id: 0.169970] time: 4:10:48.063959 \n","[Epoch 115/300] [Batch 70/70] [D loss: 0.012845, acc:  99%] [G loss: 4.743147, adv: 1.053811, recon: 0.109865, id: 0.185847] time: 4:12:59.943326 \n","[Epoch 116/300] [Batch 70/70] [D loss: 0.006116, acc: 100%] [G loss: 4.590686, adv: 1.051084, recon: 0.106663, id: 0.135871] time: 4:15:11.648241 \n","[Epoch 117/300] [Batch 70/70] [D loss: 0.013078, acc:  99%] [G loss: 4.774528, adv: 1.058595, recon: 0.114578, id: 0.152774] time: 4:17:22.788258 \n","[Epoch 118/300] [Batch 70/70] [D loss: 0.009123, acc:  99%] [G loss: 5.063763, adv: 1.062530, recon: 0.129522, id: 0.128724] time: 4:19:33.988536 \n","[Epoch 119/300] [Batch 70/70] [D loss: 0.007273, acc:  99%] [G loss: 5.247131, adv: 0.991589, recon: 0.137687, id: 0.254186] time: 4:21:45.591472 \n","[Epoch 120/300] [Batch 70/70] [D loss: 0.009763, acc:  99%] [G loss: 4.928035, adv: 1.029495, recon: 0.122808, id: 0.182711] time: 4:23:56.659127 \n","Model weights saved. combined_model\n","[Epoch 121/300] [Batch 70/70] [D loss: 0.006983, acc: 100%] [G loss: 4.472648, adv: 1.012438, recon: 0.103588, id: 0.149177] time: 4:26:09.814490 \n","[Epoch 122/300] [Batch 70/70] [D loss: 0.243475, acc:  76%] [G loss: 5.077245, adv: 0.816999, recon: 0.148693, id: 0.196076] time: 4:28:21.319032 \n","[Epoch 123/300] [Batch 70/70] [D loss: 0.121442, acc:  80%] [G loss: 3.753578, adv: 0.705102, recon: 0.097571, id: 0.122913] time: 4:30:33.091837 \n","[Epoch 124/300] [Batch 70/70] [D loss: 0.114679, acc:  81%] [G loss: 4.503357, adv: 0.792634, recon: 0.124359, id: 0.185061] time: 4:32:44.072549 \n","[Epoch 125/300] [Batch 70/70] [D loss: 0.088590, acc:  89%] [G loss: 4.004254, adv: 0.734616, recon: 0.107036, id: 0.145907] time: 4:34:54.906443 \n","[Epoch 126/300] [Batch 70/70] [D loss: 0.074463, acc:  90%] [G loss: 4.601701, adv: 0.919666, recon: 0.115317, id: 0.201950] time: 4:37:06.767804 \n","[Epoch 127/300] [Batch 70/70] [D loss: 0.027722, acc:  98%] [G loss: 4.734921, adv: 0.944691, recon: 0.122157, id: 0.174273] time: 4:39:18.879040 \n","[Epoch 128/300] [Batch 70/70] [D loss: 0.050312, acc:  94%] [G loss: 4.741086, adv: 1.071581, recon: 0.110835, id: 0.188709] time: 4:41:30.306002 \n","[Epoch 129/300] [Batch 70/70] [D loss: 0.020085, acc:  99%] [G loss: 4.532671, adv: 0.972664, recon: 0.109729, id: 0.169090] time: 4:43:41.499551 \n","[Epoch 130/300] [Batch 70/70] [D loss: 0.027220, acc:  99%] [G loss: 4.646104, adv: 1.027154, recon: 0.112952, id: 0.144200] time: 4:45:53.824621 \n","[Epoch 131/300] [Batch 70/70] [D loss: 0.015605, acc:  99%] [G loss: 4.961466, adv: 1.037100, recon: 0.125081, id: 0.145954] time: 4:48:05.108111 \n","[Epoch 132/300] [Batch 70/70] [D loss: 0.035086, acc:  97%] [G loss: 5.474631, adv: 1.287805, recon: 0.125482, id: 0.165571] time: 4:50:17.344775 \n","[Epoch 133/300] [Batch 70/70] [D loss: 0.010409, acc:  99%] [G loss: 4.781582, adv: 1.008443, recon: 0.117765, id: 0.197272] time: 4:52:28.546725 \n","[Epoch 134/300] [Batch 70/70] [D loss: 0.008041, acc: 100%] [G loss: 4.689444, adv: 1.001740, recon: 0.116301, id: 0.139990] time: 4:54:39.882755 \n","[Epoch 135/300] [Batch 70/70] [D loss: 0.015855, acc:  99%] [G loss: 4.780731, adv: 1.069661, recon: 0.110761, id: 0.186532] time: 4:56:51.509259 \n","[Epoch 136/300] [Batch 70/70] [D loss: 0.008739, acc:  99%] [G loss: 4.521081, adv: 1.003272, recon: 0.108347, id: 0.128657] time: 4:59:02.726366 \n","[Epoch 137/300] [Batch 70/70] [D loss: 0.006016, acc:  99%] [G loss: 4.645691, adv: 1.002665, recon: 0.113144, id: 0.159085] time: 5:01:14.853245 \n","[Epoch 138/300] [Batch 70/70] [D loss: 0.008066, acc:  99%] [G loss: 4.545697, adv: 1.016387, recon: 0.105973, id: 0.171114] time: 5:03:26.991015 \n","[Epoch 139/300] [Batch 70/70] [D loss: 0.004430, acc: 100%] [G loss: 4.770608, adv: 1.010377, recon: 0.116170, id: 0.176918] time: 5:05:38.627084 \n","[Epoch 140/300] [Batch 70/70] [D loss: 0.005052, acc: 100%] [G loss: 4.936319, adv: 1.022779, recon: 0.126507, id: 0.156898] time: 5:07:49.989590 \n","Model weights saved. combined_model\n","[Epoch 141/300] [Batch 70/70] [D loss: 0.004795, acc: 100%] [G loss: 4.605441, adv: 1.008494, recon: 0.109516, id: 0.171636] time: 5:10:03.645392 \n","[Epoch 142/300] [Batch 70/70] [D loss: 0.088088, acc:  90%] [G loss: 3.877922, adv: 0.707232, recon: 0.103946, id: 0.163371] time: 5:12:15.224970 \n","[Epoch 143/300] [Batch 70/70] [D loss: 0.082001, acc:  89%] [G loss: 4.557853, adv: 0.807873, recon: 0.124836, id: 0.178075] time: 5:14:27.451250 \n","[Epoch 144/300] [Batch 70/70] [D loss: 0.043792, acc:  97%] [G loss: 4.423240, adv: 0.884426, recon: 0.112545, id: 0.188420] time: 5:16:38.745660 \n","[Epoch 145/300] [Batch 70/70] [D loss: 0.019759, acc:  99%] [G loss: 4.559882, adv: 0.948592, recon: 0.114240, id: 0.159661] time: 5:18:49.809515 \n","[Epoch 146/300] [Batch 70/70] [D loss: 0.013313, acc:  99%] [G loss: 4.672951, adv: 0.988635, recon: 0.116052, id: 0.140379] time: 5:21:01.149134 \n","[Epoch 147/300] [Batch 70/70] [D loss: 0.014961, acc:  99%] [G loss: 4.441117, adv: 1.027288, recon: 0.101269, id: 0.122026] time: 5:23:13.278560 \n","[Epoch 148/300] [Batch 70/70] [D loss: 0.020575, acc:  99%] [G loss: 4.796581, adv: 0.977567, recon: 0.122665, id: 0.154630] time: 5:25:24.977509 \n","[Epoch 149/300] [Batch 70/70] [D loss: 0.007618, acc:  99%] [G loss: 4.711677, adv: 1.045108, recon: 0.110933, id: 0.148402] time: 5:27:36.206688 \n","[Epoch 150/300] [Batch 70/70] [D loss: 0.007743, acc: 100%] [G loss: 4.569932, adv: 1.004940, recon: 0.110218, id: 0.156678] time: 5:29:46.988929 \n","[Epoch 151/300] [Batch 70/70] [D loss: 0.007914, acc: 100%] [G loss: 4.426652, adv: 1.032520, recon: 0.099205, id: 0.139601] time: 5:31:57.658089 \n","[Epoch 152/300] [Batch 70/70] [D loss: 0.008935, acc:  99%] [G loss: 4.511207, adv: 1.010096, recon: 0.106214, id: 0.160274] time: 5:34:08.451723 \n","[Epoch 153/300] [Batch 70/70] [D loss: 0.009799, acc:  99%] [G loss: 4.759351, adv: 1.007967, recon: 0.116491, id: 0.149702] time: 5:36:19.479067 \n","[Epoch 154/300] [Batch 70/70] [D loss: 0.042933, acc:  95%] [G loss: 4.908898, adv: 1.194641, recon: 0.109080, id: 0.118683] time: 5:38:30.904969 \n","[Epoch 155/300] [Batch 70/70] [D loss: 0.006980, acc: 100%] [G loss: 4.484085, adv: 1.052845, recon: 0.100600, id: 0.150605] time: 5:40:43.250311 \n","[Epoch 156/300] [Batch 70/70] [D loss: 0.010803, acc:  99%] [G loss: 4.461864, adv: 1.053875, recon: 0.100307, id: 0.142373] time: 5:42:54.900899 \n","[Epoch 157/300] [Batch 70/70] [D loss: 0.007705, acc:  99%] [G loss: 4.587716, adv: 1.052397, recon: 0.104137, id: 0.149175] time: 5:45:05.757259 \n","[Epoch 158/300] [Batch 70/70] [D loss: 0.009719, acc: 100%] [G loss: 4.574525, adv: 1.055507, recon: 0.102656, id: 0.186106] time: 5:47:16.736677 \n","[Epoch 159/300] [Batch 70/70] [D loss: 0.007521, acc: 100%] [G loss: 4.640198, adv: 1.073532, recon: 0.104201, id: 0.165657] time: 5:49:28.565833 \n","[Epoch 160/300] [Batch 70/70] [D loss: 0.009656, acc: 100%] [G loss: 4.628953, adv: 0.984932, recon: 0.112718, id: 0.156884] time: 5:51:39.736227 \n","Model weights saved. combined_model\n","[Epoch 161/300] [Batch 70/70] [D loss: 0.010139, acc: 100%] [G loss: 4.524200, adv: 1.021629, recon: 0.105792, id: 0.139570] time: 5:53:52.686208 \n","[Epoch 162/300] [Batch 70/70] [D loss: 0.008035, acc:  99%] [G loss: 4.325321, adv: 1.022909, recon: 0.096302, id: 0.128690] time: 5:56:04.625640 \n","[Epoch 163/300] [Batch 70/70] [D loss: 0.008433, acc: 100%] [G loss: 4.721306, adv: 1.024397, recon: 0.110257, id: 0.177451] time: 5:58:15.611631 \n","[Epoch 164/300] [Batch 70/70] [D loss: 0.011910, acc: 100%] [G loss: 4.443281, adv: 0.974632, recon: 0.105397, id: 0.132856] time: 6:00:26.989431 \n","[Epoch 165/300] [Batch 70/70] [D loss: 0.004219, acc: 100%] [G loss: 4.481687, adv: 1.018709, recon: 0.103809, id: 0.154546] time: 6:02:38.733288 \n","[Epoch 166/300] [Batch 70/70] [D loss: 0.010923, acc:  99%] [G loss: 4.654412, adv: 1.071264, recon: 0.109398, id: 0.138528] time: 6:04:50.202027 \n","[Epoch 167/300] [Batch 70/70] [D loss: 0.009145, acc: 100%] [G loss: 4.505433, adv: 1.001295, recon: 0.106319, id: 0.124989] time: 6:07:01.646431 \n","[Epoch 168/300] [Batch 70/70] [D loss: 0.027736, acc:  98%] [G loss: 4.699911, adv: 1.197659, recon: 0.095754, id: 0.170187] time: 6:09:13.364363 \n","[Epoch 169/300] [Batch 70/70] [D loss: 0.015877, acc:  99%] [G loss: 4.480297, adv: 1.037759, recon: 0.102508, id: 0.157976] time: 6:11:25.136205 \n","[Epoch 170/300] [Batch 70/70] [D loss: 0.005663, acc: 100%] [G loss: 4.809915, adv: 1.012435, recon: 0.119395, id: 0.164424] time: 6:13:36.151283 \n","[Epoch 171/300] [Batch 70/70] [D loss: 0.007996, acc: 100%] [G loss: 4.632914, adv: 1.016895, recon: 0.112315, id: 0.131936] time: 6:15:47.370652 \n","[Epoch 172/300] [Batch 70/70] [D loss: 0.003501, acc: 100%] [G loss: 4.792114, adv: 1.020249, recon: 0.115284, id: 0.176684] time: 6:17:58.919774 \n","[Epoch 173/300] [Batch 70/70] [D loss: 0.003445, acc: 100%] [G loss: 4.152015, adv: 0.992024, recon: 0.091183, id: 0.152383] time: 6:20:10.334727 \n","[Epoch 174/300] [Batch 70/70] [D loss: 0.007114, acc: 100%] [G loss: 5.381385, adv: 1.026443, recon: 0.147768, id: 0.161675] time: 6:22:21.949969 \n","[Epoch 175/300] [Batch 70/70] [D loss: 0.015296, acc:  99%] [G loss: 4.675063, adv: 1.030586, recon: 0.112175, id: 0.125888] time: 6:24:33.347998 \n","[Epoch 176/300] [Batch 70/70] [D loss: 0.006647, acc: 100%] [G loss: 4.494078, adv: 1.022166, recon: 0.104522, id: 0.146376] time: 6:26:44.647949 \n","[Epoch 177/300] [Batch 70/70] [D loss: 0.003391, acc: 100%] [G loss: 4.364414, adv: 0.992638, recon: 0.099207, id: 0.138193] time: 6:28:55.598571 \n","[Epoch 178/300] [Batch 70/70] [D loss: 0.005018, acc: 100%] [G loss: 4.472781, adv: 1.015887, recon: 0.102483, id: 0.173087] time: 6:31:06.768517 \n","[Epoch 179/300] [Batch 70/70] [D loss: 0.015027, acc:  99%] [G loss: 4.399522, adv: 1.005580, recon: 0.101142, id: 0.159520] time: 6:33:18.113277 \n","[Epoch 180/300] [Batch 70/70] [D loss: 0.009704, acc: 100%] [G loss: 4.368359, adv: 1.031033, recon: 0.096443, id: 0.143675] time: 6:35:29.197173 \n","Model weights saved. combined_model\n","[Epoch 181/300] [Batch 70/70] [D loss: 0.106761, acc:  86%] [G loss: 3.866161, adv: 0.765753, recon: 0.098710, id: 0.146151] time: 6:37:43.777798 \n","[Epoch 182/300] [Batch 70/70] [D loss: 0.055708, acc:  93%] [G loss: 3.926325, adv: 0.866665, recon: 0.090842, id: 0.144316] time: 6:39:54.966944 \n","[Epoch 183/300] [Batch 70/70] [D loss: 0.044337, acc:  93%] [G loss: 4.318375, adv: 0.949661, recon: 0.102881, id: 0.141485] time: 6:42:06.613627 \n","[Epoch 184/300] [Batch 70/70] [D loss: 0.014748, acc:  99%] [G loss: 4.622685, adv: 1.044639, recon: 0.108365, id: 0.123559] time: 6:44:17.672491 \n","[Epoch 185/300] [Batch 70/70] [D loss: 0.010034, acc:  99%] [G loss: 4.607921, adv: 1.016413, recon: 0.109697, id: 0.162609] time: 6:46:28.875848 \n","[Epoch 186/300] [Batch 70/70] [D loss: 0.012979, acc:  99%] [G loss: 4.960968, adv: 0.982265, recon: 0.129631, id: 0.150850] time: 6:48:40.324795 \n","[Epoch 187/300] [Batch 70/70] [D loss: 0.011084, acc:  99%] [G loss: 4.373717, adv: 0.959501, recon: 0.103152, id: 0.154457] time: 6:50:51.503494 \n","[Epoch 188/300] [Batch 70/70] [D loss: 0.009754, acc:  99%] [G loss: 4.122679, adv: 0.966836, recon: 0.092498, id: 0.134075] time: 6:53:03.355249 \n","[Epoch 189/300] [Batch 70/70] [D loss: 0.002994, acc: 100%] [G loss: 4.387518, adv: 1.032996, recon: 0.096902, id: 0.122597] time: 6:55:15.387025 \n","[Epoch 190/300] [Batch 70/70] [D loss: 0.004952, acc: 100%] [G loss: 4.439809, adv: 1.008988, recon: 0.101441, id: 0.169152] time: 6:57:26.828044 \n","[Epoch 191/300] [Batch 70/70] [D loss: 0.003058, acc: 100%] [G loss: 4.338327, adv: 1.009595, recon: 0.098383, id: 0.134606] time: 6:59:38.258912 \n","[Epoch 192/300] [Batch 70/70] [D loss: 0.004414, acc: 100%] [G loss: 4.300788, adv: 1.001402, recon: 0.097289, id: 0.125980] time: 7:01:50.014968 \n","[Epoch 193/300] [Batch 70/70] [D loss: 0.002245, acc: 100%] [G loss: 4.403930, adv: 1.013844, recon: 0.101355, id: 0.150579] time: 7:04:01.294752 \n","[Epoch 194/300] [Batch 70/70] [D loss: 0.003780, acc: 100%] [G loss: 4.407451, adv: 1.011699, recon: 0.105142, id: 0.116317] time: 7:06:12.480698 \n","[Epoch 195/300] [Batch 70/70] [D loss: 0.003463, acc: 100%] [G loss: 4.312442, adv: 0.998751, recon: 0.096883, id: 0.167135] time: 7:08:24.302322 \n","[Epoch 196/300] [Batch 70/70] [D loss: 0.002997, acc: 100%] [G loss: 5.155202, adv: 1.019876, recon: 0.130156, id: 0.190157] time: 7:10:35.563742 \n","[Epoch 197/300] [Batch 70/70] [D loss: 0.003532, acc: 100%] [G loss: 4.713991, adv: 0.997802, recon: 0.115980, id: 0.150016] time: 7:12:48.228856 \n","[Epoch 198/300] [Batch 70/70] [D loss: 0.002041, acc: 100%] [G loss: 4.358083, adv: 1.012464, recon: 0.096474, id: 0.155065] time: 7:14:59.914561 \n","[Epoch 199/300] [Batch 70/70] [D loss: 0.002396, acc: 100%] [G loss: 4.341645, adv: 0.988913, recon: 0.101703, id: 0.135660] time: 7:17:12.083387 \n","[Epoch 200/300] [Batch 70/70] [D loss: 0.005999, acc:  99%] [G loss: 4.232288, adv: 1.005576, recon: 0.093113, id: 0.151041] time: 7:19:23.542597 \n","Model weights saved. combined_model\n","[Epoch 201/300] [Batch 70/70] [D loss: 0.003124, acc: 100%] [G loss: 4.516083, adv: 1.029994, recon: 0.100680, id: 0.175315] time: 7:21:36.915535 \n","[Epoch 202/300] [Batch 70/70] [D loss: 0.002523, acc: 100%] [G loss: 4.381966, adv: 0.998051, recon: 0.101055, id: 0.156976] time: 7:23:48.765019 \n","[Epoch 203/300] [Batch 70/70] [D loss: 0.003618, acc: 100%] [G loss: 4.148572, adv: 1.014488, recon: 0.087011, id: 0.172214] time: 7:26:00.124243 \n","[Epoch 204/300] [Batch 70/70] [D loss: 0.001851, acc: 100%] [G loss: 4.273705, adv: 1.001281, recon: 0.096718, id: 0.121106] time: 7:28:11.567020 \n","[Epoch 205/300] [Batch 70/70] [D loss: 0.083410, acc:  90%] [G loss: 3.605733, adv: 0.758326, recon: 0.086375, id: 0.155354] time: 7:30:23.606634 \n","[Epoch 206/300] [Batch 70/70] [D loss: 0.085649, acc:  87%] [G loss: 3.846920, adv: 0.834033, recon: 0.089921, id: 0.144050] time: 7:32:35.358168 \n","[Epoch 207/300] [Batch 70/70] [D loss: 0.017850, acc:  99%] [G loss: 4.443595, adv: 0.999762, recon: 0.103172, id: 0.145897] time: 7:34:46.577650 \n","[Epoch 208/300] [Batch 70/70] [D loss: 0.009567, acc: 100%] [G loss: 4.467863, adv: 0.972985, recon: 0.106794, id: 0.142494] time: 7:36:58.691414 \n","[Epoch 209/300] [Batch 70/70] [D loss: 0.014805, acc:  99%] [G loss: 4.253299, adv: 1.007387, recon: 0.094534, id: 0.124171] time: 7:39:10.010759 \n","[Epoch 210/300] [Batch 70/70] [D loss: 0.009174, acc:  99%] [G loss: 4.385252, adv: 1.011055, recon: 0.100987, id: 0.151030] time: 7:41:22.551902 \n","[Epoch 211/300] [Batch 70/70] [D loss: 0.005649, acc: 100%] [G loss: 4.133070, adv: 0.972142, recon: 0.094537, id: 0.111110] time: 7:43:34.440663 \n","[Epoch 212/300] [Batch 70/70] [D loss: 0.005630, acc: 100%] [G loss: 4.406459, adv: 1.021145, recon: 0.098437, id: 0.172443] time: 7:45:45.914900 \n","[Epoch 213/300] [Batch 70/70] [D loss: 0.009910, acc: 100%] [G loss: 4.338636, adv: 1.014578, recon: 0.097681, id: 0.146634] time: 7:47:57.845226 \n","[Epoch 214/300] [Batch 70/70] [D loss: 0.008882, acc: 100%] [G loss: 4.182706, adv: 1.039332, recon: 0.089911, id: 0.111552] time: 7:50:09.126415 \n","[Epoch 215/300] [Batch 70/70] [D loss: 0.004805, acc: 100%] [G loss: 4.217054, adv: 1.025839, recon: 0.090033, id: 0.129658] time: 7:52:20.644236 \n","[Epoch 216/300] [Batch 70/70] [D loss: 0.004442, acc: 100%] [G loss: 4.314359, adv: 1.038810, recon: 0.091848, id: 0.169073] time: 7:54:32.152870 \n","[Epoch 217/300] [Batch 70/70] [D loss: 0.007971, acc:  99%] [G loss: 4.336820, adv: 1.013345, recon: 0.097552, id: 0.122234] time: 7:56:43.198381 \n","[Epoch 218/300] [Batch 70/70] [D loss: 0.008971, acc: 100%] [G loss: 4.581983, adv: 1.066125, recon: 0.103254, id: 0.129021] time: 7:58:54.429055 \n","[Epoch 219/300] [Batch 70/70] [D loss: 0.008315, acc: 100%] [G loss: 4.430751, adv: 1.013815, recon: 0.102218, id: 0.153959] time: 8:01:05.911613 \n","[Epoch 220/300] [Batch 70/70] [D loss: 0.004962, acc: 100%] [G loss: 4.121315, adv: 1.015646, recon: 0.087602, id: 0.144492] time: 8:03:17.853843 \n","Model weights saved. combined_model\n","[Epoch 221/300] [Batch 70/70] [D loss: 0.005455, acc: 100%] [G loss: 4.280910, adv: 1.019600, recon: 0.094683, id: 0.132532] time: 8:05:31.757772 \n","[Epoch 222/300] [Batch 70/70] [D loss: 0.004018, acc: 100%] [G loss: 4.299885, adv: 1.014772, recon: 0.094904, id: 0.143526] time: 8:07:43.154510 \n","[Epoch 223/300] [Batch 70/70] [D loss: 0.005225, acc: 100%] [G loss: 4.210901, adv: 0.989066, recon: 0.092962, id: 0.147824] time: 8:09:54.538045 \n","[Epoch 224/300] [Batch 70/70] [D loss: 0.003098, acc: 100%] [G loss: 4.423308, adv: 1.004422, recon: 0.102286, id: 0.148141] time: 8:12:06.461606 \n","[Epoch 225/300] [Batch 70/70] [D loss: 0.002764, acc: 100%] [G loss: 4.195678, adv: 1.007021, recon: 0.091553, id: 0.135640] time: 8:14:17.764756 \n","[Epoch 226/300] [Batch 70/70] [D loss: 0.003919, acc: 100%] [G loss: 4.247670, adv: 1.013964, recon: 0.092887, id: 0.128792] time: 8:16:29.069990 \n","[Epoch 227/300] [Batch 70/70] [D loss: 0.003739, acc: 100%] [G loss: 4.290888, adv: 0.993983, recon: 0.097662, id: 0.146193] time: 8:18:40.517542 \n","[Epoch 228/300] [Batch 70/70] [D loss: 0.004377, acc: 100%] [G loss: 4.329463, adv: 0.982733, recon: 0.099280, id: 0.145323] time: 8:20:52.172851 \n","[Epoch 229/300] [Batch 70/70] [D loss: 0.047414, acc:  95%] [G loss: 4.422856, adv: 1.120185, recon: 0.092719, id: 0.104501] time: 8:23:03.506387 \n","[Epoch 230/300] [Batch 70/70] [D loss: 0.004125, acc: 100%] [G loss: 4.327178, adv: 1.019740, recon: 0.097986, id: 0.129571] time: 8:25:14.975072 \n","[Epoch 231/300] [Batch 70/70] [D loss: 0.005031, acc: 100%] [G loss: 4.093635, adv: 1.007652, recon: 0.088131, id: 0.126919] time: 8:27:27.185944 \n","[Epoch 232/300] [Batch 70/70] [D loss: 0.003745, acc: 100%] [G loss: 4.337574, adv: 1.044565, recon: 0.095639, id: 0.138239] time: 8:29:38.484082 \n","[Epoch 233/300] [Batch 70/70] [D loss: 0.006733, acc:  99%] [G loss: 4.163404, adv: 1.012190, recon: 0.091686, id: 0.116448] time: 8:31:49.565085 \n","[Epoch 234/300] [Batch 70/70] [D loss: 0.003856, acc: 100%] [G loss: 4.167380, adv: 1.027098, recon: 0.086985, id: 0.105834] time: 8:34:01.177589 \n","[Epoch 235/300] [Batch 70/70] [D loss: 0.043385, acc:  95%] [G loss: 4.275343, adv: 1.126967, recon: 0.087167, id: 0.109444] time: 8:36:12.299021 \n","[Epoch 236/300] [Batch 70/70] [D loss: 0.003551, acc: 100%] [G loss: 4.277487, adv: 1.006260, recon: 0.095603, id: 0.144097] time: 8:38:23.696134 \n","[Epoch 237/300] [Batch 70/70] [D loss: 0.002053, acc: 100%] [G loss: 4.210670, adv: 1.016383, recon: 0.090018, id: 0.109888] time: 8:40:35.331250 \n","[Epoch 238/300] [Batch 70/70] [D loss: 0.002522, acc: 100%] [G loss: 4.398778, adv: 1.007081, recon: 0.104296, id: 0.093892] time: 8:42:46.463954 \n","[Epoch 239/300] [Batch 70/70] [D loss: 0.007008, acc: 100%] [G loss: 4.081328, adv: 1.003844, recon: 0.088401, id: 0.106967] time: 8:44:57.703957 \n","[Epoch 240/300] [Batch 70/70] [D loss: 0.006777, acc: 100%] [G loss: 4.278958, adv: 1.017113, recon: 0.093377, id: 0.154329] time: 8:47:08.676857 \n","Model weights saved. combined_model\n","[Epoch 241/300] [Batch 70/70] [D loss: 0.127293, acc:  81%] [G loss: 3.639894, adv: 0.714256, recon: 0.092661, id: 0.146756] time: 8:49:21.867576 \n","[Epoch 242/300] [Batch 70/70] [D loss: 0.053500, acc:  93%] [G loss: 3.769087, adv: 0.817842, recon: 0.089972, id: 0.119669] time: 8:51:34.648690 \n","[Epoch 243/300] [Batch 70/70] [D loss: 0.037049, acc:  94%] [G loss: 4.437968, adv: 0.915998, recon: 0.111801, id: 0.128705] time: 8:53:46.304140 \n","[Epoch 244/300] [Batch 70/70] [D loss: 0.019338, acc:  97%] [G loss: 4.106888, adv: 0.968703, recon: 0.089639, id: 0.133313] time: 8:55:57.493324 \n","[Epoch 245/300] [Batch 70/70] [D loss: 0.007324, acc:  99%] [G loss: 4.283743, adv: 1.024501, recon: 0.094797, id: 0.139434] time: 8:58:08.962565 \n","[Epoch 246/300] [Batch 70/70] [D loss: 0.004582, acc: 100%] [G loss: 4.444444, adv: 1.009973, recon: 0.102337, id: 0.129814] time: 9:00:21.320209 \n","[Epoch 247/300] [Batch 70/70] [D loss: 0.021841, acc:  97%] [G loss: 4.300565, adv: 1.006891, recon: 0.095092, id: 0.168260] time: 9:02:32.714398 \n","[Epoch 248/300] [Batch 70/70] [D loss: 0.008867, acc: 100%] [G loss: 4.814816, adv: 1.054191, recon: 0.116186, id: 0.184316] time: 9:04:43.832241 \n","[Epoch 249/300] [Batch 70/70] [D loss: 0.003372, acc: 100%] [G loss: 4.281022, adv: 1.017229, recon: 0.095315, id: 0.129748] time: 9:06:55.732799 \n","[Epoch 250/300] [Batch 70/70] [D loss: 0.004258, acc: 100%] [G loss: 4.356788, adv: 1.026110, recon: 0.097365, id: 0.126673] time: 9:09:07.873073 \n","[Epoch 251/300] [Batch 70/70] [D loss: 0.090943, acc:  86%] [G loss: 3.910162, adv: 0.765825, recon: 0.102834, id: 0.131956] time: 9:11:18.901401 \n","[Epoch 252/300] [Batch 70/70] [D loss: 0.084878, acc:  87%] [G loss: 3.710047, adv: 0.791227, recon: 0.090317, id: 0.116575] time: 9:13:29.768301 \n","[Epoch 253/300] [Batch 70/70] [D loss: 0.039281, acc:  98%] [G loss: 4.159098, adv: 0.898190, recon: 0.101855, id: 0.105093] time: 9:15:40.860663 \n","[Epoch 254/300] [Batch 70/70] [D loss: 0.016060, acc:  99%] [G loss: 4.170289, adv: 0.985497, recon: 0.093036, id: 0.133167] time: 9:17:52.171956 \n","[Epoch 255/300] [Batch 70/70] [D loss: 0.012681, acc:  99%] [G loss: 4.298551, adv: 1.003280, recon: 0.097721, id: 0.124209] time: 9:20:03.413598 \n","[Epoch 256/300] [Batch 70/70] [D loss: 0.008440, acc: 100%] [G loss: 4.207644, adv: 0.974849, recon: 0.095948, id: 0.143154] time: 9:22:14.816260 \n","[Epoch 257/300] [Batch 70/70] [D loss: 0.012756, acc:  99%] [G loss: 4.531797, adv: 1.074763, recon: 0.101630, id: 0.128891] time: 9:24:25.785134 \n","[Epoch 258/300] [Batch 70/70] [D loss: 0.007606, acc: 100%] [G loss: 4.472573, adv: 1.053051, recon: 0.100302, id: 0.137781] time: 9:26:36.997895 \n","[Epoch 259/300] [Batch 70/70] [D loss: 0.025897, acc:  96%] [G loss: 4.308993, adv: 0.988213, recon: 0.100385, id: 0.118860] time: 9:28:48.203586 \n","[Epoch 260/300] [Batch 70/70] [D loss: 0.006363, acc: 100%] [G loss: 4.244530, adv: 1.004241, recon: 0.095880, id: 0.124340] time: 9:30:59.581935 \n","Model weights saved. combined_model\n","[Epoch 261/300] [Batch 70/70] [D loss: 0.005558, acc: 100%] [G loss: 4.390944, adv: 1.001160, recon: 0.101233, id: 0.144971] time: 9:33:12.914115 \n","[Epoch 262/300] [Batch 70/70] [D loss: 0.010829, acc:  99%] [G loss: 4.201830, adv: 0.997461, recon: 0.094317, id: 0.116951] time: 9:35:24.129165 \n","[Epoch 263/300] [Batch 70/70] [D loss: 0.004781, acc: 100%] [G loss: 4.201424, adv: 0.982286, recon: 0.094183, id: 0.132939] time: 9:37:35.440701 \n","[Epoch 264/300] [Batch 70/70] [D loss: 0.008198, acc:  99%] [G loss: 4.189781, adv: 0.973874, recon: 0.094339, id: 0.160472] time: 9:39:46.902731 \n","[Epoch 265/300] [Batch 70/70] [D loss: 0.005884, acc: 100%] [G loss: 4.106503, adv: 1.009398, recon: 0.087648, id: 0.135597] time: 9:41:58.568075 \n","[Epoch 266/300] [Batch 70/70] [D loss: 0.006306, acc:  99%] [G loss: 4.307866, adv: 1.044578, recon: 0.094422, id: 0.119995] time: 9:44:10.111557 \n","[Epoch 267/300] [Batch 70/70] [D loss: 0.003197, acc: 100%] [G loss: 4.195831, adv: 1.017557, recon: 0.089658, id: 0.147813] time: 9:46:21.466668 \n","[Epoch 268/300] [Batch 70/70] [D loss: 0.003942, acc: 100%] [G loss: 4.483119, adv: 1.026529, recon: 0.100857, id: 0.175737] time: 9:48:33.585143 \n","[Epoch 269/300] [Batch 70/70] [D loss: 0.006428, acc:  99%] [G loss: 4.463018, adv: 1.090203, recon: 0.096226, id: 0.141031] time: 9:50:44.549122 \n","[Epoch 270/300] [Batch 70/70] [D loss: 0.003703, acc: 100%] [G loss: 4.277968, adv: 1.049034, recon: 0.092435, id: 0.136985] time: 9:52:55.580704 \n","[Epoch 271/300] [Batch 70/70] [D loss: 0.009187, acc: 100%] [G loss: 4.079422, adv: 0.964265, recon: 0.090006, id: 0.148731] time: 9:55:06.890207 \n","[Epoch 272/300] [Batch 70/70] [D loss: 0.003408, acc: 100%] [G loss: 4.066438, adv: 1.035300, recon: 0.083427, id: 0.131613] time: 9:57:18.262805 \n","[Epoch 273/300] [Batch 70/70] [D loss: 0.002699, acc: 100%] [G loss: 4.405871, adv: 1.009519, recon: 0.101010, id: 0.177666] time: 9:59:29.684568 \n","[Epoch 274/300] [Batch 70/70] [D loss: 0.042907, acc:  98%] [G loss: 4.404673, adv: 1.111253, recon: 0.091791, id: 0.145827] time: 10:01:42.007785 \n","[Epoch 275/300] [Batch 70/70] [D loss: 0.006780, acc: 100%] [G loss: 4.137059, adv: 1.032724, recon: 0.088617, id: 0.100926] time: 10:03:53.684015 \n","[Epoch 276/300] [Batch 70/70] [D loss: 0.005286, acc: 100%] [G loss: 4.384956, adv: 1.049289, recon: 0.096381, id: 0.159031] time: 10:06:05.591129 \n","[Epoch 277/300] [Batch 70/70] [D loss: 0.003525, acc: 100%] [G loss: 4.113222, adv: 0.996517, recon: 0.088320, id: 0.158131] time: 10:08:17.742629 \n","[Epoch 278/300] [Batch 70/70] [D loss: 0.014242, acc:  99%] [G loss: 4.462980, adv: 1.129262, recon: 0.093084, id: 0.122958] time: 10:10:31.419654 \n","[Epoch 279/300] [Batch 70/70] [D loss: 0.005237, acc: 100%] [G loss: 4.518705, adv: 1.000445, recon: 0.106184, id: 0.151464] time: 10:12:43.599472 \n","[Epoch 280/300] [Batch 70/70] [D loss: 0.002831, acc: 100%] [G loss: 3.963865, adv: 1.013051, recon: 0.080519, id: 0.103887] time: 10:14:55.732185 \n","Model weights saved. combined_model\n","[Epoch 281/300] [Batch 70/70] [D loss: 0.002625, acc: 100%] [G loss: 3.928204, adv: 0.998790, recon: 0.081607, id: 0.106910] time: 10:17:10.038700 \n","[Epoch 282/300] [Batch 70/70] [D loss: 0.003202, acc: 100%] [G loss: 4.240901, adv: 1.015198, recon: 0.094181, id: 0.135294] time: 10:19:22.469379 \n","[Epoch 283/300] [Batch 70/70] [D loss: 0.002122, acc: 100%] [G loss: 4.042286, adv: 1.005569, recon: 0.081949, id: 0.149647] time: 10:21:34.781322 \n","[Epoch 284/300] [Batch 70/70] [D loss: 0.003801, acc: 100%] [G loss: 4.027446, adv: 0.991022, recon: 0.087003, id: 0.091966] time: 10:23:47.203213 \n","[Epoch 285/300] [Batch 70/70] [D loss: 0.005208, acc: 100%] [G loss: 4.606692, adv: 1.023169, recon: 0.105928, id: 0.190499] time: 10:25:59.585140 \n","[Epoch 286/300] [Batch 70/70] [D loss: 0.017989, acc:  99%] [G loss: 4.041358, adv: 1.004155, recon: 0.085054, id: 0.134976] time: 10:28:12.976618 \n","[Epoch 287/300] [Batch 70/70] [D loss: 0.005689, acc: 100%] [G loss: 3.999810, adv: 0.985392, recon: 0.086502, id: 0.107529] time: 10:30:25.289653 \n","[Epoch 288/300] [Batch 70/70] [D loss: 0.003745, acc: 100%] [G loss: 4.008796, adv: 1.017573, recon: 0.083587, id: 0.093579] time: 10:32:37.417426 \n","[Epoch 289/300] [Batch 70/70] [D loss: 0.003366, acc: 100%] [G loss: 3.995454, adv: 1.023918, recon: 0.082833, id: 0.091291] time: 10:34:49.846509 \n","[Epoch 290/300] [Batch 70/70] [D loss: 0.002992, acc: 100%] [G loss: 4.355021, adv: 0.992809, recon: 0.100290, id: 0.168024] time: 10:37:01.939500 \n","[Epoch 291/300] [Batch 70/70] [D loss: 0.004922, acc: 100%] [G loss: 4.204371, adv: 1.016715, recon: 0.089442, id: 0.153439] time: 10:39:14.041451 \n","[Epoch 292/300] [Batch 70/70] [D loss: 0.023222, acc:  98%] [G loss: 4.160204, adv: 1.054810, recon: 0.085403, id: 0.138085] time: 10:41:26.043079 \n","[Epoch 293/300] [Batch 70/70] [D loss: 0.005790, acc: 100%] [G loss: 4.138835, adv: 1.057444, recon: 0.087290, id: 0.096258] time: 10:43:37.628955 \n","[Epoch 294/300] [Batch 70/70] [D loss: 0.004014, acc: 100%] [G loss: 3.884192, adv: 0.976387, recon: 0.082486, id: 0.102377] time: 10:45:48.976888 \n","[Epoch 295/300] [Batch 70/70] [D loss: 0.003426, acc: 100%] [G loss: 3.973867, adv: 1.024618, recon: 0.082215, id: 0.099396] time: 10:48:00.573432 \n","[Epoch 296/300] [Batch 70/70] [D loss: 0.010695, acc:  98%] [G loss: 4.017795, adv: 0.987723, recon: 0.085571, id: 0.092318] time: 10:50:12.234486 \n","[Epoch 297/300] [Batch 70/70] [D loss: 0.004615, acc: 100%] [G loss: 4.284115, adv: 1.048877, recon: 0.090343, id: 0.167646] time: 10:52:23.777134 \n","[Epoch 298/300] [Batch 70/70] [D loss: 0.029640, acc:  96%] [G loss: 4.425438, adv: 1.020591, recon: 0.098901, id: 0.201048] time: 10:54:36.333783 \n","[Epoch 299/300] [Batch 70/70] [D loss: 0.017266, acc:  99%] [G loss: 4.300198, adv: 1.107848, recon: 0.088484, id: 0.116823] time: 10:56:48.227573 \n","[Epoch 300/300] [Batch 70/70] [D loss: 0.002023, acc: 100%] [G loss: 4.020653, adv: 1.023371, recon: 0.086015, id: 0.100494] time: 10:58:59.377899 \n","Model weights saved. combined_model\n","2020-08-16T16:27:58.222241 End\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"mpntQ1Pxvfy7","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}