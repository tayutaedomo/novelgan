{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"15_vangogh_img1.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"18QSpnhe52yfAJSe6Q-KWp8oGZR41AV5O","authorship_tag":"ABX9TyPHpyc/XDq0xg51JM3BA1qu"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"UxqZT229H44v","colab_type":"text"},"source":["### vangogh2novel モデル作成、保存\n","trainA を画像1枚にして学習を実行する"]},{"cell_type":"code","metadata":{"id":"OquHoSSzGVBE","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":350},"executionInfo":{"status":"ok","timestamp":1597713356954,"user_tz":-540,"elapsed":3876,"user":{"displayName":"Noboru Koike","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggp8njUb4jc54JrzfM5cQBkfiCdlz6nY17y8-1szg=s64","userId":"05156582812995850159"}},"outputId":"2ff7171d-d9af-4504-aa5c-13ea7546bc3c"},"source":["!nvidia-smi"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Tue Aug 18 01:15:54 2020       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 450.57       Driver Version: 418.67       CUDA Version: 10.1     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   40C    P0    27W / 250W |      0MiB / 16280MiB |      0%      Default |\n","|                               |                      |                 ERR! |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"7dxxo4o8IFLM","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597713361114,"user_tz":-540,"elapsed":2458,"user":{"displayName":"Noboru Koike","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggp8njUb4jc54JrzfM5cQBkfiCdlz6nY17y8-1szg=s64","userId":"05156582812995850159"}}},"source":["from tensorflow_addons.layers import InstanceNormalization\n","from tensorflow.keras.layers import Input, Dropout, Concatenate\n","from tensorflow.keras.layers import LeakyReLU\n","from tensorflow.keras.layers import UpSampling2D, Conv2D\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.optimizers import Adam"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"tJ0seoYcIHk8","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597713362392,"user_tz":-540,"elapsed":676,"user":{"displayName":"Noboru Koike","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggp8njUb4jc54JrzfM5cQBkfiCdlz6nY17y8-1szg=s64","userId":"05156582812995850159"}}},"source":["import matplotlib.pyplot as plt\n","import numpy as np\n","import pandas as pd\n","import datetime\n","import os"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"0UoP6USwIJic","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597713364832,"user_tz":-540,"elapsed":1552,"user":{"displayName":"Noboru Koike","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggp8njUb4jc54JrzfM5cQBkfiCdlz6nY17y8-1szg=s64","userId":"05156582812995850159"}}},"source":["from glob import glob\n","import cv2\n","from matplotlib.pyplot import imread"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"8X1cVXVZILc_","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597713366122,"user_tz":-540,"elapsed":641,"user":{"displayName":"Noboru Koike","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggp8njUb4jc54JrzfM5cQBkfiCdlz6nY17y8-1szg=s64","userId":"05156582812995850159"}}},"source":["DATA_DIR_PATH = '/content/drive/My Drive/kikagaku/novelgan/data'\n","\n","OUTPUT_DIR_PATH = os.path.join(DATA_DIR_PATH, '15_out')"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"Zg5-CvCYIOKH","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597713368295,"user_tz":-540,"elapsed":1301,"user":{"displayName":"Noboru Koike","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggp8njUb4jc54JrzfM5cQBkfiCdlz6nY17y8-1szg=s64","userId":"05156582812995850159"}}},"source":["#os.makedirs(os.path.join(DATA_DIR_PATH, 'datasets'), exist_ok=True)\n","\n","os.makedirs(os.path.join(OUTPUT_DIR_PATH, 'images'), exist_ok=True)\n","os.makedirs(os.path.join(OUTPUT_DIR_PATH, 'saved_models'), exist_ok=True)"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"AcdUhck_IQOU","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597713372601,"user_tz":-540,"elapsed":817,"user":{"displayName":"Noboru Koike","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggp8njUb4jc54JrzfM5cQBkfiCdlz6nY17y8-1szg=s64","userId":"05156582812995850159"}}},"source":["class DataLoader():\n","    def __init__(self, dataset_name, img_res=(256, 256)):\n","        self.dataset_name = dataset_name\n","        self.img_res = img_res\n","        self.datasets_path = os.path.join(DATA_DIR_PATH, 'datasets')\n","\n","    def load_data(self, domain, batch_size=1, is_testing=False):\n","        data_type = \"train%s\" % domain if not is_testing else \"test%s\" % domain\n","        #path = glob('./datasets/%s/%s/*' % (self.dataset_name, data_type))\n","        path = glob(os.path.join(self.datasets_path, self.dataset_name, data_type, '*'))\n","\n","        batch_images = np.random.choice(path, size=batch_size)\n","\n","        imgs = []\n","        for img_path in batch_images:\n","            img = self.imread(img_path)\n","            if not is_testing:\n","                #img = scipy.misc.imresize(img, self.img_res)\n","                img = cv2.resize(img, self.img_res)\n","\n","                if np.random.random() > 0.5:\n","                    img = np.fliplr(img)\n","            else:\n","                #img = scipy.misc.imresize(img, self.img_res)\n","                img = cv2.resize(img, self.img_res)\n","            imgs.append(img)\n","\n","        imgs = np.array(imgs)/127.5 - 1.\n","\n","        return imgs\n","\n","    def load_batch(self, batch_size=1, is_testing=False):\n","        data_type = \"train\" if not is_testing else \"val\"\n","        #path_A = glob('./datasets/%s/%sA/*' % (self.dataset_name, data_type))\n","        #path_B = glob('./datasets/%s/%sB/*' % (self.dataset_name, data_type))\n","        path_A = glob(os.path.join(self.datasets_path, self.dataset_name, '{}A'.format(data_type), '*'))\n","        path_B = glob(os.path.join(self.datasets_path, self.dataset_name, '{}B'.format(data_type), '*'))\n","\n","        self.n_batches = int(min(len(path_A), len(path_B)) / batch_size)\n","        total_samples = self.n_batches * batch_size\n","\n","        # Sample n_batches * batch_size from each path list so that model sees all\n","        # samples from both domains\n","        path_A = np.random.choice(path_A, total_samples, replace=False)\n","        path_B = np.random.choice(path_B, total_samples, replace=False)\n","\n","        #for i in range(self.n_batches-1):\n","        for i in range(self.n_batches):\n","            batch_A = path_A[i*batch_size:(i+1)*batch_size]\n","            batch_B = path_B[i*batch_size:(i+1)*batch_size]\n","            imgs_A, imgs_B = [], []\n","\n","            for img_A, img_B in zip(batch_A, batch_B):\n","                img_A = self.imread(img_A)\n","                img_B = self.imread(img_B)\n","\n","                #img_A = scipy.misc.imresize(img_A, self.img_res)\n","                img_A = cv2.resize(img_A, self.img_res)\n","                #img_B = scipy.misc.imresize(img_B, self.img_res)\n","                img_B = cv2.resize(img_B, self.img_res)\n","\n","                if not is_testing and np.random.random() > 0.5:\n","                    img_A = np.fliplr(img_A)\n","                    img_B = np.fliplr(img_B)\n","\n","                imgs_A.append(img_A)\n","                imgs_B.append(img_B)\n","\n","            imgs_A = np.array(imgs_A)/127.5 - 1.\n","            imgs_B = np.array(imgs_B)/127.5 - 1.\n","\n","            yield imgs_A, imgs_B\n","\n","    def load_img(self, path):\n","        img = self.imread(path)\n","        #img = scipy.misc.imresize(img, self.img_res)\n","        img = cv2.resize(img, self.img_res)\n","        img = img/127.5 - 1.\n","        return img[np.newaxis, :, :, :]\n","\n","    def imread(self, path):\n","        #return scipy.misc.imread(path, mode='RGB').astype(np.float)\n","        return imread(path).astype(np.float)"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"jE1BiGQqIR3b","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597713373927,"user_tz":-540,"elapsed":458,"user":{"displayName":"Noboru Koike","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggp8njUb4jc54JrzfM5cQBkfiCdlz6nY17y8-1szg=s64","userId":"05156582812995850159"}}},"source":["IMG_ROWS = 256\n","IMG_COLS = 256\n","\n","data_loader = DataLoader('vangogh2novel_2', img_res=(IMG_ROWS, IMG_COLS))"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"PAqis8M3IUly","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597713377220,"user_tz":-540,"elapsed":2387,"user":{"displayName":"Noboru Koike","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggp8njUb4jc54JrzfM5cQBkfiCdlz6nY17y8-1szg=s64","userId":"05156582812995850159"}}},"source":["class CycleGAN:\n","    def __init__(self):\n","        self.history = pd.DataFrame({}, columns=[\n","            'epoch', 'epochs', 'batch_idx', 'batch_num', 'd_loss', 'acc', 'g_loss',\n","            'adv', 'recon', 'id', 'elapsed_time'])\n","\n","        self.img_save_dir = os.path.join(OUTPUT_DIR_PATH, 'images')\n","        self.model_save_dir = os.path.join(OUTPUT_DIR_PATH, 'saved_models')\n","        self.combined_name = 'combined_model'\n","        self.g_AB_name = 'g_AB_model'\n","        self.g_BA_name = 'g_BA_model'\n","\n","        self.train_cnt = 0\n","\n","        # Input shape\n","        self.img_rows = IMG_ROWS\n","        self.img_cols = IMG_COLS\n","        self.channels = 3\n","        self.img_shape = (self.img_rows, self.img_cols, self.channels)\n","\n","        self.d_A = None\n","        self.d_B = None\n","        self.g_AB = None\n","        self.g_BA = None\n","        self.combined = None\n","\n","    def init(self, data_loader=None):\n","        # Configure data loader\n","        #self.dataset_name = 'apple2orange'\n","        #self.data_loader = DataLoader(dataset_name=self.dataset_name,\n","        #                              img_res=(self.img_rows, self.img_cols))\n","        if data_loader:\n","            self.data_loader = data_loader\n","            self.dataset_name = self.data_loader.dataset_name \n","\n","        # Calculate output shape of D (PatchGAN)\n","        patch = int(self.img_rows / 2**4)\n","        self.disc_patch = (patch, patch, 1)\n","\n","        # Number of filters in the first layer of G and D\n","        #self.gf = 32 # U-Net, 128\n","        self.gf = 64\n","        self.df = 64\n","\n","        # Loss weights\n","        self.lambda_cycle = 10.0                    # Cycle-consistency loss\n","        self.lambda_id = 0.1 * self.lambda_cycle    # Identity loss\n","\n","        optimizer = Adam(0.0002, 0.5)\n","\n","        # Build and compile the discriminators\n","        self.d_A = self.build_discriminator()\n","        self.d_B = self.build_discriminator()\n","        self.d_A.compile(loss='mse',\n","                         optimizer=optimizer,\n","                         metrics=['accuracy'])\n","        self.d_B.compile(loss='mse',\n","                         optimizer=optimizer,\n","                         metrics=['accuracy'])\n","\n","        # Build the generators\n","        self.g_AB = self.build_generator()\n","        self.g_BA = self.build_generator()\n","\n","        # Input images from both domains\n","        img_A = Input(shape=self.img_shape)\n","        img_B = Input(shape=self.img_shape)\n","\n","        # Translate images to the other domain\n","        fake_B = self.g_AB(img_A)\n","        fake_A = self.g_BA(img_B)\n","\n","        # Translate images back to original domain\n","        reconstr_A = self.g_BA(fake_B)\n","        reconstr_B = self.g_AB(fake_A)\n","\n","        # Identity mapping of images\n","        img_A_id = self.g_BA(img_A)\n","        img_B_id = self.g_AB(img_B)\n","\n","        # For the combined model we will only train the generators\n","        self.d_A.trainable = False\n","        self.d_B.trainable = False\n","\n","        # Discriminators determines validity of translated images\n","        valid_A = self.d_A(fake_A)\n","        valid_B = self.d_B(fake_B)\n","\n","        # Combined model trains generators to fool discriminators\n","        self.combined = Model(inputs=[img_A, img_B],\n","                              outputs=[valid_A, valid_B,\n","                                       reconstr_A, reconstr_B,\n","                                       img_A_id, img_B_id ])\n","        self.combined.compile(loss=['mse', 'mse',\n","                                    'mae', 'mae',\n","                                    'mae', 'mae'],\n","                              loss_weights=[1, 1,\n","                                            self.lambda_cycle, self.lambda_cycle,\n","                                            self.lambda_id, self.lambda_id ],\n","                              optimizer=optimizer)\n","\n","    def build_generator(self):\n","        \"\"\"U-Net Generator\"\"\"\n","\n","        def conv2d(layer_input, filters, f_size=4):\n","            \"\"\"Layers used during downsampling\"\"\"\n","            d = Conv2D(filters, kernel_size=f_size, strides=2, padding='same')(layer_input)\n","            d = LeakyReLU(alpha=0.2)(d)\n","            d = InstanceNormalization()(d)\n","            return d\n","\n","        def deconv2d(layer_input, skip_input, filters, f_size=4, dropout_rate=0):\n","            \"\"\"Layers used during upsampling\"\"\"\n","            u = UpSampling2D(size=2)(layer_input)\n","            u = Conv2D(filters, kernel_size=f_size, strides=1, padding='same', activation='relu')(u)\n","            if dropout_rate:\n","                u = Dropout(dropout_rate)(u)\n","            u = InstanceNormalization()(u)\n","            u = Concatenate()([u, skip_input])\n","            return u\n","\n","        # Image input\n","        d0 = Input(shape=self.img_shape)\n","\n","        # U-Net, 12\n","        ## Downsampling\n","        #d1 = conv2d(d0, self.gf)\n","        #d2 = conv2d(d1, self.gf*2)\n","        #d3 = conv2d(d2, self.gf*4)\n","        #d4 = conv2d(d3, self.gf*8)\n","        #\n","        ## Upsampling\n","        #u1 = deconv2d(d4, d3, self.gf*4)\n","        #u2 = deconv2d(u1, d2, self.gf*2)\n","        #u3 = deconv2d(u2, d1, self.gf)\n","        #\n","        #u4 = UpSampling2D(size=2)(u3)\n","        #output_img = Conv2D(self.channels, kernel_size=4, strides=1, padding='same', activation='tanh')(u4)\n","\n","        # Downsampling\n","        d1 = conv2d(d0, self.gf)\n","        d2 = conv2d(d1, self.gf*2)\n","        d3 = conv2d(d2, self.gf*4)\n","        d4 = conv2d(d3, self.gf*8)\n","        d5 = conv2d(d4, self.gf*8)\n","        d6 = conv2d(d5, self.gf*8)\n","        d7 = conv2d(d6, self.gf*8)\n","\n","        # Upsampling\n","        u1 = deconv2d(d7, d6, self.gf*8)\n","        u2 = deconv2d(u1, d5, self.gf*8)\n","        u3 = deconv2d(u2, d4, self.gf*8)\n","        u4 = deconv2d(u3, d3, self.gf*4)\n","        u5 = deconv2d(u4, d2, self.gf*2)\n","        u6 = deconv2d(u5, d1, self.gf)\n","\n","        u7 = UpSampling2D(size=2)(u6)\n","        output_img = Conv2D(self.channels, kernel_size=4, strides=1, padding='same', activation='tanh')(u7)\n","\n","        return Model(d0, output_img)\n","\n","    def build_discriminator(self):\n","\n","        def d_layer(layer_input, filters, f_size=4, normalization=True):\n","            \"\"\"Discriminator layer\"\"\"\n","            d = Conv2D(filters, kernel_size=f_size, strides=2, padding='same')(layer_input)\n","            d = LeakyReLU(alpha=0.2)(d)\n","            if normalization:\n","                d = InstanceNormalization()(d)\n","            return d\n","\n","        img = Input(shape=self.img_shape)\n","\n","        d1 = d_layer(img, self.df, normalization=False)\n","        d2 = d_layer(d1, self.df*2)\n","        d3 = d_layer(d2, self.df*4)\n","        d4 = d_layer(d3, self.df*8)\n","\n","        validity = Conv2D(1, kernel_size=4, strides=1, padding='same')(d4)\n","\n","        return Model(img, validity)\n","\n","    def train(self, epochs, batch_size=1, sample_interval=-1, save_interval=-1):\n","        self.train_cnt += 1\n","\n","        print(datetime.datetime.now().isoformat(), 'Start', self.train_cnt)\n","\n","        start_time = datetime.datetime.now()\n","\n","        # Adversarial loss ground truths\n","        valid = np.ones((batch_size,) + self.disc_patch)\n","        fake = np.zeros((batch_size,) + self.disc_patch)\n","\n","        step_cnt = 1\n","\n","        #for epoch in range(epochs):\n","        for epoch in range(1, epochs+1):\n","            #for batch_i, (imgs_A, imgs_B) in enumerate(self.data_loader.load_batch(batch_size)):\n","            for batch_i, (imgs_A, imgs_B) in enumerate(self.data_loader.load_batch(batch_size), 1):\n","\n","                # Translate images to opposite domain\n","                fake_B = self.g_AB.predict(imgs_A)\n","                fake_A = self.g_BA.predict(imgs_B)\n","\n","                # Train the discriminators (original images = real / translated = Fake)\n","                dA_loss_real = self.d_A.train_on_batch(imgs_A, valid)\n","                dA_loss_fake = self.d_A.train_on_batch(fake_A, fake)\n","                dA_loss = 0.5 * np.add(dA_loss_real, dA_loss_fake)\n","\n","                dB_loss_real = self.d_B.train_on_batch(imgs_B, valid)\n","                dB_loss_fake = self.d_B.train_on_batch(fake_B, fake)\n","                dB_loss = 0.5 * np.add(dB_loss_real, dB_loss_fake)\n","\n","                # Total disciminator loss\n","                d_loss = 0.5 * np.add(dA_loss, dB_loss)\n","\n","                # Train the generators\n","                g_loss = self.combined.train_on_batch([imgs_A, imgs_B],\n","                                                      [valid, valid,\n","                                                       imgs_A, imgs_B,\n","                                                       imgs_A, imgs_B])\n","\n","                elapsed_time = datetime.datetime.now() - start_time\n","\n","                # Plot the progress\n","                # print(\"[Epoch %d/%d] [Batch %d/%d] [D loss: %f, acc: %3d%%] [G loss: %05f, adv: %05f, recon: %05f, id: %05f] time: %s \" % (\n","                #     epoch, epochs,\n","                #     batch_i, self.data_loader.n_batches,\n","                #     d_loss[0], 100*d_loss[1],\n","                #     g_loss[0],\n","                #     np.mean(g_loss[1:3]),\n","                #     np.mean(g_loss[3:5]),\n","                #     np.mean(g_loss[5:6]),\n","                #     elapsed_time))\n","                self.history = self.history.append({\n","                    'epoch': epoch,\n","                    'epochs': epochs,\n","                    'batch_idx': batch_i,\n","                    'batch_num': self.data_loader.n_batches,\n","                    'd_loss': d_loss[0],\n","                    'acc': d_loss[1],\n","                    'g_loss': g_loss[0],\n","                    'adv': np.mean(g_loss[1:3]),\n","                    'recon': np.mean(g_loss[3:5]),\n","                    'id': np.mean(g_loss[5:6]),\n","                    'elapsed_time': elapsed_time\n","                }, ignore_index=True)\n","\n","                # If at save interval => save generated image samples\n","                #if sample_interval > 0 and batch_i % sample_interval == 0:\n","                if sample_interval > 0 and step_cnt % sample_interval == 0:\n","                    print(\"[Epoch %d/%d] [Batch %d/%d] [D loss: %f, acc: %3d%%] [G loss: %05f, adv: %05f, recon: %05f, id: %05f] time: %s \" % (\n","                        epoch, epochs,\n","                        batch_i, self.data_loader.n_batches,\n","                        d_loss[0], 100*d_loss[1],\n","                        g_loss[0],\n","                        np.mean(g_loss[1:3]),\n","                        np.mean(g_loss[3:5]),\n","                        np.mean(g_loss[5:6]),\n","                        elapsed_time))\n","\n","                    self.sample_images(epoch, batch_i)\n","\n","                #if save_interval > 0 and batch_i != 1 and (batch_i % save_interval) == 0:\n","                if save_interval > 0 and step_cnt % save_interval == 0:\n","                    file_suffix = '{}_{}_{}'.format(self.train_cnt, epoch, batch_i)\n","                    self.save_model_weights(self.combined, self.combined_name, file_suffix)\n","\n","                step_cnt += 1\n","\n","        print(datetime.datetime.now().isoformat(), 'End')\n","\n","    def generate_image_A(self, img):\n","        return self.g_AB.predict(img)\n","\n","    def generate_image_B(self, img):\n","        return self.g_BA.predict(img)\n","\n","    def sample_images(self, epoch, batch_i):\n","        dir_path = os.path.join(self.img_save_dir, self.dataset_name)\n","\n","        #os.makedirs('images/%s' % self.dataset_name, exist_ok=True)\n","        os.makedirs(dir_path, exist_ok=True)\n","\n","        r, c = 2, 3\n","\n","        imgs_A = self.data_loader.load_data(domain=\"A\", batch_size=1, is_testing=True)\n","        imgs_B = self.data_loader.load_data(domain=\"B\", batch_size=1, is_testing=True)\n","\n","        # Demo (for GIF)\n","        #imgs_A = self.data_loader.load_img('datasets/apple2orange/testA/n07740461_1541.jpg')\n","        #imgs_B = self.data_loader.load_img('datasets/apple2orange/testB/n07749192_4241.jpg')\n","\n","        # Translate images to the other domain\n","        fake_B = self.g_AB.predict(imgs_A)\n","        fake_A = self.g_BA.predict(imgs_B)\n","\n","        # Translate back to original domain\n","        reconstr_A = self.g_BA.predict(fake_B)\n","        reconstr_B = self.g_AB.predict(fake_A)\n","\n","        gen_imgs = np.concatenate([imgs_A, fake_B, reconstr_A, imgs_B, fake_A, reconstr_B])\n","\n","        # Rescale images 0 - 1\n","        gen_imgs = 0.5 * gen_imgs + 0.5\n","\n","        titles = ['Original', 'Translated', 'Reconstructed']\n","        fig, axs = plt.subplots(r, c)\n","        cnt = 0\n","\n","        for i in range(r):\n","            for j in range(c):\n","                axs[i, j].imshow(gen_imgs[cnt])\n","                axs[i, j].set_title(titles[j])\n","                axs[i, j].axis('off')\n","                cnt += 1\n","\n","        #fig.savefig(\"images/%s/%d_%d.png\" % (self.dataset_name, epoch, batch_i))\n","        file_path = os.path.join(dir_path, '{}_{}_{}.png'.format(self.train_cnt, epoch, batch_i))\n","        fig.savefig(file_path)\n","\n","        plt.close()\n","\n","    def plot_hisotry(self, columns=[]):\n","        if len(columns) == 0:\n","            columns = ['d_loss', 'g_loss']\n","            #columns = ['d_loss', 'acc', 'g_loss', 'adv', 'recon', 'id',]\n","        self.history[columns].plot()\n","\n","    def save_models(self, file_suffix=None):\n","        self.save_model_weights(self.combined, self.combined_name, file_suffix)\n","        #self.save_model_weights(self.g_AB, self.g_AB_name, file_suffix)\n","        #self.save_model_weights(self.g_BA, self.g_BA_name, file_suffix)\n","\n","    def save_model_weights(self, model, model_name, file_suffix=None):\n","        file_path = os.path.join(self.model_save_dir, self._create_h5_file_name(model_name, file_suffix))\n","        model.save_weights(file_path)\n","\n","        print('Model weights saved.', model_name)\n","\n","    def load_models(self, file_suffix=None):\n","        self.load_model_weights(self.combined_name, file_suffix)\n","        self.load_model_weights(self.g_AB_name, file_suffix)\n","        self.load_model_weights(self.g_BA_name, file_suffix)\n","\n","    def load_model_weights(self, model_name, file_suffix=None):\n","        model = None\n","\n","        if model_name == self.combined_name:\n","            model = self.combined\n","        elif model_name == self.g_AB_name:\n","            model = self.g_AB\n","        elif model_name == self.g_BA_name:\n","            model = self.g_BA\n","        else:\n","            print('Unsupported.', model_name)\n","            return\n","\n","        if not model:\n","            print('Not initialized.', model_name)\n","            return\n","\n","        file_path = os.path.join(self.model_save_dir, self._create_h5_file_name(model_name, file_suffix))\n","\n","        if not os.path.exists(file_path):\n","            print('File Not found.', model_name)\n","            return\n","\n","        model.load_weights(file_path)\n","\n","        print('Model weights loaded.', model_name)\n","\n","    def _create_h5_file_name(self, model_name, suffix=None):\n","        if suffix:\n","            return '{}_{}.h5'.format(model_name, suffix)\n","        else:\n","            return '{}.h5'.format(model_name)"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"vtp6KwZxIWO5","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1597713547004,"user_tz":-540,"elapsed":140394,"user":{"displayName":"Noboru Koike","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggp8njUb4jc54JrzfM5cQBkfiCdlz6nY17y8-1szg=s64","userId":"05156582812995850159"}},"outputId":"edba0110-1550-4fc3-90f5-66d05f6f2520"},"source":["gan = CycleGAN()\n","gan.init(data_loader=data_loader)\n","\n","# Image A Count: 1, BatchSize:1, Steps: 1/1=1\n","gan.train(epochs=100, batch_size=1, sample_interval=1, save_interval=-1)\n","\n","#gan.history.to_csv(os.path.join(OUTPUT_DIR_PATH, 'history.csv'))"],"execution_count":10,"outputs":[{"output_type":"stream","text":["2020-08-18T01:16:56.054343 Start 1\n","[Epoch 1/100] [Batch 1/1] [D loss: 4.573336, acc:  46%] [G loss: 29.825464, adv: 7.247347, recon: 0.690020, id: 0.783698] time: 0:00:27.885540 \n","[Epoch 2/100] [Batch 1/1] [D loss: 8.550787, acc:  54%] [G loss: 89.498169, adv: 35.719386, recon: 0.822844, id: 0.771132] time: 0:00:31.475765 \n","[Epoch 3/100] [Batch 1/1] [D loss: 13.988053, acc:  52%] [G loss: 42.611866, adv: 12.848026, recon: 0.765667, id: 0.732989] time: 0:00:33.943832 \n","[Epoch 4/100] [Batch 1/1] [D loss: 11.127170, acc:  49%] [G loss: 50.653446, adv: 16.910456, recon: 0.755426, id: 0.769304] time: 0:00:36.655131 \n","[Epoch 5/100] [Batch 1/1] [D loss: 12.485182, acc:  49%] [G loss: 22.281809, adv: 3.242475, recon: 0.708188, id: 0.774473] time: 0:00:38.519718 \n","[Epoch 6/100] [Batch 1/1] [D loss: 4.921129, acc:  52%] [G loss: 21.145210, adv: 3.370201, recon: 0.638253, id: 0.803606] time: 0:00:39.985553 \n","[Epoch 7/100] [Batch 1/1] [D loss: 6.555819, acc:  52%] [G loss: 19.833000, adv: 2.770659, recon: 0.626706, id: 0.911322] time: 0:00:42.045911 \n","[Epoch 8/100] [Batch 1/1] [D loss: 4.979746, acc:  50%] [G loss: 20.128433, adv: 3.116294, recon: 0.610023, id: 0.938797] time: 0:00:43.440845 \n","[Epoch 9/100] [Batch 1/1] [D loss: 3.800112, acc:  52%] [G loss: 16.900398, adv: 1.833106, recon: 0.576917, id: 0.858484] time: 0:00:44.915754 \n","[Epoch 10/100] [Batch 1/1] [D loss: 2.200475, acc:  54%] [G loss: 15.564360, adv: 1.435403, recon: 0.551533, id: 0.844534] time: 0:00:46.407353 \n","[Epoch 11/100] [Batch 1/1] [D loss: 1.536525, acc:  55%] [G loss: 14.786512, adv: 1.212063, recon: 0.531927, id: 0.825172] time: 0:00:48.603810 \n","[Epoch 12/100] [Batch 1/1] [D loss: 1.020513, acc:  53%] [G loss: 14.001187, adv: 1.104659, recon: 0.506883, id: 0.838093] time: 0:00:49.467543 \n","[Epoch 13/100] [Batch 1/1] [D loss: 1.030944, acc:  54%] [G loss: 13.939228, adv: 1.022663, recon: 0.514366, id: 0.811436] time: 0:00:50.341185 \n","[Epoch 14/100] [Batch 1/1] [D loss: 0.969282, acc:  55%] [G loss: 13.570545, adv: 0.896360, recon: 0.508329, id: 0.814019] time: 0:00:51.209750 \n","[Epoch 15/100] [Batch 1/1] [D loss: 0.906025, acc:  52%] [G loss: 12.835770, adv: 0.925182, recon: 0.470765, id: 0.790483] time: 0:00:52.649784 \n","[Epoch 16/100] [Batch 1/1] [D loss: 0.626841, acc:  51%] [G loss: 12.239028, adv: 0.892244, recon: 0.443163, id: 0.790089] time: 0:00:53.540586 \n","[Epoch 17/100] [Batch 1/1] [D loss: 0.582443, acc:  53%] [G loss: 11.682600, adv: 0.869330, recon: 0.423615, id: 0.767773] time: 0:00:54.420798 \n","[Epoch 18/100] [Batch 1/1] [D loss: 0.313236, acc:  62%] [G loss: 11.184934, adv: 0.769410, recon: 0.409911, id: 0.755301] time: 0:00:55.279363 \n","[Epoch 19/100] [Batch 1/1] [D loss: 0.218093, acc:  71%] [G loss: 10.957159, adv: 0.715830, recon: 0.405040, id: 0.736483] time: 0:00:56.137794 \n","[Epoch 20/100] [Batch 1/1] [D loss: 0.522517, acc:  66%] [G loss: 12.316941, adv: 0.839477, recon: 0.456757, id: 0.735227] time: 0:00:57.553172 \n","[Epoch 21/100] [Batch 1/1] [D loss: 0.292444, acc:  68%] [G loss: 11.509752, adv: 0.700572, recon: 0.431779, id: 0.720010] time: 0:00:58.680048 \n","[Epoch 22/100] [Batch 1/1] [D loss: 0.491252, acc:  61%] [G loss: 11.995900, adv: 0.894891, recon: 0.434682, id: 0.752692] time: 0:00:59.558603 \n","[Epoch 23/100] [Batch 1/1] [D loss: 0.508596, acc:  61%] [G loss: 12.126643, adv: 0.796248, recon: 0.447872, id: 0.708755] time: 0:01:01.028261 \n","[Epoch 24/100] [Batch 1/1] [D loss: 0.646353, acc:  61%] [G loss: 12.588388, adv: 0.894720, recon: 0.462260, id: 0.737291] time: 0:01:02.622920 \n","[Epoch 25/100] [Batch 1/1] [D loss: 0.425592, acc:  60%] [G loss: 12.357215, adv: 0.774240, recon: 0.463443, id: 0.744155] time: 0:01:03.500702 \n","[Epoch 26/100] [Batch 1/1] [D loss: 0.617883, acc:  62%] [G loss: 12.026987, adv: 0.862360, recon: 0.438940, id: 0.726450] time: 0:01:04.376304 \n","[Epoch 27/100] [Batch 1/1] [D loss: 0.362226, acc:  61%] [G loss: 11.655026, adv: 0.769963, recon: 0.431011, id: 0.725653] time: 0:01:05.266073 \n","[Epoch 28/100] [Batch 1/1] [D loss: 0.551711, acc:  64%] [G loss: 11.524767, adv: 0.840988, recon: 0.418368, id: 0.723247] time: 0:01:06.149128 \n","[Epoch 29/100] [Batch 1/1] [D loss: 0.574216, acc:  65%] [G loss: 11.635278, adv: 0.827012, recon: 0.427732, id: 0.694224] time: 0:01:07.048633 \n","[Epoch 30/100] [Batch 1/1] [D loss: 0.330906, acc:  67%] [G loss: 11.042418, adv: 0.713756, recon: 0.410258, id: 0.672476] time: 0:01:07.922296 \n","[Epoch 31/100] [Batch 1/1] [D loss: 0.331442, acc:  67%] [G loss: 10.803136, adv: 0.634779, recon: 0.407576, id: 0.662680] time: 0:01:08.807428 \n","[Epoch 32/100] [Batch 1/1] [D loss: 0.358369, acc:  65%] [G loss: 10.638528, adv: 0.681065, recon: 0.394501, id: 0.673826] time: 0:01:09.716093 \n","[Epoch 33/100] [Batch 1/1] [D loss: 0.395268, acc:  67%] [G loss: 10.940735, adv: 0.694065, recon: 0.409476, id: 0.657878] time: 0:01:10.592645 \n","[Epoch 34/100] [Batch 1/1] [D loss: 0.467966, acc:  69%] [G loss: 9.978804, adv: 0.751369, recon: 0.355228, id: 0.639066] time: 0:01:11.472146 \n","[Epoch 35/100] [Batch 1/1] [D loss: 0.301005, acc:  68%] [G loss: 10.803082, adv: 0.626068, recon: 0.411057, id: 0.642267] time: 0:01:12.339960 \n","[Epoch 36/100] [Batch 1/1] [D loss: 0.265293, acc:  68%] [G loss: 10.730421, adv: 0.632671, recon: 0.407400, id: 0.626694] time: 0:01:13.204885 \n","[Epoch 37/100] [Batch 1/1] [D loss: 0.544917, acc:  66%] [G loss: 11.018868, adv: 1.016100, recon: 0.377359, id: 0.626948] time: 0:01:14.067376 \n","[Epoch 38/100] [Batch 1/1] [D loss: 0.520370, acc:  59%] [G loss: 11.757011, adv: 1.470821, recon: 0.375868, id: 0.617477] time: 0:01:14.933585 \n","[Epoch 39/100] [Batch 1/1] [D loss: 0.663525, acc:  61%] [G loss: 11.058835, adv: 1.150089, recon: 0.369276, id: 0.597657] time: 0:01:15.798050 \n","[Epoch 40/100] [Batch 1/1] [D loss: 0.724019, acc:  59%] [G loss: 10.310824, adv: 0.850593, recon: 0.367198, id: 0.589648] time: 0:01:16.663714 \n","[Epoch 41/100] [Batch 1/1] [D loss: 0.541548, acc:  65%] [G loss: 10.089422, adv: 0.647171, recon: 0.376947, id: 0.583750] time: 0:01:17.533588 \n","[Epoch 42/100] [Batch 1/1] [D loss: 0.539667, acc:  61%] [G loss: 10.163480, adv: 0.811324, recon: 0.360835, id: 0.565822] time: 0:01:18.776234 \n","[Epoch 43/100] [Batch 1/1] [D loss: 0.319177, acc:  68%] [G loss: 8.993554, adv: 0.751387, recon: 0.309399, id: 0.614178] time: 0:01:19.662026 \n","[Epoch 44/100] [Batch 1/1] [D loss: 0.412868, acc:  70%] [G loss: 9.854633, adv: 0.801915, recon: 0.351393, id: 0.582821] time: 0:01:20.531372 \n","[Epoch 45/100] [Batch 1/1] [D loss: 0.295243, acc:  68%] [G loss: 9.626854, adv: 0.694883, recon: 0.351813, id: 0.575081] time: 0:01:21.389225 \n","[Epoch 46/100] [Batch 1/1] [D loss: 0.321059, acc:  68%] [G loss: 9.736975, adv: 0.627724, recon: 0.363623, id: 0.549188] time: 0:01:22.265339 \n","[Epoch 47/100] [Batch 1/1] [D loss: 0.481295, acc:  66%] [G loss: 9.015854, adv: 0.794183, recon: 0.308379, id: 0.544355] time: 0:01:23.139759 \n","[Epoch 48/100] [Batch 1/1] [D loss: 0.377504, acc:  64%] [G loss: 9.524914, adv: 0.715688, recon: 0.346311, id: 0.547227] time: 0:01:24.008436 \n","[Epoch 49/100] [Batch 1/1] [D loss: 0.293271, acc:  75%] [G loss: 9.501663, adv: 0.764515, recon: 0.341921, id: 0.541556] time: 0:01:24.892768 \n","[Epoch 50/100] [Batch 1/1] [D loss: 0.349811, acc:  69%] [G loss: 10.436035, adv: 0.747853, recon: 0.384195, id: 0.521479] time: 0:01:25.754675 \n","[Epoch 51/100] [Batch 1/1] [D loss: 0.361708, acc:  68%] [G loss: 10.135836, adv: 0.748722, recon: 0.371989, id: 0.555715] time: 0:01:26.636273 \n","[Epoch 52/100] [Batch 1/1] [D loss: 0.281146, acc:  71%] [G loss: 10.381415, adv: 0.709295, recon: 0.386194, id: 0.527522] time: 0:01:27.511918 \n","[Epoch 53/100] [Batch 1/1] [D loss: 0.299191, acc:  72%] [G loss: 9.494270, adv: 0.684714, recon: 0.349493, id: 0.519409] time: 0:01:28.368242 \n","[Epoch 54/100] [Batch 1/1] [D loss: 0.241056, acc:  72%] [G loss: 9.373385, adv: 0.657295, recon: 0.347520, id: 0.525390] time: 0:01:29.257098 \n","[Epoch 55/100] [Batch 1/1] [D loss: 0.153090, acc:  82%] [G loss: 9.212192, adv: 0.720535, recon: 0.335289, id: 0.503239] time: 0:01:30.124292 \n","[Epoch 56/100] [Batch 1/1] [D loss: 0.259356, acc:  73%] [G loss: 9.242317, adv: 0.727026, recon: 0.330970, id: 0.497840] time: 0:01:30.977991 \n","[Epoch 57/100] [Batch 1/1] [D loss: 0.294584, acc:  75%] [G loss: 9.109802, adv: 0.765907, recon: 0.320893, id: 0.482623] time: 0:01:31.834327 \n","[Epoch 58/100] [Batch 1/1] [D loss: 0.236428, acc:  74%] [G loss: 9.292645, adv: 0.638307, recon: 0.346149, id: 0.483147] time: 0:01:32.696205 \n","[Epoch 59/100] [Batch 1/1] [D loss: 0.281207, acc:  72%] [G loss: 9.323470, adv: 0.761359, recon: 0.330721, id: 0.499550] time: 0:01:33.544355 \n","[Epoch 60/100] [Batch 1/1] [D loss: 0.337485, acc:  65%] [G loss: 8.617141, adv: 0.723606, recon: 0.306381, id: 0.475451] time: 0:01:34.412723 \n","[Epoch 61/100] [Batch 1/1] [D loss: 0.373541, acc:  72%] [G loss: 9.014231, adv: 0.759978, recon: 0.322470, id: 0.489256] time: 0:01:35.268236 \n","[Epoch 62/100] [Batch 1/1] [D loss: 0.344440, acc:  69%] [G loss: 9.595659, adv: 0.743009, recon: 0.348515, id: 0.475064] time: 0:01:36.124424 \n","[Epoch 63/100] [Batch 1/1] [D loss: 0.223993, acc:  79%] [G loss: 9.147910, adv: 0.697198, recon: 0.331515, id: 0.473901] time: 0:01:36.976385 \n","[Epoch 64/100] [Batch 1/1] [D loss: 0.214009, acc:  75%] [G loss: 9.128832, adv: 0.627243, recon: 0.340634, id: 0.462167] time: 0:01:37.837103 \n","[Epoch 65/100] [Batch 1/1] [D loss: 0.274575, acc:  74%] [G loss: 8.823803, adv: 0.622930, recon: 0.328627, id: 0.443226] time: 0:01:38.693479 \n","[Epoch 66/100] [Batch 1/1] [D loss: 0.232193, acc:  74%] [G loss: 8.776003, adv: 0.683938, recon: 0.318381, id: 0.439351] time: 0:01:39.544428 \n","[Epoch 67/100] [Batch 1/1] [D loss: 0.270894, acc:  79%] [G loss: 8.906920, adv: 0.726496, recon: 0.318288, id: 0.443332] time: 0:01:40.407581 \n","[Epoch 68/100] [Batch 1/1] [D loss: 0.309454, acc:  74%] [G loss: 8.336350, adv: 0.670576, recon: 0.297484, id: 0.444686] time: 0:01:41.732270 \n","[Epoch 69/100] [Batch 1/1] [D loss: 0.330720, acc:  69%] [G loss: 9.244884, adv: 0.615294, recon: 0.351823, id: 0.469939] time: 0:01:42.599641 \n","[Epoch 70/100] [Batch 1/1] [D loss: 0.274700, acc:  75%] [G loss: 9.191698, adv: 0.722421, recon: 0.335515, id: 0.433936] time: 0:01:43.466829 \n","[Epoch 71/100] [Batch 1/1] [D loss: 0.205643, acc:  76%] [G loss: 8.491835, adv: 0.766197, recon: 0.291102, id: 0.436300] time: 0:01:44.343027 \n","[Epoch 72/100] [Batch 1/1] [D loss: 0.224349, acc:  76%] [G loss: 8.913807, adv: 0.679181, recon: 0.325339, id: 0.443896] time: 0:01:45.205539 \n","[Epoch 73/100] [Batch 1/1] [D loss: 0.235745, acc:  76%] [G loss: 8.312633, adv: 0.626424, recon: 0.303870, id: 0.424876] time: 0:01:46.061251 \n","[Epoch 74/100] [Batch 1/1] [D loss: 0.371354, acc:  74%] [G loss: 8.888067, adv: 0.765043, recon: 0.314667, id: 0.434611] time: 0:01:46.939308 \n","[Epoch 75/100] [Batch 1/1] [D loss: 0.278823, acc:  72%] [G loss: 9.201090, adv: 0.721708, recon: 0.334642, id: 0.416471] time: 0:01:47.787592 \n","[Epoch 76/100] [Batch 1/1] [D loss: 0.283657, acc:  73%] [G loss: 7.545805, adv: 0.778022, recon: 0.250515, id: 0.415279] time: 0:01:48.647193 \n","[Epoch 77/100] [Batch 1/1] [D loss: 0.200558, acc:  78%] [G loss: 7.246711, adv: 0.766307, recon: 0.239466, id: 0.405029] time: 0:01:49.506564 \n","[Epoch 78/100] [Batch 1/1] [D loss: 0.248710, acc:  72%] [G loss: 8.023936, adv: 0.590740, recon: 0.298222, id: 0.389152] time: 0:01:50.356196 \n","[Epoch 79/100] [Batch 1/1] [D loss: 0.185219, acc:  79%] [G loss: 8.425334, adv: 0.723428, recon: 0.304410, id: 0.382189] time: 0:01:51.213150 \n","[Epoch 80/100] [Batch 1/1] [D loss: 0.339986, acc:  76%] [G loss: 8.336619, adv: 0.720201, recon: 0.301124, id: 0.396467] time: 0:01:52.083173 \n","[Epoch 81/100] [Batch 1/1] [D loss: 0.643761, acc:  75%] [G loss: 8.661657, adv: 0.844760, recon: 0.301957, id: 0.377132] time: 0:01:52.967166 \n","[Epoch 82/100] [Batch 1/1] [D loss: 0.420940, acc:  73%] [G loss: 10.276803, adv: 0.761887, recon: 0.388074, id: 0.382788] time: 0:01:53.831662 \n","[Epoch 83/100] [Batch 1/1] [D loss: 0.308412, acc:  74%] [G loss: 8.096805, adv: 0.711701, recon: 0.284782, id: 0.392983] time: 0:01:54.704197 \n","[Epoch 84/100] [Batch 1/1] [D loss: 0.248049, acc:  76%] [G loss: 8.504410, adv: 0.760837, recon: 0.302964, id: 0.395618] time: 0:01:55.568047 \n","[Epoch 85/100] [Batch 1/1] [D loss: 0.127397, acc:  85%] [G loss: 8.004679, adv: 0.732729, recon: 0.283952, id: 0.385873] time: 0:01:56.421146 \n","[Epoch 86/100] [Batch 1/1] [D loss: 0.798887, acc:  76%] [G loss: 8.510734, adv: 0.758042, recon: 0.303359, id: 0.380996] time: 0:01:57.296274 \n","[Epoch 87/100] [Batch 1/1] [D loss: 0.275474, acc:  76%] [G loss: 8.001965, adv: 0.737273, recon: 0.280834, id: 0.364798] time: 0:01:58.171777 \n","[Epoch 88/100] [Batch 1/1] [D loss: 0.263048, acc:  72%] [G loss: 8.600179, adv: 0.618875, recon: 0.322579, id: 0.368463] time: 0:01:59.041350 \n","[Epoch 89/100] [Batch 1/1] [D loss: 0.335328, acc:  73%] [G loss: 9.249404, adv: 0.765804, recon: 0.341651, id: 0.352603] time: 0:01:59.924409 \n","[Epoch 90/100] [Batch 1/1] [D loss: 0.322446, acc:  66%] [G loss: 8.104073, adv: 0.753407, recon: 0.287242, id: 0.363862] time: 0:02:00.783500 \n","[Epoch 91/100] [Batch 1/1] [D loss: 0.282392, acc:  68%] [G loss: 7.526765, adv: 0.691452, recon: 0.265708, id: 0.354091] time: 0:02:01.648689 \n","[Epoch 92/100] [Batch 1/1] [D loss: 0.208779, acc:  77%] [G loss: 7.615993, adv: 0.721574, recon: 0.268453, id: 0.361183] time: 0:02:02.517244 \n","[Epoch 93/100] [Batch 1/1] [D loss: 0.254845, acc:  76%] [G loss: 7.683514, adv: 0.741440, recon: 0.266957, id: 0.356924] time: 0:02:03.386551 \n","[Epoch 94/100] [Batch 1/1] [D loss: 0.237532, acc:  74%] [G loss: 7.586578, adv: 0.691727, recon: 0.268683, id: 0.348266] time: 0:02:04.239575 \n","[Epoch 95/100] [Batch 1/1] [D loss: 0.321732, acc:  74%] [G loss: 9.390095, adv: 0.794652, recon: 0.346335, id: 0.344653] time: 0:02:05.116389 \n","[Epoch 96/100] [Batch 1/1] [D loss: 0.311913, acc:  70%] [G loss: 9.032427, adv: 0.755493, recon: 0.329778, id: 0.346419] time: 0:02:05.983310 \n","[Epoch 97/100] [Batch 1/1] [D loss: 0.228846, acc:  74%] [G loss: 8.829920, adv: 0.740514, recon: 0.323053, id: 0.373837] time: 0:02:06.838598 \n","[Epoch 98/100] [Batch 1/1] [D loss: 0.507974, acc:  71%] [G loss: 8.275976, adv: 0.888429, recon: 0.281246, id: 0.359672] time: 0:02:07.694399 \n","[Epoch 99/100] [Batch 1/1] [D loss: 0.272316, acc:  72%] [G loss: 7.827757, adv: 0.829110, recon: 0.268829, id: 0.359088] time: 0:02:08.546430 \n","[Epoch 100/100] [Batch 1/1] [D loss: 0.468881, acc:  69%] [G loss: 9.463924, adv: 1.039983, recon: 0.323044, id: 0.350907] time: 0:02:09.398618 \n","2020-08-18T01:19:06.459038 End\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"uPzRLtZxImHy","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1597714089045,"user_tz":-540,"elapsed":473315,"user":{"displayName":"Noboru Koike","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggp8njUb4jc54JrzfM5cQBkfiCdlz6nY17y8-1szg=s64","userId":"05156582812995850159"}},"outputId":"5600b2f1-4274-4225-e66c-8b9d23ea5449"},"source":["# Image A Count: 1, BatchSize:1, Steps: 1/1=1\n","gan.train(epochs=900, batch_size=1, sample_interval=10, save_interval=-1)"],"execution_count":11,"outputs":[{"output_type":"stream","text":["2020-08-18T01:20:15.948325 Start 2\n","[Epoch 10/900] [Batch 1/1] [D loss: 0.278213, acc:  71%] [G loss: 7.465380, adv: 0.675419, recon: 0.267840, id: 0.350606] time: 0:00:04.865479 \n","[Epoch 20/900] [Batch 1/1] [D loss: 0.177251, acc:  81%] [G loss: 7.592539, adv: 0.677594, recon: 0.273323, id: 0.312648] time: 0:00:10.105786 \n","[Epoch 30/900] [Batch 1/1] [D loss: 0.138871, acc:  84%] [G loss: 7.283198, adv: 0.638269, recon: 0.266943, id: 0.299442] time: 0:00:15.321987 \n","[Epoch 40/900] [Batch 1/1] [D loss: 0.183071, acc:  81%] [G loss: 7.493988, adv: 0.661981, recon: 0.271678, id: 0.285558] time: 0:00:20.544279 \n","[Epoch 50/900] [Batch 1/1] [D loss: 0.143114, acc:  83%] [G loss: 7.504030, adv: 0.797179, recon: 0.263474, id: 0.296451] time: 0:00:25.761310 \n","[Epoch 60/900] [Batch 1/1] [D loss: 0.231512, acc:  77%] [G loss: 8.288233, adv: 0.675169, recon: 0.309290, id: 0.270037] time: 0:00:31.003603 \n","[Epoch 70/900] [Batch 1/1] [D loss: 0.175145, acc:  79%] [G loss: 6.554304, adv: 0.719509, recon: 0.227657, id: 0.259411] time: 0:00:36.235433 \n","[Epoch 80/900] [Batch 1/1] [D loss: 0.186896, acc:  80%] [G loss: 7.724207, adv: 0.630351, recon: 0.288980, id: 0.269683] time: 0:00:41.448327 \n","[Epoch 90/900] [Batch 1/1] [D loss: 0.136234, acc:  85%] [G loss: 6.867164, adv: 0.648539, recon: 0.247521, id: 0.274226] time: 0:00:46.685641 \n","[Epoch 100/900] [Batch 1/1] [D loss: 0.142346, acc:  84%] [G loss: 6.839302, adv: 0.789506, recon: 0.234663, id: 0.255760] time: 0:00:51.912964 \n","[Epoch 110/900] [Batch 1/1] [D loss: 0.125908, acc:  85%] [G loss: 8.046631, adv: 0.716172, recon: 0.298487, id: 0.250159] time: 0:00:57.151387 \n","[Epoch 120/900] [Batch 1/1] [D loss: 0.117885, acc:  87%] [G loss: 6.757165, adv: 0.807997, recon: 0.230282, id: 0.235069] time: 0:01:02.333610 \n","[Epoch 130/900] [Batch 1/1] [D loss: 0.476426, acc:  76%] [G loss: 6.803329, adv: 0.888152, recon: 0.221664, id: 0.226695] time: 0:01:07.577649 \n","[Epoch 140/900] [Batch 1/1] [D loss: 0.167761, acc:  79%] [G loss: 6.925325, adv: 0.848508, recon: 0.233604, id: 0.236282] time: 0:01:12.791823 \n","[Epoch 150/900] [Batch 1/1] [D loss: 0.138293, acc:  85%] [G loss: 6.434977, adv: 0.733255, recon: 0.219412, id: 0.234670] time: 0:01:18.021598 \n","[Epoch 160/900] [Batch 1/1] [D loss: 0.134154, acc:  84%] [G loss: 6.583231, adv: 0.614578, recon: 0.241647, id: 0.236869] time: 0:01:23.256944 \n","[Epoch 170/900] [Batch 1/1] [D loss: 0.114102, acc:  89%] [G loss: 7.153372, adv: 0.670936, recon: 0.261363, id: 0.227294] time: 0:01:28.496022 \n","[Epoch 180/900] [Batch 1/1] [D loss: 0.108822, acc:  88%] [G loss: 6.301347, adv: 0.712315, recon: 0.217585, id: 0.218445] time: 0:01:33.693288 \n","[Epoch 190/900] [Batch 1/1] [D loss: 0.177319, acc:  80%] [G loss: 6.079039, adv: 0.723206, recon: 0.207848, id: 0.209710] time: 0:01:38.923938 \n","[Epoch 200/900] [Batch 1/1] [D loss: 0.182093, acc:  86%] [G loss: 7.347540, adv: 1.146767, recon: 0.227687, id: 0.224342] time: 0:01:44.123131 \n","[Epoch 210/900] [Batch 1/1] [D loss: 0.101414, acc:  88%] [G loss: 7.485986, adv: 0.780398, recon: 0.268253, id: 0.215143] time: 0:01:49.334140 \n","[Epoch 220/900] [Batch 1/1] [D loss: 0.144065, acc:  83%] [G loss: 6.057059, adv: 0.700591, recon: 0.208552, id: 0.212674] time: 0:01:54.561880 \n","[Epoch 230/900] [Batch 1/1] [D loss: 0.218301, acc:  72%] [G loss: 6.633331, adv: 0.676126, recon: 0.240303, id: 0.213296] time: 0:01:59.776818 \n","[Epoch 240/900] [Batch 1/1] [D loss: 0.302461, acc:  80%] [G loss: 6.887408, adv: 0.842109, recon: 0.232783, id: 0.207889] time: 0:02:04.968982 \n","[Epoch 250/900] [Batch 1/1] [D loss: 0.148486, acc:  83%] [G loss: 6.358828, adv: 0.580184, recon: 0.235416, id: 0.187868] time: 0:02:10.163571 \n","[Epoch 260/900] [Batch 1/1] [D loss: 0.113164, acc:  87%] [G loss: 6.515689, adv: 0.724324, recon: 0.227940, id: 0.203421] time: 0:02:15.357463 \n","[Epoch 270/900] [Batch 1/1] [D loss: 0.165517, acc:  79%] [G loss: 6.073600, adv: 0.738374, recon: 0.206840, id: 0.188234] time: 0:02:20.601970 \n","[Epoch 280/900] [Batch 1/1] [D loss: 0.145424, acc:  81%] [G loss: 6.853389, adv: 0.664263, recon: 0.248324, id: 0.182459] time: 0:02:25.795212 \n","[Epoch 290/900] [Batch 1/1] [D loss: 0.095144, acc:  89%] [G loss: 5.737657, adv: 0.725359, recon: 0.193328, id: 0.186817] time: 0:02:31.059046 \n","[Epoch 300/900] [Batch 1/1] [D loss: 0.115698, acc:  87%] [G loss: 6.393446, adv: 0.706237, recon: 0.225072, id: 0.184108] time: 0:02:36.279597 \n","[Epoch 310/900] [Batch 1/1] [D loss: 0.113139, acc:  86%] [G loss: 6.759696, adv: 0.650811, recon: 0.245062, id: 0.177128] time: 0:02:41.517773 \n","[Epoch 320/900] [Batch 1/1] [D loss: 0.169460, acc:  77%] [G loss: 5.691457, adv: 0.641387, recon: 0.199367, id: 0.177714] time: 0:02:46.752540 \n","[Epoch 330/900] [Batch 1/1] [D loss: 0.185823, acc:  80%] [G loss: 6.527562, adv: 1.018709, recon: 0.202397, id: 0.209075] time: 0:02:51.936254 \n","[Epoch 340/900] [Batch 1/1] [D loss: 0.164325, acc:  80%] [G loss: 5.686281, adv: 0.771908, recon: 0.187537, id: 0.176066] time: 0:02:57.219210 \n","[Epoch 350/900] [Batch 1/1] [D loss: 0.131544, acc:  82%] [G loss: 6.199182, adv: 0.724820, recon: 0.214282, id: 0.171313] time: 0:03:02.533004 \n","[Epoch 360/900] [Batch 1/1] [D loss: 0.232375, acc:  77%] [G loss: 6.460326, adv: 0.637213, recon: 0.233040, id: 0.171081] time: 0:03:09.180937 \n","[Epoch 370/900] [Batch 1/1] [D loss: 0.130334, acc:  84%] [G loss: 6.323215, adv: 0.643006, recon: 0.225826, id: 0.165034] time: 0:03:14.387086 \n","[Epoch 380/900] [Batch 1/1] [D loss: 0.116744, acc:  87%] [G loss: 5.498388, adv: 0.789950, recon: 0.177528, id: 0.165900] time: 0:03:19.587173 \n","[Epoch 390/900] [Batch 1/1] [D loss: 0.160104, acc:  78%] [G loss: 5.710879, adv: 0.625057, recon: 0.202974, id: 0.171723] time: 0:03:24.810002 \n","[Epoch 400/900] [Batch 1/1] [D loss: 0.186621, acc:  72%] [G loss: 6.040980, adv: 0.694395, recon: 0.209040, id: 0.165503] time: 0:03:30.005199 \n","[Epoch 410/900] [Batch 1/1] [D loss: 0.124424, acc:  87%] [G loss: 5.405456, adv: 0.807342, recon: 0.171548, id: 0.164298] time: 0:03:35.215321 \n","[Epoch 420/900] [Batch 1/1] [D loss: 0.151250, acc:  83%] [G loss: 6.043961, adv: 0.799865, recon: 0.198260, id: 0.162614] time: 0:03:40.430007 \n","[Epoch 430/900] [Batch 1/1] [D loss: 0.181933, acc:  76%] [G loss: 5.619725, adv: 0.586059, recon: 0.201577, id: 0.156309] time: 0:03:45.648723 \n","[Epoch 440/900] [Batch 1/1] [D loss: 0.079437, acc:  93%] [G loss: 6.480717, adv: 0.789274, recon: 0.223182, id: 0.176358] time: 0:03:50.874854 \n","[Epoch 450/900] [Batch 1/1] [D loss: 0.268238, acc:  70%] [G loss: 5.517132, adv: 0.748050, recon: 0.183348, id: 0.166519] time: 0:03:56.086953 \n","[Epoch 460/900] [Batch 1/1] [D loss: 0.155042, acc:  79%] [G loss: 5.359550, adv: 0.624136, recon: 0.185973, id: 0.162893] time: 0:04:01.295792 \n","[Epoch 470/900] [Batch 1/1] [D loss: 0.134648, acc:  83%] [G loss: 5.620517, adv: 0.771823, recon: 0.183818, id: 0.162237] time: 0:04:06.510806 \n","[Epoch 480/900] [Batch 1/1] [D loss: 0.145950, acc:  81%] [G loss: 6.102399, adv: 0.709461, recon: 0.212936, id: 0.159344] time: 0:04:11.722201 \n","[Epoch 490/900] [Batch 1/1] [D loss: 0.176311, acc:  80%] [G loss: 6.466381, adv: 0.724194, recon: 0.226941, id: 0.155582] time: 0:04:16.930216 \n","[Epoch 500/900] [Batch 1/1] [D loss: 0.168921, acc:  78%] [G loss: 5.559142, adv: 0.805261, recon: 0.178410, id: 0.152494] time: 0:04:22.126725 \n","[Epoch 510/900] [Batch 1/1] [D loss: 0.227545, acc:  79%] [G loss: 5.872895, adv: 0.872960, recon: 0.185190, id: 0.157921] time: 0:04:27.308461 \n","[Epoch 520/900] [Batch 1/1] [D loss: 0.168824, acc:  80%] [G loss: 5.506986, adv: 0.642250, recon: 0.190572, id: 0.156357] time: 0:04:32.518093 \n","[Epoch 530/900] [Batch 1/1] [D loss: 0.300259, acc:  72%] [G loss: 6.375475, adv: 0.801561, recon: 0.215076, id: 0.150124] time: 0:04:37.731947 \n","[Epoch 540/900] [Batch 1/1] [D loss: 0.205054, acc:  72%] [G loss: 5.382371, adv: 0.602265, recon: 0.189329, id: 0.146683] time: 0:04:42.947005 \n","[Epoch 550/900] [Batch 1/1] [D loss: 0.136138, acc:  83%] [G loss: 5.759192, adv: 0.690634, recon: 0.198257, id: 0.168517] time: 0:04:48.168861 \n","[Epoch 560/900] [Batch 1/1] [D loss: 0.118628, acc:  85%] [G loss: 5.403431, adv: 0.807955, recon: 0.172268, id: 0.154441] time: 0:04:53.380209 \n","[Epoch 570/900] [Batch 1/1] [D loss: 0.142840, acc:  83%] [G loss: 4.984092, adv: 0.675952, recon: 0.163961, id: 0.146224] time: 0:04:58.612245 \n","[Epoch 580/900] [Batch 1/1] [D loss: 0.136389, acc:  83%] [G loss: 5.722136, adv: 0.717599, recon: 0.193383, id: 0.152319] time: 0:05:04.244099 \n","[Epoch 590/900] [Batch 1/1] [D loss: 0.124299, acc:  83%] [G loss: 4.881835, adv: 0.651856, recon: 0.161663, id: 0.140150] time: 0:05:09.482003 \n","[Epoch 600/900] [Batch 1/1] [D loss: 0.183668, acc:  79%] [G loss: 5.686218, adv: 0.789336, recon: 0.185860, id: 0.148973] time: 0:05:14.668612 \n","[Epoch 610/900] [Batch 1/1] [D loss: 0.172097, acc:  79%] [G loss: 5.358329, adv: 0.761135, recon: 0.173662, id: 0.153946] time: 0:05:19.858553 \n","[Epoch 620/900] [Batch 1/1] [D loss: 0.124492, acc:  85%] [G loss: 4.871846, adv: 0.663192, recon: 0.160284, id: 0.140111] time: 0:05:25.137390 \n","[Epoch 630/900] [Batch 1/1] [D loss: 0.308116, acc:  83%] [G loss: 5.388262, adv: 0.789304, recon: 0.171629, id: 0.140285] time: 0:05:30.366315 \n","[Epoch 640/900] [Batch 1/1] [D loss: 0.263707, acc:  76%] [G loss: 6.057930, adv: 0.730526, recon: 0.207209, id: 0.140937] time: 0:05:35.556017 \n","[Epoch 650/900] [Batch 1/1] [D loss: 0.147916, acc:  83%] [G loss: 5.422071, adv: 0.721922, recon: 0.179858, id: 0.148553] time: 0:05:40.735507 \n","[Epoch 660/900] [Batch 1/1] [D loss: 0.114695, acc:  88%] [G loss: 5.593616, adv: 0.915761, recon: 0.169227, id: 0.138180] time: 0:05:45.983663 \n","[Epoch 670/900] [Batch 1/1] [D loss: 0.090489, acc:  89%] [G loss: 4.868221, adv: 0.705020, recon: 0.155935, id: 0.140560] time: 0:05:51.232079 \n","[Epoch 680/900] [Batch 1/1] [D loss: 0.147726, acc:  81%] [G loss: 5.224659, adv: 0.714526, recon: 0.171161, id: 0.144576] time: 0:05:56.477625 \n","[Epoch 690/900] [Batch 1/1] [D loss: 0.156284, acc:  76%] [G loss: 5.254208, adv: 0.756462, recon: 0.168537, id: 0.146295] time: 0:06:01.729454 \n","[Epoch 700/900] [Batch 1/1] [D loss: 0.110167, acc:  88%] [G loss: 4.867602, adv: 0.792045, recon: 0.148220, id: 0.134699] time: 0:06:07.188941 \n","[Epoch 710/900] [Batch 1/1] [D loss: 0.123390, acc:  84%] [G loss: 5.093203, adv: 0.717619, recon: 0.164187, id: 0.138582] time: 0:06:12.429622 \n","[Epoch 720/900] [Batch 1/1] [D loss: 0.207370, acc:  82%] [G loss: 5.206411, adv: 0.685981, recon: 0.173284, id: 0.140183] time: 0:06:17.661746 \n","[Epoch 730/900] [Batch 1/1] [D loss: 0.172821, acc:  80%] [G loss: 5.501218, adv: 0.754427, recon: 0.181341, id: 0.144201] time: 0:06:22.888178 \n","[Epoch 740/900] [Batch 1/1] [D loss: 0.129688, acc:  85%] [G loss: 5.147738, adv: 0.656931, recon: 0.173794, id: 0.136218] time: 0:06:28.107248 \n","[Epoch 750/900] [Batch 1/1] [D loss: 0.107110, acc:  86%] [G loss: 4.551970, adv: 0.708706, recon: 0.141805, id: 0.136371] time: 0:06:33.344272 \n","[Epoch 760/900] [Batch 1/1] [D loss: 0.133190, acc:  82%] [G loss: 4.985466, adv: 0.634311, recon: 0.168216, id: 0.137032] time: 0:06:38.589551 \n","[Epoch 770/900] [Batch 1/1] [D loss: 0.125097, acc:  83%] [G loss: 5.247355, adv: 0.659440, recon: 0.177628, id: 0.136562] time: 0:06:43.819392 \n","[Epoch 780/900] [Batch 1/1] [D loss: 0.125649, acc:  85%] [G loss: 5.843147, adv: 0.832423, recon: 0.190088, id: 0.150982] time: 0:06:49.113278 \n","[Epoch 790/900] [Batch 1/1] [D loss: 0.142806, acc:  85%] [G loss: 5.976187, adv: 0.806476, recon: 0.196907, id: 0.142460] time: 0:06:54.344939 \n","[Epoch 800/900] [Batch 1/1] [D loss: 0.104925, acc:  88%] [G loss: 5.123755, adv: 0.667917, recon: 0.170993, id: 0.130906] time: 0:06:59.581814 \n","[Epoch 810/900] [Batch 1/1] [D loss: 0.116095, acc:  86%] [G loss: 5.377653, adv: 0.635626, recon: 0.185097, id: 0.135624] time: 0:07:04.801521 \n","[Epoch 820/900] [Batch 1/1] [D loss: 0.104651, acc:  88%] [G loss: 5.440652, adv: 0.773821, recon: 0.176073, id: 0.147206] time: 0:07:10.024991 \n","[Epoch 830/900] [Batch 1/1] [D loss: 0.195652, acc:  76%] [G loss: 4.936266, adv: 0.695668, recon: 0.160114, id: 0.134302] time: 0:07:15.235796 \n","[Epoch 840/900] [Batch 1/1] [D loss: 0.145983, acc:  81%] [G loss: 4.762226, adv: 0.695685, recon: 0.152287, id: 0.134830] time: 0:07:21.017280 \n","[Epoch 850/900] [Batch 1/1] [D loss: 0.130059, acc:  86%] [G loss: 5.254340, adv: 0.786865, recon: 0.166698, id: 0.135676] time: 0:07:26.230690 \n","[Epoch 860/900] [Batch 1/1] [D loss: 0.202639, acc:  69%] [G loss: 4.925690, adv: 0.587825, recon: 0.170579, id: 0.127599] time: 0:07:31.406210 \n","[Epoch 870/900] [Batch 1/1] [D loss: 0.210523, acc:  74%] [G loss: 4.787263, adv: 0.803967, recon: 0.144087, id: 0.136500] time: 0:07:36.686176 \n","[Epoch 880/900] [Batch 1/1] [D loss: 0.157558, acc:  82%] [G loss: 4.884971, adv: 0.753689, recon: 0.153970, id: 0.135832] time: 0:07:41.907205 \n","[Epoch 890/900] [Batch 1/1] [D loss: 0.368977, acc:  75%] [G loss: 5.603527, adv: 0.991781, recon: 0.164052, id: 0.129990] time: 0:07:47.109092 \n","[Epoch 900/900] [Batch 1/1] [D loss: 0.154689, acc:  81%] [G loss: 5.047544, adv: 0.781235, recon: 0.157703, id: 0.142220] time: 0:07:52.309454 \n","2020-08-18T01:28:08.634405 End\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"LYqysh8dJwr2","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":383},"executionInfo":{"status":"ok","timestamp":1597714657600,"user_tz":-540,"elapsed":493651,"user":{"displayName":"Noboru Koike","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggp8njUb4jc54JrzfM5cQBkfiCdlz6nY17y8-1szg=s64","userId":"05156582812995850159"}},"outputId":"1f23fb63-a5cc-4a9e-e07a-27435e1f1775"},"source":["# Image A Count: 1, BatchSize:1, Steps: 1/1=1\n","gan.train(epochs=1000, batch_size=1, sample_interval=50, save_interval=-1)"],"execution_count":13,"outputs":[{"output_type":"stream","text":["2020-08-18T01:29:24.249331 Start 3\n","[Epoch 50/1000] [Batch 1/1] [D loss: 0.117059, acc:  85%] [G loss: 5.086572, adv: 0.762139, recon: 0.161628, id: 0.126234] time: 0:00:24.275150 \n","[Epoch 100/1000] [Batch 1/1] [D loss: 0.112053, acc:  89%] [G loss: 4.190142, adv: 0.681212, recon: 0.127516, id: 0.126827] time: 0:00:48.794228 \n","[Epoch 150/1000] [Batch 1/1] [D loss: 0.088107, acc:  94%] [G loss: 4.467377, adv: 0.704445, recon: 0.138244, id: 0.131897] time: 0:01:13.450791 \n","[Epoch 200/1000] [Batch 1/1] [D loss: 0.134805, acc:  84%] [G loss: 5.586086, adv: 0.791955, recon: 0.181858, id: 0.129858] time: 0:01:38.047613 \n","[Epoch 250/1000] [Batch 1/1] [D loss: 0.140357, acc:  82%] [G loss: 5.211852, adv: 0.701412, recon: 0.172639, id: 0.129276] time: 0:02:02.597731 \n","[Epoch 300/1000] [Batch 1/1] [D loss: 0.138763, acc:  84%] [G loss: 4.829324, adv: 0.710010, recon: 0.154561, id: 0.121862] time: 0:02:27.215454 \n","[Epoch 350/1000] [Batch 1/1] [D loss: 0.107231, acc:  88%] [G loss: 5.190697, adv: 0.903013, recon: 0.153099, id: 0.128584] time: 0:02:51.813462 \n","[Epoch 400/1000] [Batch 1/1] [D loss: 0.148647, acc:  77%] [G loss: 4.213449, adv: 0.681727, recon: 0.129803, id: 0.123085] time: 0:03:16.383405 \n","[Epoch 450/1000] [Batch 1/1] [D loss: 0.149574, acc:  83%] [G loss: 4.840109, adv: 0.792818, recon: 0.147080, id: 0.122976] time: 0:03:40.971542 \n","[Epoch 500/1000] [Batch 1/1] [D loss: 0.115868, acc:  85%] [G loss: 4.901987, adv: 0.747873, recon: 0.155216, id: 0.125453] time: 0:04:05.494951 \n","[Epoch 550/1000] [Batch 1/1] [D loss: 0.119987, acc:  88%] [G loss: 4.879803, adv: 0.782883, recon: 0.150217, id: 0.115030] time: 0:04:30.302909 \n","[Epoch 600/1000] [Batch 1/1] [D loss: 0.104776, acc:  87%] [G loss: 5.089594, adv: 0.783848, recon: 0.159738, id: 0.118157] time: 0:04:54.836991 \n","[Epoch 650/1000] [Batch 1/1] [D loss: 0.092738, acc:  90%] [G loss: 4.723754, adv: 0.836882, recon: 0.138392, id: 0.124529] time: 0:05:19.356678 \n","[Epoch 700/1000] [Batch 1/1] [D loss: 0.105966, acc:  88%] [G loss: 5.074728, adv: 0.789819, recon: 0.158303, id: 0.114786] time: 0:05:43.904280 \n","[Epoch 750/1000] [Batch 1/1] [D loss: 0.144585, acc:  89%] [G loss: 5.057285, adv: 0.876972, recon: 0.149860, id: 0.118613] time: 0:06:08.406979 \n","[Epoch 800/1000] [Batch 1/1] [D loss: 0.167773, acc:  76%] [G loss: 4.018471, adv: 0.677906, recon: 0.121378, id: 0.111812] time: 0:06:32.965880 \n","[Epoch 850/1000] [Batch 1/1] [D loss: 0.134944, acc:  81%] [G loss: 4.470574, adv: 0.739312, recon: 0.135539, id: 0.114852] time: 0:06:58.872026 \n","[Epoch 900/1000] [Batch 1/1] [D loss: 0.337012, acc:  85%] [G loss: 5.260684, adv: 1.292656, recon: 0.121434, id: 0.113083] time: 0:07:23.445747 \n","[Epoch 950/1000] [Batch 1/1] [D loss: 0.086502, acc:  89%] [G loss: 4.558759, adv: 0.814104, recon: 0.132981, id: 0.114177] time: 0:07:47.964618 \n","[Epoch 1000/1000] [Batch 1/1] [D loss: 0.119375, acc:  86%] [G loss: 4.665279, adv: 0.821012, recon: 0.137001, id: 0.120935] time: 0:08:12.511262 \n","2020-08-18T01:37:37.132595 End\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"IiJDE9xFL09G","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":383},"executionInfo":{"status":"ok","timestamp":1597715993427,"user_tz":-540,"elapsed":976430,"user":{"displayName":"Noboru Koike","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggp8njUb4jc54JrzfM5cQBkfiCdlz6nY17y8-1szg=s64","userId":"05156582812995850159"}},"outputId":"e30f96f5-6051-4f7e-80b0-fab3091eb891"},"source":["# Image A Count: 1, BatchSize:1, Steps: 1/1=1\n","gan.train(epochs=2000, batch_size=1, sample_interval=100, save_interval=-1)"],"execution_count":14,"outputs":[{"output_type":"stream","text":["2020-08-18T01:43:37.203050 Start 4\n","[Epoch 100/2000] [Batch 1/1] [D loss: 0.094207, acc:  88%] [G loss: 4.163815, adv: 0.785536, recon: 0.117927, id: 0.112077] time: 0:00:48.547211 \n","[Epoch 200/2000] [Batch 1/1] [D loss: 0.141208, acc:  83%] [G loss: 4.805613, adv: 0.861629, recon: 0.140377, id: 0.108036] time: 0:01:37.316037 \n","[Epoch 300/2000] [Batch 1/1] [D loss: 0.072740, acc:  94%] [G loss: 5.095047, adv: 0.968469, recon: 0.143137, id: 0.117908] time: 0:02:26.183923 \n","[Epoch 400/2000] [Batch 1/1] [D loss: 0.142356, acc:  83%] [G loss: 4.467903, adv: 0.809825, recon: 0.129422, id: 0.102555] time: 0:03:14.864970 \n","[Epoch 500/2000] [Batch 1/1] [D loss: 0.114978, acc:  86%] [G loss: 4.169961, adv: 0.796920, recon: 0.117422, id: 0.103919] time: 0:04:03.598859 \n","[Epoch 600/2000] [Batch 1/1] [D loss: 0.063974, acc:  93%] [G loss: 4.425746, adv: 0.818041, recon: 0.126624, id: 0.101952] time: 0:04:52.809832 \n","[Epoch 700/2000] [Batch 1/1] [D loss: 0.171978, acc:  80%] [G loss: 5.051221, adv: 1.051574, recon: 0.134182, id: 0.101005] time: 0:05:41.749456 \n","[Epoch 800/2000] [Batch 1/1] [D loss: 0.139585, acc:  80%] [G loss: 4.557961, adv: 0.793198, recon: 0.135337, id: 0.104215] time: 0:06:30.516654 \n","[Epoch 900/2000] [Batch 1/1] [D loss: 0.083231, acc:  91%] [G loss: 4.277554, adv: 0.843325, recon: 0.117882, id: 0.098327] time: 0:07:19.223252 \n","[Epoch 1000/2000] [Batch 1/1] [D loss: 0.044387, acc:  97%] [G loss: 4.417587, adv: 0.941420, recon: 0.115737, id: 0.099574] time: 0:08:07.958594 \n","[Epoch 1100/2000] [Batch 1/1] [D loss: 0.174277, acc:  77%] [G loss: 3.862025, adv: 0.552721, recon: 0.125192, id: 0.096806] time: 0:08:56.683964 \n","[Epoch 1200/2000] [Batch 1/1] [D loss: 0.069104, acc:  95%] [G loss: 3.956556, adv: 0.822848, recon: 0.105431, id: 0.094089] time: 0:09:45.349731 \n","[Epoch 1300/2000] [Batch 1/1] [D loss: 0.083557, acc:  94%] [G loss: 4.749475, adv: 0.811236, recon: 0.143219, id: 0.096683] time: 0:10:34.315648 \n","[Epoch 1400/2000] [Batch 1/1] [D loss: 0.042002, acc:  98%] [G loss: 4.981489, adv: 0.943157, recon: 0.141505, id: 0.092610] time: 0:11:23.252841 \n","[Epoch 1500/2000] [Batch 1/1] [D loss: 0.119310, acc:  81%] [G loss: 3.968873, adv: 0.738011, recon: 0.113848, id: 0.094415] time: 0:12:11.920891 \n","[Epoch 1600/2000] [Batch 1/1] [D loss: 0.163187, acc:  76%] [G loss: 4.020420, adv: 0.795806, recon: 0.111227, id: 0.093251] time: 0:13:00.585212 \n","[Epoch 1700/2000] [Batch 1/1] [D loss: 0.034003, acc:  98%] [G loss: 4.427685, adv: 0.991452, recon: 0.111725, id: 0.092573] time: 0:13:49.143080 \n","[Epoch 1800/2000] [Batch 1/1] [D loss: 0.083294, acc:  91%] [G loss: 4.341559, adv: 0.795179, recon: 0.125535, id: 0.096571] time: 0:14:37.691339 \n","[Epoch 1900/2000] [Batch 1/1] [D loss: 0.060801, acc:  95%] [G loss: 4.246264, adv: 0.884793, recon: 0.113443, id: 0.091082] time: 0:15:26.336500 \n","[Epoch 2000/2000] [Batch 1/1] [D loss: 0.035973, acc:  98%] [G loss: 4.561299, adv: 0.991381, recon: 0.118010, id: 0.091029] time: 0:16:15.402362 \n","2020-08-18T01:59:52.974740 End\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"SiU3nIhkPGzK","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}