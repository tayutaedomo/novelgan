{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"18_vangogh_img2_r2.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1aZ-MKAyHVJwFZ69KfEFhB6-_0444ygQp","authorship_tag":"ABX9TyOfVeYjxSYdE0R89pVC8pgP"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"UxqZT229H44v","colab_type":"text"},"source":["### vangogh2novel モデル作成、保存\n","trainA を画像2枚にして学習を実行する、画風色調が似ている人物画2枚\n","100+900+3000+3000+5000+1000+10000=23000 からの続き"]},{"cell_type":"code","metadata":{"id":"OquHoSSzGVBE","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":350},"executionInfo":{"status":"ok","timestamp":1597756510358,"user_tz":-540,"elapsed":2041,"user":{"displayName":"Noboru Koike","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggp8njUb4jc54JrzfM5cQBkfiCdlz6nY17y8-1szg=s64","userId":"05156582812995850159"}},"outputId":"461e8ab2-8c2d-413c-f3c0-6b2c5d24fd4c"},"source":["!nvidia-smi"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Tue Aug 18 13:15:09 2020       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 450.57       Driver Version: 418.67       CUDA Version: 10.1     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   37C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n","|                               |                      |                 ERR! |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"7dxxo4o8IFLM","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597756516104,"user_tz":-540,"elapsed":1913,"user":{"displayName":"Noboru Koike","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggp8njUb4jc54JrzfM5cQBkfiCdlz6nY17y8-1szg=s64","userId":"05156582812995850159"}}},"source":["from tensorflow_addons.layers import InstanceNormalization\n","from tensorflow.keras.layers import Input, Dropout, Concatenate\n","from tensorflow.keras.layers import LeakyReLU\n","from tensorflow.keras.layers import UpSampling2D, Conv2D\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.optimizers import Adam"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"tJ0seoYcIHk8","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597756517280,"user_tz":-540,"elapsed":583,"user":{"displayName":"Noboru Koike","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggp8njUb4jc54JrzfM5cQBkfiCdlz6nY17y8-1szg=s64","userId":"05156582812995850159"}}},"source":["import matplotlib.pyplot as plt\n","import numpy as np\n","import pandas as pd\n","import datetime\n","import os"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"0UoP6USwIJic","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597756521329,"user_tz":-540,"elapsed":1179,"user":{"displayName":"Noboru Koike","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggp8njUb4jc54JrzfM5cQBkfiCdlz6nY17y8-1szg=s64","userId":"05156582812995850159"}}},"source":["from glob import glob\n","import cv2\n","from matplotlib.pyplot import imread"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"8X1cVXVZILc_","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597756526313,"user_tz":-540,"elapsed":561,"user":{"displayName":"Noboru Koike","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggp8njUb4jc54JrzfM5cQBkfiCdlz6nY17y8-1szg=s64","userId":"05156582812995850159"}}},"source":["DATA_DIR_PATH = '/content/drive/My Drive/kikagaku/novelgan/data'\n","\n","OUTPUT_DIR_PATH = os.path.join(DATA_DIR_PATH, '18_out')"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"Zg5-CvCYIOKH","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597756529759,"user_tz":-540,"elapsed":1920,"user":{"displayName":"Noboru Koike","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggp8njUb4jc54JrzfM5cQBkfiCdlz6nY17y8-1szg=s64","userId":"05156582812995850159"}}},"source":["#os.makedirs(os.path.join(DATA_DIR_PATH, 'datasets'), exist_ok=True)\n","\n","os.makedirs(os.path.join(OUTPUT_DIR_PATH, 'images'), exist_ok=True)\n","os.makedirs(os.path.join(OUTPUT_DIR_PATH, 'saved_models'), exist_ok=True)"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"AcdUhck_IQOU","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597756530959,"user_tz":-540,"elapsed":598,"user":{"displayName":"Noboru Koike","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggp8njUb4jc54JrzfM5cQBkfiCdlz6nY17y8-1szg=s64","userId":"05156582812995850159"}}},"source":["class DataLoader():\n","    def __init__(self, dataset_name, img_res=(256, 256)):\n","        self.dataset_name = dataset_name\n","        self.img_res = img_res\n","        self.datasets_path = os.path.join(DATA_DIR_PATH, 'datasets')\n","\n","    def load_data(self, domain, batch_size=1, is_testing=False):\n","        data_type = \"train%s\" % domain if not is_testing else \"test%s\" % domain\n","        #path = glob('./datasets/%s/%s/*' % (self.dataset_name, data_type))\n","        path = glob(os.path.join(self.datasets_path, self.dataset_name, data_type, '*'))\n","\n","        batch_images = np.random.choice(path, size=batch_size)\n","\n","        imgs = []\n","        for img_path in batch_images:\n","            img = self.imread(img_path)\n","            if not is_testing:\n","                #img = scipy.misc.imresize(img, self.img_res)\n","                img = cv2.resize(img, self.img_res)\n","\n","                if np.random.random() > 0.5:\n","                    img = np.fliplr(img)\n","            else:\n","                #img = scipy.misc.imresize(img, self.img_res)\n","                img = cv2.resize(img, self.img_res)\n","            imgs.append(img)\n","\n","        imgs = np.array(imgs)/127.5 - 1.\n","\n","        return imgs\n","\n","    def load_batch(self, batch_size=1, is_testing=False):\n","        data_type = \"train\" if not is_testing else \"val\"\n","        #path_A = glob('./datasets/%s/%sA/*' % (self.dataset_name, data_type))\n","        #path_B = glob('./datasets/%s/%sB/*' % (self.dataset_name, data_type))\n","        path_A = glob(os.path.join(self.datasets_path, self.dataset_name, '{}A'.format(data_type), '*'))\n","        path_B = glob(os.path.join(self.datasets_path, self.dataset_name, '{}B'.format(data_type), '*'))\n","\n","        self.n_batches = int(min(len(path_A), len(path_B)) / batch_size)\n","        total_samples = self.n_batches * batch_size\n","\n","        # Sample n_batches * batch_size from each path list so that model sees all\n","        # samples from both domains\n","        path_A = np.random.choice(path_A, total_samples, replace=False)\n","        path_B = np.random.choice(path_B, total_samples, replace=False)\n","\n","        #for i in range(self.n_batches-1):\n","        for i in range(self.n_batches):\n","            batch_A = path_A[i*batch_size:(i+1)*batch_size]\n","            batch_B = path_B[i*batch_size:(i+1)*batch_size]\n","            imgs_A, imgs_B = [], []\n","\n","            for img_A, img_B in zip(batch_A, batch_B):\n","                img_A = self.imread(img_A)\n","                img_B = self.imread(img_B)\n","\n","                #img_A = scipy.misc.imresize(img_A, self.img_res)\n","                img_A = cv2.resize(img_A, self.img_res)\n","                #img_B = scipy.misc.imresize(img_B, self.img_res)\n","                img_B = cv2.resize(img_B, self.img_res)\n","\n","                if not is_testing and np.random.random() > 0.5:\n","                    img_A = np.fliplr(img_A)\n","                    img_B = np.fliplr(img_B)\n","\n","                imgs_A.append(img_A)\n","                imgs_B.append(img_B)\n","\n","            imgs_A = np.array(imgs_A)/127.5 - 1.\n","            imgs_B = np.array(imgs_B)/127.5 - 1.\n","\n","            yield imgs_A, imgs_B\n","\n","    def load_img(self, path):\n","        img = self.imread(path)\n","        #img = scipy.misc.imresize(img, self.img_res)\n","        img = cv2.resize(img, self.img_res)\n","        img = img/127.5 - 1.\n","        return img[np.newaxis, :, :, :]\n","\n","    def imread(self, path):\n","        #return scipy.misc.imread(path, mode='RGB').astype(np.float)\n","        return imread(path).astype(np.float)"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"jE1BiGQqIR3b","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597756534327,"user_tz":-540,"elapsed":537,"user":{"displayName":"Noboru Koike","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggp8njUb4jc54JrzfM5cQBkfiCdlz6nY17y8-1szg=s64","userId":"05156582812995850159"}}},"source":["IMG_ROWS = 256\n","IMG_COLS = 256\n","\n","data_loader = DataLoader('vangogh2novel_4', img_res=(IMG_ROWS, IMG_COLS))"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"PAqis8M3IUly","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597756536573,"user_tz":-540,"elapsed":1461,"user":{"displayName":"Noboru Koike","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggp8njUb4jc54JrzfM5cQBkfiCdlz6nY17y8-1szg=s64","userId":"05156582812995850159"}}},"source":["class CycleGAN:\n","    def __init__(self):\n","        self.history = pd.DataFrame({}, columns=[\n","            'epoch', 'epochs', 'batch_idx', 'batch_num', 'd_loss', 'acc', 'g_loss',\n","            'adv', 'recon', 'id', 'elapsed_time'])\n","\n","        self.img_save_dir = os.path.join(OUTPUT_DIR_PATH, 'images')\n","        self.model_save_dir = os.path.join(OUTPUT_DIR_PATH, 'saved_models')\n","        self.combined_name = 'combined_model'\n","        self.g_AB_name = 'g_AB_model'\n","        self.g_BA_name = 'g_BA_model'\n","\n","        self.train_cnt = 0\n","\n","        # Input shape\n","        self.img_rows = IMG_ROWS\n","        self.img_cols = IMG_COLS\n","        self.channels = 3\n","        self.img_shape = (self.img_rows, self.img_cols, self.channels)\n","\n","        self.d_A = None\n","        self.d_B = None\n","        self.g_AB = None\n","        self.g_BA = None\n","        self.combined = None\n","\n","    def init(self, data_loader=None):\n","        # Configure data loader\n","        #self.dataset_name = 'apple2orange'\n","        #self.data_loader = DataLoader(dataset_name=self.dataset_name,\n","        #                              img_res=(self.img_rows, self.img_cols))\n","        if data_loader:\n","            self.data_loader = data_loader\n","            self.dataset_name = self.data_loader.dataset_name \n","\n","        # Calculate output shape of D (PatchGAN)\n","        patch = int(self.img_rows / 2**4)\n","        self.disc_patch = (patch, patch, 1)\n","\n","        # Number of filters in the first layer of G and D\n","        #self.gf = 32 # U-Net, 128\n","        self.gf = 64\n","        self.df = 64\n","\n","        # Loss weights\n","        self.lambda_cycle = 10.0                    # Cycle-consistency loss\n","        self.lambda_id = 0.1 * self.lambda_cycle    # Identity loss\n","\n","        optimizer = Adam(0.0002, 0.5)\n","\n","        # Build and compile the discriminators\n","        self.d_A = self.build_discriminator()\n","        self.d_B = self.build_discriminator()\n","        self.d_A.compile(loss='mse',\n","                         optimizer=optimizer,\n","                         metrics=['accuracy'])\n","        self.d_B.compile(loss='mse',\n","                         optimizer=optimizer,\n","                         metrics=['accuracy'])\n","\n","        # Build the generators\n","        self.g_AB = self.build_generator()\n","        self.g_BA = self.build_generator()\n","\n","        # Input images from both domains\n","        img_A = Input(shape=self.img_shape)\n","        img_B = Input(shape=self.img_shape)\n","\n","        # Translate images to the other domain\n","        fake_B = self.g_AB(img_A)\n","        fake_A = self.g_BA(img_B)\n","\n","        # Translate images back to original domain\n","        reconstr_A = self.g_BA(fake_B)\n","        reconstr_B = self.g_AB(fake_A)\n","\n","        # Identity mapping of images\n","        img_A_id = self.g_BA(img_A)\n","        img_B_id = self.g_AB(img_B)\n","\n","        # For the combined model we will only train the generators\n","        self.d_A.trainable = False\n","        self.d_B.trainable = False\n","\n","        # Discriminators determines validity of translated images\n","        valid_A = self.d_A(fake_A)\n","        valid_B = self.d_B(fake_B)\n","\n","        # Combined model trains generators to fool discriminators\n","        self.combined = Model(inputs=[img_A, img_B],\n","                              outputs=[valid_A, valid_B,\n","                                       reconstr_A, reconstr_B,\n","                                       img_A_id, img_B_id ])\n","        self.combined.compile(loss=['mse', 'mse',\n","                                    'mae', 'mae',\n","                                    'mae', 'mae'],\n","                              loss_weights=[1, 1,\n","                                            self.lambda_cycle, self.lambda_cycle,\n","                                            self.lambda_id, self.lambda_id ],\n","                              optimizer=optimizer)\n","\n","    def build_generator(self):\n","        \"\"\"U-Net Generator\"\"\"\n","\n","        def conv2d(layer_input, filters, f_size=4):\n","            \"\"\"Layers used during downsampling\"\"\"\n","            d = Conv2D(filters, kernel_size=f_size, strides=2, padding='same')(layer_input)\n","            d = LeakyReLU(alpha=0.2)(d)\n","            d = InstanceNormalization()(d)\n","            return d\n","\n","        def deconv2d(layer_input, skip_input, filters, f_size=4, dropout_rate=0):\n","            \"\"\"Layers used during upsampling\"\"\"\n","            u = UpSampling2D(size=2)(layer_input)\n","            u = Conv2D(filters, kernel_size=f_size, strides=1, padding='same', activation='relu')(u)\n","            if dropout_rate:\n","                u = Dropout(dropout_rate)(u)\n","            u = InstanceNormalization()(u)\n","            u = Concatenate()([u, skip_input])\n","            return u\n","\n","        # Image input\n","        d0 = Input(shape=self.img_shape)\n","\n","        # U-Net, 12\n","        ## Downsampling\n","        #d1 = conv2d(d0, self.gf)\n","        #d2 = conv2d(d1, self.gf*2)\n","        #d3 = conv2d(d2, self.gf*4)\n","        #d4 = conv2d(d3, self.gf*8)\n","        #\n","        ## Upsampling\n","        #u1 = deconv2d(d4, d3, self.gf*4)\n","        #u2 = deconv2d(u1, d2, self.gf*2)\n","        #u3 = deconv2d(u2, d1, self.gf)\n","        #\n","        #u4 = UpSampling2D(size=2)(u3)\n","        #output_img = Conv2D(self.channels, kernel_size=4, strides=1, padding='same', activation='tanh')(u4)\n","\n","        # Downsampling\n","        d1 = conv2d(d0, self.gf)\n","        d2 = conv2d(d1, self.gf*2)\n","        d3 = conv2d(d2, self.gf*4)\n","        d4 = conv2d(d3, self.gf*8)\n","        d5 = conv2d(d4, self.gf*8)\n","        d6 = conv2d(d5, self.gf*8)\n","        d7 = conv2d(d6, self.gf*8)\n","\n","        # Upsampling\n","        u1 = deconv2d(d7, d6, self.gf*8)\n","        u2 = deconv2d(u1, d5, self.gf*8)\n","        u3 = deconv2d(u2, d4, self.gf*8)\n","        u4 = deconv2d(u3, d3, self.gf*4)\n","        u5 = deconv2d(u4, d2, self.gf*2)\n","        u6 = deconv2d(u5, d1, self.gf)\n","\n","        u7 = UpSampling2D(size=2)(u6)\n","        output_img = Conv2D(self.channels, kernel_size=4, strides=1, padding='same', activation='tanh')(u7)\n","\n","        return Model(d0, output_img)\n","\n","    def build_discriminator(self):\n","\n","        def d_layer(layer_input, filters, f_size=4, normalization=True):\n","            \"\"\"Discriminator layer\"\"\"\n","            d = Conv2D(filters, kernel_size=f_size, strides=2, padding='same')(layer_input)\n","            d = LeakyReLU(alpha=0.2)(d)\n","            if normalization:\n","                d = InstanceNormalization()(d)\n","            return d\n","\n","        img = Input(shape=self.img_shape)\n","\n","        d1 = d_layer(img, self.df, normalization=False)\n","        d2 = d_layer(d1, self.df*2)\n","        d3 = d_layer(d2, self.df*4)\n","        d4 = d_layer(d3, self.df*8)\n","\n","        validity = Conv2D(1, kernel_size=4, strides=1, padding='same')(d4)\n","\n","        return Model(img, validity)\n","\n","    def train(self, epochs, batch_size=1, sample_interval=-1, save_interval=-1):\n","        self.train_cnt += 1\n","\n","        print(datetime.datetime.now().isoformat(), 'Start', self.train_cnt)\n","\n","        start_time = datetime.datetime.now()\n","\n","        # Adversarial loss ground truths\n","        valid = np.ones((batch_size,) + self.disc_patch)\n","        fake = np.zeros((batch_size,) + self.disc_patch)\n","\n","        step_cnt = 1\n","\n","        #for epoch in range(epochs):\n","        for epoch in range(1, epochs+1):\n","            #for batch_i, (imgs_A, imgs_B) in enumerate(self.data_loader.load_batch(batch_size)):\n","            for batch_i, (imgs_A, imgs_B) in enumerate(self.data_loader.load_batch(batch_size), 1):\n","\n","                # Translate images to opposite domain\n","                fake_B = self.g_AB.predict(imgs_A)\n","                fake_A = self.g_BA.predict(imgs_B)\n","\n","                # Train the discriminators (original images = real / translated = Fake)\n","                dA_loss_real = self.d_A.train_on_batch(imgs_A, valid)\n","                dA_loss_fake = self.d_A.train_on_batch(fake_A, fake)\n","                dA_loss = 0.5 * np.add(dA_loss_real, dA_loss_fake)\n","\n","                dB_loss_real = self.d_B.train_on_batch(imgs_B, valid)\n","                dB_loss_fake = self.d_B.train_on_batch(fake_B, fake)\n","                dB_loss = 0.5 * np.add(dB_loss_real, dB_loss_fake)\n","\n","                # Total disciminator loss\n","                d_loss = 0.5 * np.add(dA_loss, dB_loss)\n","\n","                # Train the generators\n","                g_loss = self.combined.train_on_batch([imgs_A, imgs_B],\n","                                                      [valid, valid,\n","                                                       imgs_A, imgs_B,\n","                                                       imgs_A, imgs_B])\n","\n","                elapsed_time = datetime.datetime.now() - start_time\n","\n","                # Plot the progress\n","                # print(\"[Epoch %d/%d] [Batch %d/%d] [D loss: %f, acc: %3d%%] [G loss: %05f, adv: %05f, recon: %05f, id: %05f] time: %s \" % (\n","                #     epoch, epochs,\n","                #     batch_i, self.data_loader.n_batches,\n","                #     d_loss[0], 100*d_loss[1],\n","                #     g_loss[0],\n","                #     np.mean(g_loss[1:3]),\n","                #     np.mean(g_loss[3:5]),\n","                #     np.mean(g_loss[5:6]),\n","                #     elapsed_time))\n","                self.history = self.history.append({\n","                    'epoch': epoch,\n","                    'epochs': epochs,\n","                    'batch_idx': batch_i,\n","                    'batch_num': self.data_loader.n_batches,\n","                    'd_loss': d_loss[0],\n","                    'acc': d_loss[1],\n","                    'g_loss': g_loss[0],\n","                    'adv': np.mean(g_loss[1:3]),\n","                    'recon': np.mean(g_loss[3:5]),\n","                    'id': np.mean(g_loss[5:6]),\n","                    'elapsed_time': elapsed_time\n","                }, ignore_index=True)\n","\n","                # If at save interval => save generated image samples\n","                #if sample_interval > 0 and batch_i % sample_interval == 0:\n","                if sample_interval > 0 and step_cnt % sample_interval == 0:\n","                    print(\"[Epoch %d/%d] [Batch %d/%d] [D loss: %f, acc: %3d%%] [G loss: %05f, adv: %05f, recon: %05f, id: %05f] time: %s \" % (\n","                        epoch, epochs,\n","                        batch_i, self.data_loader.n_batches,\n","                        d_loss[0], 100*d_loss[1],\n","                        g_loss[0],\n","                        np.mean(g_loss[1:3]),\n","                        np.mean(g_loss[3:5]),\n","                        np.mean(g_loss[5:6]),\n","                        elapsed_time))\n","\n","                    self.sample_images(epoch, batch_i)\n","\n","                #if save_interval > 0 and batch_i != 1 and (batch_i % save_interval) == 0:\n","                if save_interval > 0 and step_cnt % save_interval == 0:\n","                    file_suffix = '{}_{}_{}'.format(self.train_cnt, epoch, batch_i)\n","                    self.save_model_weights(self.combined, self.combined_name, file_suffix)\n","\n","                step_cnt += 1\n","\n","        print(datetime.datetime.now().isoformat(), 'End')\n","\n","    def generate_image_A(self, img):\n","        return self.g_AB.predict(img)\n","\n","    def generate_image_B(self, img):\n","        return self.g_BA.predict(img)\n","\n","    def sample_images(self, epoch, batch_i):\n","        dir_path = os.path.join(self.img_save_dir, self.dataset_name)\n","\n","        #os.makedirs('images/%s' % self.dataset_name, exist_ok=True)\n","        os.makedirs(dir_path, exist_ok=True)\n","\n","        r, c = 2, 3\n","\n","        imgs_A = self.data_loader.load_data(domain=\"A\", batch_size=1, is_testing=True)\n","        imgs_B = self.data_loader.load_data(domain=\"B\", batch_size=1, is_testing=True)\n","\n","        # Demo (for GIF)\n","        #imgs_A = self.data_loader.load_img('datasets/apple2orange/testA/n07740461_1541.jpg')\n","        #imgs_B = self.data_loader.load_img('datasets/apple2orange/testB/n07749192_4241.jpg')\n","\n","        # Translate images to the other domain\n","        fake_B = self.g_AB.predict(imgs_A)\n","        fake_A = self.g_BA.predict(imgs_B)\n","\n","        # Translate back to original domain\n","        reconstr_A = self.g_BA.predict(fake_B)\n","        reconstr_B = self.g_AB.predict(fake_A)\n","\n","        gen_imgs = np.concatenate([imgs_A, fake_B, reconstr_A, imgs_B, fake_A, reconstr_B])\n","\n","        # Rescale images 0 - 1\n","        gen_imgs = 0.5 * gen_imgs + 0.5\n","\n","        titles = ['Original', 'Translated', 'Reconstructed']\n","        fig, axs = plt.subplots(r, c)\n","        cnt = 0\n","\n","        for i in range(r):\n","            for j in range(c):\n","                axs[i, j].imshow(gen_imgs[cnt])\n","                axs[i, j].set_title(titles[j])\n","                axs[i, j].axis('off')\n","                cnt += 1\n","\n","        #fig.savefig(\"images/%s/%d_%d.png\" % (self.dataset_name, epoch, batch_i))\n","        file_path = os.path.join(dir_path, '{}_{}_{}.png'.format(self.train_cnt, epoch, batch_i))\n","        fig.savefig(file_path)\n","\n","        plt.close()\n","\n","    def plot_hisotry(self, columns=[]):\n","        if len(columns) == 0:\n","            columns = ['d_loss', 'g_loss']\n","            #columns = ['d_loss', 'acc', 'g_loss', 'adv', 'recon', 'id',]\n","        self.history[columns].plot()\n","\n","    def save_models(self, file_suffix=None):\n","        self.save_model_weights(self.combined, self.combined_name, file_suffix)\n","        #self.save_model_weights(self.g_AB, self.g_AB_name, file_suffix)\n","        #self.save_model_weights(self.g_BA, self.g_BA_name, file_suffix)\n","\n","    def save_model_weights(self, model, model_name, file_suffix=None):\n","        file_path = os.path.join(self.model_save_dir, self._create_h5_file_name(model_name, file_suffix))\n","        model.save_weights(file_path)\n","\n","        print('Model weights saved.', model_name)\n","\n","    def load_models(self, file_suffix=None):\n","        self.load_model_weights(self.combined_name, file_suffix)\n","        self.load_model_weights(self.g_AB_name, file_suffix)\n","        self.load_model_weights(self.g_BA_name, file_suffix)\n","\n","    def load_model_weights(self, model_name, file_suffix=None):\n","        model = None\n","\n","        if model_name == self.combined_name:\n","            model = self.combined\n","        elif model_name == self.g_AB_name:\n","            model = self.g_AB\n","        elif model_name == self.g_BA_name:\n","            model = self.g_BA\n","        else:\n","            print('Unsupported.', model_name)\n","            return\n","\n","        if not model:\n","            print('Not initialized.', model_name)\n","            return\n","\n","        file_path = os.path.join(self.model_save_dir, self._create_h5_file_name(model_name, file_suffix))\n","\n","        if not os.path.exists(file_path):\n","            print('File Not found.', model_name)\n","            return\n","\n","        model.load_weights(file_path)\n","\n","        print('Model weights loaded.', model_name)\n","\n","    def _create_h5_file_name(self, model_name, suffix=None):\n","        if suffix:\n","            return '{}_{}.h5'.format(model_name, suffix)\n","        else:\n","            return '{}.h5'.format(model_name)"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"vtp6KwZxIWO5","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":66},"executionInfo":{"status":"ok","timestamp":1597756572647,"user_tz":-540,"elapsed":16523,"user":{"displayName":"Noboru Koike","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggp8njUb4jc54JrzfM5cQBkfiCdlz6nY17y8-1szg=s64","userId":"05156582812995850159"}},"outputId":"5be788d3-6164-4bbe-843f-45d5abbce88e"},"source":["gan = CycleGAN()\n","gan.init(data_loader=data_loader)\n","gan.load_models('17_oout_7_10000_2')"],"execution_count":10,"outputs":[{"output_type":"stream","text":["Model weights loaded. combined_model\n","File Not found. g_AB_model\n","File Not found. g_BA_model\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"uPzRLtZxImHy","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1597814699663,"user_tz":-540,"elapsed":58042508,"user":{"displayName":"Noboru Koike","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggp8njUb4jc54JrzfM5cQBkfiCdlz6nY17y8-1szg=s64","userId":"05156582812995850159"}},"outputId":"4d034d7e-d54b-463f-a2c4-c75f5c25726d"},"source":["# Image A Count: 2, BatchSize:1, Steps: 2/1=2\n","gan.train(epochs=60000, batch_size=1, sample_interval=2*250, save_interval=2*1000)"],"execution_count":11,"outputs":[{"output_type":"stream","text":["2020-08-18T13:17:37.351027 Start 1\n","[Epoch 250/60000] [Batch 2/2] [D loss: 0.002492, acc: 100%] [G loss: 3.252234, adv: 0.995125, recon: 0.056730, id: 0.049175] time: 0:04:42.877678 \n","[Epoch 500/60000] [Batch 2/2] [D loss: 0.002235, acc: 100%] [G loss: 3.077176, adv: 0.986190, recon: 0.048116, id: 0.043255] time: 0:08:40.678056 \n","[Epoch 750/60000] [Batch 2/2] [D loss: 0.009199, acc: 100%] [G loss: 3.168179, adv: 1.031410, recon: 0.048024, id: 0.040325] time: 0:12:38.339162 \n","[Epoch 1000/60000] [Batch 2/2] [D loss: 0.001475, acc: 100%] [G loss: 2.921271, adv: 0.998122, recon: 0.040906, id: 0.037913] time: 0:16:35.106445 \n","Model weights saved. combined_model\n","[Epoch 1250/60000] [Batch 2/2] [D loss: 0.001139, acc: 100%] [G loss: 2.981542, adv: 1.002380, recon: 0.043188, id: 0.039264] time: 0:20:34.454806 \n","[Epoch 1500/60000] [Batch 2/2] [D loss: 0.001472, acc: 100%] [G loss: 2.793283, adv: 1.005165, recon: 0.034470, id: 0.035535] time: 0:24:31.825597 \n","[Epoch 1750/60000] [Batch 2/2] [D loss: 0.002194, acc: 100%] [G loss: 2.993388, adv: 1.003684, recon: 0.042837, id: 0.036948] time: 0:28:29.377833 \n","[Epoch 2000/60000] [Batch 2/2] [D loss: 0.000892, acc: 100%] [G loss: 3.009367, adv: 0.992079, recon: 0.045589, id: 0.036770] time: 0:32:26.165248 \n","Model weights saved. combined_model\n","[Epoch 2250/60000] [Batch 2/2] [D loss: 0.001623, acc: 100%] [G loss: 3.124481, adv: 0.991616, recon: 0.050332, id: 0.036195] time: 0:36:24.568449 \n","[Epoch 2500/60000] [Batch 2/2] [D loss: 0.000695, acc: 100%] [G loss: 2.898456, adv: 1.006197, recon: 0.038963, id: 0.035119] time: 0:40:21.653816 \n","[Epoch 2750/60000] [Batch 2/2] [D loss: 0.002147, acc: 100%] [G loss: 3.087377, adv: 1.014263, recon: 0.046299, id: 0.035091] time: 0:44:18.723441 \n","[Epoch 3000/60000] [Batch 2/2] [D loss: 0.002509, acc: 100%] [G loss: 2.976249, adv: 1.007428, recon: 0.042399, id: 0.035639] time: 0:48:16.079145 \n","Model weights saved. combined_model\n","[Epoch 3250/60000] [Batch 2/2] [D loss: 0.000844, acc: 100%] [G loss: 2.975728, adv: 0.994260, recon: 0.043047, id: 0.034456] time: 0:52:15.185439 \n","[Epoch 3500/60000] [Batch 2/2] [D loss: 0.000795, acc: 100%] [G loss: 3.133729, adv: 1.001878, recon: 0.048605, id: 0.034747] time: 0:56:13.126818 \n","[Epoch 3750/60000] [Batch 2/2] [D loss: 0.003417, acc: 100%] [G loss: 3.095959, adv: 1.006982, recon: 0.047619, id: 0.035800] time: 1:00:10.834411 \n","[Epoch 4000/60000] [Batch 2/2] [D loss: 0.001089, acc: 100%] [G loss: 3.204398, adv: 0.995629, recon: 0.054902, id: 0.034461] time: 1:04:07.497413 \n","Model weights saved. combined_model\n","[Epoch 4250/60000] [Batch 2/2] [D loss: 0.000946, acc: 100%] [G loss: 2.925573, adv: 0.994376, recon: 0.041004, id: 0.035750] time: 1:08:07.473776 \n","[Epoch 4500/60000] [Batch 2/2] [D loss: 0.000842, acc: 100%] [G loss: 2.999197, adv: 0.992539, recon: 0.044316, id: 0.034891] time: 1:12:04.594251 \n","[Epoch 4750/60000] [Batch 2/2] [D loss: 0.001230, acc: 100%] [G loss: 2.913209, adv: 0.998105, recon: 0.040318, id: 0.033995] time: 1:16:02.083954 \n","[Epoch 5000/60000] [Batch 2/2] [D loss: 0.001144, acc: 100%] [G loss: 3.112385, adv: 1.003531, recon: 0.048024, id: 0.032845] time: 1:19:59.391656 \n","Model weights saved. combined_model\n","[Epoch 5250/60000] [Batch 2/2] [D loss: 0.054793, acc:  93%] [G loss: 3.202306, adv: 1.056711, recon: 0.048627, id: 0.033487] time: 1:23:58.381583 \n","[Epoch 5500/60000] [Batch 2/2] [D loss: 0.001972, acc: 100%] [G loss: 3.163278, adv: 0.998228, recon: 0.051511, id: 0.033637] time: 1:27:56.091590 \n","[Epoch 5750/60000] [Batch 2/2] [D loss: 0.001383, acc: 100%] [G loss: 2.893611, adv: 0.995742, recon: 0.039576, id: 0.048300] time: 1:31:54.069711 \n","[Epoch 6000/60000] [Batch 2/2] [D loss: 0.000474, acc: 100%] [G loss: 2.916594, adv: 1.000157, recon: 0.040585, id: 0.035470] time: 1:35:53.170841 \n","Model weights saved. combined_model\n","[Epoch 6250/60000] [Batch 2/2] [D loss: 0.001274, acc: 100%] [G loss: 2.992543, adv: 1.001192, recon: 0.043147, id: 0.033466] time: 1:39:54.374047 \n","[Epoch 6500/60000] [Batch 2/2] [D loss: 0.002813, acc: 100%] [G loss: 2.879241, adv: 1.028460, recon: 0.036054, id: 0.033501] time: 1:43:55.003824 \n","[Epoch 6750/60000] [Batch 2/2] [D loss: 0.001036, acc: 100%] [G loss: 3.083622, adv: 0.999295, recon: 0.047754, id: 0.032187] time: 1:47:55.421768 \n","[Epoch 7000/60000] [Batch 2/2] [D loss: 0.001047, acc: 100%] [G loss: 2.922172, adv: 0.999458, recon: 0.040327, id: 0.033564] time: 1:51:57.229650 \n","Model weights saved. combined_model\n","[Epoch 7250/60000] [Batch 2/2] [D loss: 0.000415, acc: 100%] [G loss: 2.856344, adv: 1.000759, recon: 0.037722, id: 0.036978] time: 1:56:01.782861 \n","[Epoch 7500/60000] [Batch 2/2] [D loss: 0.001039, acc: 100%] [G loss: 3.009697, adv: 0.996933, recon: 0.043794, id: 0.034103] time: 2:00:02.823036 \n","[Epoch 7750/60000] [Batch 2/2] [D loss: 0.002017, acc: 100%] [G loss: 2.852823, adv: 1.014732, recon: 0.035925, id: 0.032741] time: 2:04:03.954678 \n","[Epoch 8000/60000] [Batch 2/2] [D loss: 0.002344, acc: 100%] [G loss: 3.023611, adv: 1.031920, recon: 0.042108, id: 0.033099] time: 2:08:04.589886 \n","Model weights saved. combined_model\n","[Epoch 8250/60000] [Batch 2/2] [D loss: 0.000776, acc: 100%] [G loss: 2.878660, adv: 0.993881, recon: 0.038388, id: 0.032815] time: 2:12:07.670471 \n","[Epoch 8500/60000] [Batch 2/2] [D loss: 0.001172, acc: 100%] [G loss: 2.869566, adv: 1.004438, recon: 0.037834, id: 0.032091] time: 2:16:08.638061 \n","[Epoch 8750/60000] [Batch 2/2] [D loss: 0.001182, acc: 100%] [G loss: 2.808273, adv: 1.000150, recon: 0.034505, id: 0.031878] time: 2:20:10.594348 \n","[Epoch 9000/60000] [Batch 2/2] [D loss: 0.000451, acc: 100%] [G loss: 3.091960, adv: 0.999176, recon: 0.047894, id: 0.031079] time: 2:24:10.899435 \n","Model weights saved. combined_model\n","[Epoch 9250/60000] [Batch 2/2] [D loss: 0.000883, acc: 100%] [G loss: 2.867393, adv: 0.994366, recon: 0.038414, id: 0.031042] time: 2:28:11.861697 \n","[Epoch 9500/60000] [Batch 2/2] [D loss: 0.000640, acc: 100%] [G loss: 2.803405, adv: 1.000889, recon: 0.035203, id: 0.031306] time: 2:32:11.034186 \n","[Epoch 9750/60000] [Batch 2/2] [D loss: 0.005551, acc: 100%] [G loss: 2.747450, adv: 0.977115, recon: 0.034629, id: 0.030703] time: 2:36:10.752131 \n","[Epoch 10000/60000] [Batch 2/2] [D loss: 0.000437, acc: 100%] [G loss: 2.895790, adv: 1.003294, recon: 0.039209, id: 0.031935] time: 2:40:10.185224 \n","Model weights saved. combined_model\n","[Epoch 10250/60000] [Batch 2/2] [D loss: 0.001682, acc: 100%] [G loss: 2.877902, adv: 1.030934, recon: 0.035855, id: 0.030709] time: 2:44:11.685104 \n","[Epoch 10500/60000] [Batch 2/2] [D loss: 0.001274, acc: 100%] [G loss: 2.874891, adv: 1.016227, recon: 0.036737, id: 0.030443] time: 2:48:11.676562 \n","[Epoch 10750/60000] [Batch 2/2] [D loss: 0.001631, acc: 100%] [G loss: 4.590541, adv: 0.990283, recon: 0.119595, id: 0.104569] time: 2:52:11.040356 \n","[Epoch 11000/60000] [Batch 2/2] [D loss: 0.000500, acc: 100%] [G loss: 2.917527, adv: 1.002546, recon: 0.040476, id: 0.035979] time: 2:56:10.665132 \n","Model weights saved. combined_model\n","[Epoch 11250/60000] [Batch 2/2] [D loss: 0.000418, acc: 100%] [G loss: 2.752491, adv: 1.000673, recon: 0.033106, id: 0.033952] time: 3:00:12.904894 \n","[Epoch 11500/60000] [Batch 2/2] [D loss: 0.001092, acc: 100%] [G loss: 2.915370, adv: 0.997445, recon: 0.039843, id: 0.032617] time: 3:04:12.844893 \n","[Epoch 11750/60000] [Batch 2/2] [D loss: 0.003872, acc: 100%] [G loss: 2.904127, adv: 1.059605, recon: 0.033709, id: 0.031861] time: 3:08:12.327807 \n","[Epoch 12000/60000] [Batch 2/2] [D loss: 0.001261, acc: 100%] [G loss: 2.900554, adv: 0.998297, recon: 0.038714, id: 0.031600] time: 3:12:12.409228 \n","Model weights saved. combined_model\n","[Epoch 12250/60000] [Batch 2/2] [D loss: 0.000631, acc: 100%] [G loss: 2.806669, adv: 1.005840, recon: 0.034671, id: 0.030748] time: 3:16:13.884164 \n","[Epoch 12500/60000] [Batch 2/2] [D loss: 0.001079, acc: 100%] [G loss: 2.819339, adv: 0.997884, recon: 0.035788, id: 0.031119] time: 3:20:13.699247 \n","[Epoch 12750/60000] [Batch 2/2] [D loss: 0.000701, acc: 100%] [G loss: 2.803017, adv: 0.997333, recon: 0.035257, id: 0.030484] time: 3:24:13.710600 \n","[Epoch 13000/60000] [Batch 2/2] [D loss: 0.001265, acc: 100%] [G loss: 2.858702, adv: 0.994358, recon: 0.037445, id: 0.031136] time: 3:28:13.464400 \n","Model weights saved. combined_model\n","[Epoch 13250/60000] [Batch 2/2] [D loss: 0.000558, acc: 100%] [G loss: 2.918375, adv: 0.995313, recon: 0.040269, id: 0.030507] time: 3:32:14.993278 \n","[Epoch 13500/60000] [Batch 2/2] [D loss: 0.000464, acc: 100%] [G loss: 2.848481, adv: 0.998338, recon: 0.036647, id: 0.031105] time: 3:36:14.710711 \n","[Epoch 13750/60000] [Batch 2/2] [D loss: 0.001594, acc: 100%] [G loss: 2.903777, adv: 1.025076, recon: 0.037226, id: 0.029155] time: 3:40:14.012736 \n","[Epoch 14000/60000] [Batch 2/2] [D loss: 0.000449, acc: 100%] [G loss: 2.968223, adv: 1.004913, recon: 0.042608, id: 0.030423] time: 3:44:13.385658 \n","Model weights saved. combined_model\n","[Epoch 14250/60000] [Batch 2/2] [D loss: 0.001867, acc: 100%] [G loss: 3.084063, adv: 1.004855, recon: 0.047528, id: 0.030157] time: 3:48:15.116863 \n","[Epoch 14500/60000] [Batch 2/2] [D loss: 0.000799, acc: 100%] [G loss: 2.884366, adv: 0.983104, recon: 0.040566, id: 0.030008] time: 3:52:14.706003 \n","[Epoch 14750/60000] [Batch 2/2] [D loss: 0.000605, acc: 100%] [G loss: 2.998629, adv: 1.000955, recon: 0.042100, id: 0.030054] time: 3:56:14.020257 \n","[Epoch 15000/60000] [Batch 2/2] [D loss: 0.000955, acc: 100%] [G loss: 2.852687, adv: 1.009626, recon: 0.036427, id: 0.030228] time: 4:00:13.272021 \n","Model weights saved. combined_model\n","[Epoch 15250/60000] [Batch 2/2] [D loss: 0.000529, acc: 100%] [G loss: 2.810906, adv: 0.995008, recon: 0.035775, id: 0.030371] time: 4:04:14.798125 \n","[Epoch 15500/60000] [Batch 2/2] [D loss: 0.000791, acc: 100%] [G loss: 3.852937, adv: 1.011054, recon: 0.082656, id: 0.069039] time: 4:08:14.001177 \n","[Epoch 15750/60000] [Batch 2/2] [D loss: 0.000366, acc: 100%] [G loss: 3.200652, adv: 0.999937, recon: 0.053657, id: 0.051935] time: 4:12:13.278196 \n","[Epoch 16000/60000] [Batch 2/2] [D loss: 0.000382, acc: 100%] [G loss: 3.138374, adv: 1.005238, recon: 0.049868, id: 0.046284] time: 4:16:13.628224 \n","Model weights saved. combined_model\n","[Epoch 16250/60000] [Batch 2/2] [D loss: 0.000965, acc: 100%] [G loss: 3.094316, adv: 1.009558, recon: 0.047202, id: 0.042762] time: 4:20:14.606945 \n","[Epoch 16500/60000] [Batch 2/2] [D loss: 0.003290, acc: 100%] [G loss: 3.077265, adv: 1.041688, recon: 0.044179, id: 0.041790] time: 4:24:15.043902 \n","[Epoch 16750/60000] [Batch 2/2] [D loss: 0.000399, acc: 100%] [G loss: 3.113022, adv: 1.003431, recon: 0.047858, id: 0.040549] time: 4:28:15.567448 \n","[Epoch 17000/60000] [Batch 2/2] [D loss: 0.000483, acc: 100%] [G loss: 2.968260, adv: 0.996791, recon: 0.042521, id: 0.035782] time: 4:32:17.386725 \n","Model weights saved. combined_model\n","[Epoch 17250/60000] [Batch 2/2] [D loss: 0.000565, acc: 100%] [G loss: 2.844884, adv: 1.000523, recon: 0.036722, id: 0.034905] time: 4:36:19.866058 \n","[Epoch 17500/60000] [Batch 2/2] [D loss: 0.000253, acc: 100%] [G loss: 3.115621, adv: 1.000418, recon: 0.047711, id: 0.033090] time: 4:40:20.841264 \n","[Epoch 17750/60000] [Batch 2/2] [D loss: 0.000533, acc: 100%] [G loss: 3.068259, adv: 1.009038, recon: 0.044408, id: 0.033953] time: 4:44:21.662730 \n","[Epoch 18000/60000] [Batch 2/2] [D loss: 0.000514, acc: 100%] [G loss: 3.060241, adv: 1.002526, recon: 0.045273, id: 0.032521] time: 4:48:22.108229 \n","Model weights saved. combined_model\n","[Epoch 18250/60000] [Batch 2/2] [D loss: 0.000482, acc: 100%] [G loss: 3.026769, adv: 0.998978, recon: 0.043557, id: 0.033012] time: 4:52:25.060226 \n","[Epoch 18500/60000] [Batch 2/2] [D loss: 0.000841, acc: 100%] [G loss: 2.877129, adv: 1.004176, recon: 0.037084, id: 0.031446] time: 4:56:25.575016 \n","[Epoch 18750/60000] [Batch 2/2] [D loss: 0.000362, acc: 100%] [G loss: 2.897761, adv: 1.002024, recon: 0.037262, id: 0.031708] time: 5:00:26.496483 \n","[Epoch 19000/60000] [Batch 2/2] [D loss: 0.000216, acc: 100%] [G loss: 2.950436, adv: 1.005118, recon: 0.040703, id: 0.029799] time: 5:04:27.305614 \n","Model weights saved. combined_model\n","[Epoch 19250/60000] [Batch 2/2] [D loss: 0.000522, acc: 100%] [G loss: 2.849981, adv: 1.000156, recon: 0.037016, id: 0.030464] time: 5:08:29.955340 \n","[Epoch 19500/60000] [Batch 2/2] [D loss: 0.000547, acc: 100%] [G loss: 2.944932, adv: 1.002149, recon: 0.040633, id: 0.030419] time: 5:12:30.624927 \n","[Epoch 19750/60000] [Batch 2/2] [D loss: 0.000678, acc: 100%] [G loss: 3.153288, adv: 0.998572, recon: 0.050548, id: 0.033703] time: 5:16:31.846941 \n","[Epoch 20000/60000] [Batch 2/2] [D loss: 0.000201, acc: 100%] [G loss: 2.859488, adv: 1.001325, recon: 0.036195, id: 0.031180] time: 5:20:32.524770 \n","Model weights saved. combined_model\n","[Epoch 20250/60000] [Batch 2/2] [D loss: 0.000346, acc: 100%] [G loss: 2.796629, adv: 1.003404, recon: 0.033141, id: 0.029773] time: 5:24:34.758202 \n","[Epoch 20500/60000] [Batch 2/2] [D loss: 0.000208, acc: 100%] [G loss: 2.722427, adv: 1.001338, recon: 0.031176, id: 0.029321] time: 5:28:35.341819 \n","[Epoch 20750/60000] [Batch 2/2] [D loss: 0.000417, acc: 100%] [G loss: 2.867632, adv: 1.002484, recon: 0.037822, id: 0.031120] time: 5:32:36.448518 \n","[Epoch 21000/60000] [Batch 2/2] [D loss: 0.000406, acc: 100%] [G loss: 2.767313, adv: 0.997243, recon: 0.033061, id: 0.028827] time: 5:36:37.081849 \n","Model weights saved. combined_model\n","[Epoch 21250/60000] [Batch 2/2] [D loss: 0.000699, acc: 100%] [G loss: 2.892729, adv: 1.015296, recon: 0.037094, id: 0.029887] time: 5:40:39.279391 \n","[Epoch 21500/60000] [Batch 2/2] [D loss: 0.000582, acc: 100%] [G loss: 2.707838, adv: 0.997717, recon: 0.030285, id: 0.028308] time: 5:44:39.776127 \n","[Epoch 21750/60000] [Batch 2/2] [D loss: 0.000216, acc: 100%] [G loss: 2.889991, adv: 1.000653, recon: 0.038854, id: 0.029305] time: 5:48:40.981556 \n","[Epoch 22000/60000] [Batch 2/2] [D loss: 0.000577, acc: 100%] [G loss: 2.988393, adv: 1.017581, recon: 0.040430, id: 0.030038] time: 5:52:41.815518 \n","Model weights saved. combined_model\n","[Epoch 22250/60000] [Batch 2/2] [D loss: 0.000640, acc: 100%] [G loss: 2.981987, adv: 1.004769, recon: 0.041208, id: 0.028909] time: 5:56:44.929405 \n","[Epoch 22500/60000] [Batch 2/2] [D loss: 0.001192, acc: 100%] [G loss: 3.056317, adv: 1.000302, recon: 0.045660, id: 0.032194] time: 6:00:46.079305 \n","[Epoch 22750/60000] [Batch 2/2] [D loss: 0.000186, acc: 100%] [G loss: 2.879711, adv: 0.998325, recon: 0.037731, id: 0.028796] time: 6:04:47.710342 \n","[Epoch 23000/60000] [Batch 2/2] [D loss: 0.000465, acc: 100%] [G loss: 2.895420, adv: 1.003712, recon: 0.038016, id: 0.029362] time: 6:08:48.836046 \n","Model weights saved. combined_model\n","[Epoch 23250/60000] [Batch 2/2] [D loss: 0.000308, acc: 100%] [G loss: 2.756360, adv: 0.999773, recon: 0.032498, id: 0.030696] time: 6:12:51.948201 \n","[Epoch 23500/60000] [Batch 2/2] [D loss: 0.000196, acc: 100%] [G loss: 2.754876, adv: 0.998019, recon: 0.032697, id: 0.029359] time: 6:16:52.341515 \n","[Epoch 23750/60000] [Batch 2/2] [D loss: 0.000158, acc: 100%] [G loss: 2.729331, adv: 0.998664, recon: 0.031683, id: 0.028719] time: 6:20:53.805204 \n","[Epoch 24000/60000] [Batch 2/2] [D loss: 0.000197, acc: 100%] [G loss: 2.967726, adv: 1.001420, recon: 0.041710, id: 0.028996] time: 6:24:55.508521 \n","Model weights saved. combined_model\n","[Epoch 24250/60000] [Batch 2/2] [D loss: 0.000220, acc: 100%] [G loss: 2.776814, adv: 1.000377, recon: 0.033615, id: 0.028004] time: 6:28:58.542930 \n","[Epoch 24500/60000] [Batch 2/2] [D loss: 0.000579, acc: 100%] [G loss: 2.900765, adv: 0.996340, recon: 0.038633, id: 0.033841] time: 6:32:59.825270 \n","[Epoch 24750/60000] [Batch 2/2] [D loss: 0.000187, acc: 100%] [G loss: 3.035493, adv: 1.001608, recon: 0.044409, id: 0.028480] time: 6:37:00.851453 \n","[Epoch 25000/60000] [Batch 2/2] [D loss: 0.000232, acc: 100%] [G loss: 2.840783, adv: 1.000548, recon: 0.035881, id: 0.027457] time: 6:41:02.672668 \n","Model weights saved. combined_model\n","[Epoch 25250/60000] [Batch 2/2] [D loss: 0.000138, acc: 100%] [G loss: 2.734695, adv: 0.999973, recon: 0.030896, id: 0.027827] time: 6:45:04.538297 \n","[Epoch 25500/60000] [Batch 2/2] [D loss: 0.001106, acc: 100%] [G loss: 2.834555, adv: 1.020417, recon: 0.033374, id: 0.027764] time: 6:49:04.954589 \n","[Epoch 25750/60000] [Batch 2/2] [D loss: 0.000679, acc: 100%] [G loss: 2.872825, adv: 1.006840, recon: 0.035544, id: 0.028522] time: 6:53:05.145928 \n","[Epoch 26000/60000] [Batch 2/2] [D loss: 0.000208, acc: 100%] [G loss: 2.737781, adv: 1.000562, recon: 0.031178, id: 0.027368] time: 6:57:08.908957 \n","Model weights saved. combined_model\n","[Epoch 26250/60000] [Batch 2/2] [D loss: 0.000255, acc: 100%] [G loss: 2.887612, adv: 0.996456, recon: 0.037085, id: 0.028111] time: 7:01:12.591532 \n","[Epoch 26500/60000] [Batch 2/2] [D loss: 0.000351, acc: 100%] [G loss: 2.851012, adv: 0.999166, recon: 0.035787, id: 0.031107] time: 7:05:14.830500 \n","[Epoch 26750/60000] [Batch 2/2] [D loss: 0.000773, acc: 100%] [G loss: 2.736946, adv: 1.000125, recon: 0.030892, id: 0.033221] time: 7:09:17.393051 \n","[Epoch 27000/60000] [Batch 2/2] [D loss: 0.000291, acc: 100%] [G loss: 3.239831, adv: 1.005639, recon: 0.051217, id: 0.030803] time: 7:13:21.027042 \n","Model weights saved. combined_model\n","[Epoch 27250/60000] [Batch 2/2] [D loss: 0.000215, acc: 100%] [G loss: 3.002296, adv: 1.000346, recon: 0.041432, id: 0.029187] time: 7:17:26.561075 \n","[Epoch 27500/60000] [Batch 2/2] [D loss: 0.007885, acc: 100%] [G loss: 2.925475, adv: 1.031831, recon: 0.036905, id: 0.028565] time: 7:21:29.285970 \n","[Epoch 27750/60000] [Batch 2/2] [D loss: 0.000167, acc: 100%] [G loss: 2.880566, adv: 0.997127, recon: 0.037443, id: 0.028456] time: 7:25:32.395044 \n","[Epoch 28000/60000] [Batch 2/2] [D loss: 0.000241, acc: 100%] [G loss: 2.781199, adv: 0.998005, recon: 0.033581, id: 0.028250] time: 7:29:36.657084 \n","Model weights saved. combined_model\n","[Epoch 28250/60000] [Batch 2/2] [D loss: 0.001005, acc: 100%] [G loss: 2.958246, adv: 0.996228, recon: 0.040802, id: 0.028841] time: 7:33:41.763683 \n","[Epoch 28500/60000] [Batch 2/2] [D loss: 0.000331, acc: 100%] [G loss: 2.719538, adv: 1.005945, recon: 0.029811, id: 0.027814] time: 7:37:45.748336 \n","[Epoch 28750/60000] [Batch 2/2] [D loss: 0.000361, acc: 100%] [G loss: 2.894996, adv: 0.997918, recon: 0.038876, id: 0.027889] time: 7:41:48.853847 \n","[Epoch 29000/60000] [Batch 2/2] [D loss: 0.001135, acc: 100%] [G loss: 2.671319, adv: 1.000776, recon: 0.028286, id: 0.028071] time: 7:45:52.009389 \n","Model weights saved. combined_model\n","[Epoch 29250/60000] [Batch 2/2] [D loss: 0.000102, acc: 100%] [G loss: 2.792426, adv: 0.998890, recon: 0.033324, id: 0.026326] time: 7:49:57.260367 \n","[Epoch 29500/60000] [Batch 2/2] [D loss: 0.000144, acc: 100%] [G loss: 2.771173, adv: 0.998068, recon: 0.032429, id: 0.026697] time: 7:54:00.697640 \n","[Epoch 29750/60000] [Batch 2/2] [D loss: 0.000450, acc: 100%] [G loss: 2.740201, adv: 1.001106, recon: 0.031496, id: 0.027351] time: 7:58:04.707317 \n","[Epoch 30000/60000] [Batch 2/2] [D loss: 0.000213, acc: 100%] [G loss: 2.730247, adv: 1.003459, recon: 0.031359, id: 0.027316] time: 8:02:07.656038 \n","Model weights saved. combined_model\n","[Epoch 30250/60000] [Batch 2/2] [D loss: 0.000245, acc: 100%] [G loss: 2.755054, adv: 0.998772, recon: 0.032143, id: 0.026802] time: 8:06:10.545350 \n","[Epoch 30500/60000] [Batch 2/2] [D loss: 0.000219, acc: 100%] [G loss: 2.787946, adv: 0.997944, recon: 0.033747, id: 0.026513] time: 8:10:11.260817 \n","[Epoch 30750/60000] [Batch 2/2] [D loss: 0.000226, acc: 100%] [G loss: 2.791194, adv: 0.999888, recon: 0.033542, id: 0.027020] time: 8:14:11.406263 \n","[Epoch 31000/60000] [Batch 2/2] [D loss: 0.000296, acc: 100%] [G loss: 2.807750, adv: 1.005794, recon: 0.034110, id: 0.027028] time: 8:18:12.623267 \n","Model weights saved. combined_model\n","[Epoch 31250/60000] [Batch 2/2] [D loss: 0.005162, acc: 100%] [G loss: 2.688020, adv: 0.972328, recon: 0.031422, id: 0.026523] time: 8:22:14.573156 \n","[Epoch 31500/60000] [Batch 2/2] [D loss: 0.000155, acc: 100%] [G loss: 2.912656, adv: 1.000917, recon: 0.038557, id: 0.026466] time: 8:26:14.790269 \n","[Epoch 31750/60000] [Batch 2/2] [D loss: 0.000335, acc: 100%] [G loss: 2.882460, adv: 1.000944, recon: 0.037499, id: 0.026058] time: 8:30:17.833154 \n","[Epoch 32000/60000] [Batch 2/2] [D loss: 0.000098, acc: 100%] [G loss: 2.857069, adv: 1.001407, recon: 0.036410, id: 0.026375] time: 8:34:19.451942 \n","Model weights saved. combined_model\n","[Epoch 32250/60000] [Batch 2/2] [D loss: 0.000155, acc: 100%] [G loss: 2.777482, adv: 1.000076, recon: 0.033561, id: 0.026071] time: 8:38:22.433829 \n","[Epoch 32500/60000] [Batch 2/2] [D loss: 0.000335, acc: 100%] [G loss: 2.761233, adv: 0.997676, recon: 0.032588, id: 0.026427] time: 8:42:23.326174 \n","[Epoch 32750/60000] [Batch 2/2] [D loss: 0.000333, acc: 100%] [G loss: 2.800157, adv: 0.999155, recon: 0.033786, id: 0.026426] time: 8:46:24.096128 \n","[Epoch 33000/60000] [Batch 2/2] [D loss: 0.000255, acc: 100%] [G loss: 2.833243, adv: 0.999083, recon: 0.034910, id: 0.025484] time: 8:50:24.335354 \n","Model weights saved. combined_model\n","[Epoch 33250/60000] [Batch 2/2] [D loss: 0.000110, acc: 100%] [G loss: 2.775908, adv: 1.000871, recon: 0.032993, id: 0.025513] time: 8:54:26.608554 \n","[Epoch 33500/60000] [Batch 2/2] [D loss: 0.000116, acc: 100%] [G loss: 2.808772, adv: 1.000240, recon: 0.034940, id: 0.025902] time: 8:58:28.025418 \n","[Epoch 33750/60000] [Batch 2/2] [D loss: 0.000837, acc: 100%] [G loss: 2.663097, adv: 0.997489, recon: 0.028842, id: 0.025737] time: 9:02:28.743981 \n","[Epoch 34000/60000] [Batch 2/2] [D loss: 0.000123, acc: 100%] [G loss: 2.860693, adv: 0.999591, recon: 0.037393, id: 0.028993] time: 9:06:29.164502 \n","Model weights saved. combined_model\n","[Epoch 34250/60000] [Batch 2/2] [D loss: 0.000141, acc: 100%] [G loss: 2.772550, adv: 0.999835, recon: 0.032913, id: 0.026042] time: 9:10:30.916218 \n","[Epoch 34500/60000] [Batch 2/2] [D loss: 0.000113, acc: 100%] [G loss: 2.765717, adv: 1.000889, recon: 0.032526, id: 0.025880] time: 9:14:31.218883 \n","[Epoch 34750/60000] [Batch 2/2] [D loss: 0.000175, acc: 100%] [G loss: 2.746479, adv: 1.000569, recon: 0.031541, id: 0.025217] time: 9:18:31.776486 \n","[Epoch 35000/60000] [Batch 2/2] [D loss: 0.000117, acc: 100%] [G loss: 2.723872, adv: 1.000361, recon: 0.030909, id: 0.025485] time: 9:22:32.999929 \n","Model weights saved. combined_model\n","[Epoch 35250/60000] [Batch 2/2] [D loss: 0.000808, acc: 100%] [G loss: 2.697911, adv: 0.993658, recon: 0.030432, id: 0.025472] time: 9:26:34.899619 \n","[Epoch 35500/60000] [Batch 2/2] [D loss: 0.000502, acc: 100%] [G loss: 2.731510, adv: 0.994896, recon: 0.030247, id: 0.025359] time: 9:30:35.440591 \n","[Epoch 35750/60000] [Batch 2/2] [D loss: 0.000165, acc: 100%] [G loss: 2.861972, adv: 1.002109, recon: 0.036146, id: 0.025435] time: 9:34:36.008247 \n","[Epoch 36000/60000] [Batch 2/2] [D loss: 0.000289, acc: 100%] [G loss: 2.838354, adv: 0.997993, recon: 0.036475, id: 0.024632] time: 9:38:36.591613 \n","Model weights saved. combined_model\n","[Epoch 36250/60000] [Batch 2/2] [D loss: 0.000133, acc: 100%] [G loss: 2.860102, adv: 1.001381, recon: 0.036257, id: 0.025631] time: 9:42:39.921129 \n","[Epoch 36500/60000] [Batch 2/2] [D loss: 0.000168, acc: 100%] [G loss: 2.657155, adv: 1.001255, recon: 0.027868, id: 0.025034] time: 9:46:40.305745 \n","[Epoch 36750/60000] [Batch 2/2] [D loss: 0.000068, acc: 100%] [G loss: 2.674048, adv: 1.000898, recon: 0.029052, id: 0.024833] time: 9:50:40.904592 \n","[Epoch 37000/60000] [Batch 2/2] [D loss: 0.000558, acc: 100%] [G loss: 2.792349, adv: 0.999082, recon: 0.033052, id: 0.027162] time: 9:54:41.613579 \n","Model weights saved. combined_model\n","[Epoch 37250/60000] [Batch 2/2] [D loss: 0.000151, acc: 100%] [G loss: 2.725014, adv: 1.000196, recon: 0.030880, id: 0.025192] time: 9:58:43.846301 \n","[Epoch 37500/60000] [Batch 2/2] [D loss: 0.000206, acc: 100%] [G loss: 2.748871, adv: 1.003441, recon: 0.030290, id: 0.024750] time: 10:02:44.224748 \n","[Epoch 37750/60000] [Batch 2/2] [D loss: 0.000145, acc: 100%] [G loss: 2.748724, adv: 1.000829, recon: 0.031287, id: 0.024902] time: 10:06:45.970886 \n","[Epoch 38000/60000] [Batch 2/2] [D loss: 0.000346, acc: 100%] [G loss: 2.694600, adv: 1.000694, recon: 0.029597, id: 0.025151] time: 10:10:47.059456 \n","Model weights saved. combined_model\n","[Epoch 38250/60000] [Batch 2/2] [D loss: 0.000198, acc: 100%] [G loss: 2.773042, adv: 0.996947, recon: 0.032610, id: 0.026324] time: 10:14:49.571750 \n","[Epoch 38500/60000] [Batch 2/2] [D loss: 0.000172, acc: 100%] [G loss: 2.726742, adv: 1.002811, recon: 0.030755, id: 0.024961] time: 10:18:50.292045 \n","[Epoch 38750/60000] [Batch 2/2] [D loss: 0.000355, acc: 100%] [G loss: 2.844027, adv: 1.005494, recon: 0.035685, id: 0.027370] time: 10:22:50.828170 \n","[Epoch 39000/60000] [Batch 2/2] [D loss: 0.001123, acc: 100%] [G loss: 2.749933, adv: 1.006986, recon: 0.030497, id: 0.024775] time: 10:26:52.482301 \n","Model weights saved. combined_model\n","[Epoch 39250/60000] [Batch 2/2] [D loss: 0.000203, acc: 100%] [G loss: 2.833952, adv: 1.004625, recon: 0.034722, id: 0.025877] time: 10:30:57.635829 \n","[Epoch 39500/60000] [Batch 2/2] [D loss: 0.000098, acc: 100%] [G loss: 2.753838, adv: 1.001030, recon: 0.030836, id: 0.024575] time: 10:35:00.072189 \n","[Epoch 39750/60000] [Batch 2/2] [D loss: 0.000082, acc: 100%] [G loss: 2.940670, adv: 1.001697, recon: 0.039891, id: 0.025021] time: 10:39:01.307428 \n","[Epoch 40000/60000] [Batch 2/2] [D loss: 0.000145, acc: 100%] [G loss: 2.878818, adv: 1.003643, recon: 0.037385, id: 0.026581] time: 10:43:02.742167 \n","Model weights saved. combined_model\n","[Epoch 40250/60000] [Batch 2/2] [D loss: 0.000188, acc: 100%] [G loss: 2.690691, adv: 0.999684, recon: 0.028454, id: 0.024937] time: 10:47:05.791449 \n","[Epoch 40500/60000] [Batch 2/2] [D loss: 0.000109, acc: 100%] [G loss: 2.816328, adv: 1.001813, recon: 0.033734, id: 0.024556] time: 10:51:06.910669 \n","[Epoch 40750/60000] [Batch 2/2] [D loss: 0.000609, acc: 100%] [G loss: 2.684564, adv: 0.993103, recon: 0.029400, id: 0.024429] time: 10:55:09.047267 \n","[Epoch 41000/60000] [Batch 2/2] [D loss: 0.000353, acc: 100%] [G loss: 2.727619, adv: 1.001990, recon: 0.031009, id: 0.024385] time: 10:59:09.879844 \n","Model weights saved. combined_model\n","[Epoch 41250/60000] [Batch 2/2] [D loss: 0.000217, acc: 100%] [G loss: 2.822819, adv: 1.000471, recon: 0.035074, id: 0.024157] time: 11:03:12.864993 \n","[Epoch 41500/60000] [Batch 2/2] [D loss: 0.000283, acc: 100%] [G loss: 2.836413, adv: 0.997048, recon: 0.035280, id: 0.024690] time: 11:07:13.783580 \n","[Epoch 41750/60000] [Batch 2/2] [D loss: 0.000163, acc: 100%] [G loss: 2.673340, adv: 1.003225, recon: 0.027946, id: 0.024353] time: 11:11:14.823653 \n","[Epoch 42000/60000] [Batch 2/2] [D loss: 0.000251, acc: 100%] [G loss: 2.653526, adv: 0.994543, recon: 0.028439, id: 0.023961] time: 11:15:15.532860 \n","Model weights saved. combined_model\n","[Epoch 42250/60000] [Batch 2/2] [D loss: 0.000192, acc: 100%] [G loss: 2.658442, adv: 1.000150, recon: 0.027409, id: 0.024853] time: 11:19:19.010992 \n","[Epoch 42500/60000] [Batch 2/2] [D loss: 0.000098, acc: 100%] [G loss: 2.677720, adv: 1.003433, recon: 0.028424, id: 0.023979] time: 11:23:19.926972 \n","[Epoch 42750/60000] [Batch 2/2] [D loss: 0.000224, acc: 100%] [G loss: 2.645285, adv: 1.009894, recon: 0.026978, id: 0.023920] time: 11:27:20.900985 \n","[Epoch 43000/60000] [Batch 2/2] [D loss: 0.000181, acc: 100%] [G loss: 2.729337, adv: 1.000326, recon: 0.030599, id: 0.024254] time: 11:31:21.971353 \n","Model weights saved. combined_model\n","[Epoch 43250/60000] [Batch 2/2] [D loss: 0.001823, acc: 100%] [G loss: 2.676688, adv: 0.978481, recon: 0.030641, id: 0.024251] time: 11:35:24.763544 \n","[Epoch 43500/60000] [Batch 2/2] [D loss: 0.000752, acc: 100%] [G loss: 2.786191, adv: 1.020050, recon: 0.030658, id: 0.024652] time: 11:39:25.857140 \n","[Epoch 43750/60000] [Batch 2/2] [D loss: 0.000129, acc: 100%] [G loss: 2.727140, adv: 1.001573, recon: 0.030540, id: 0.023517] time: 11:43:27.087387 \n","[Epoch 44000/60000] [Batch 2/2] [D loss: 0.000376, acc: 100%] [G loss: 2.789613, adv: 0.995859, recon: 0.033222, id: 0.024105] time: 11:47:29.620446 \n","Model weights saved. combined_model\n","[Epoch 44250/60000] [Batch 2/2] [D loss: 0.000091, acc: 100%] [G loss: 2.808145, adv: 1.002088, recon: 0.033502, id: 0.023917] time: 11:51:32.484236 \n","[Epoch 44500/60000] [Batch 2/2] [D loss: 0.000193, acc: 100%] [G loss: 2.896755, adv: 1.001422, recon: 0.038324, id: 0.023963] time: 11:55:33.894890 \n","[Epoch 44750/60000] [Batch 2/2] [D loss: 0.000098, acc: 100%] [G loss: 2.759201, adv: 0.998956, recon: 0.032417, id: 0.025407] time: 11:59:35.356182 \n","[Epoch 45000/60000] [Batch 2/2] [D loss: 0.000060, acc: 100%] [G loss: 2.979010, adv: 1.000088, recon: 0.043335, id: 0.030303] time: 12:03:36.531580 \n","Model weights saved. combined_model\n","[Epoch 45250/60000] [Batch 2/2] [D loss: 0.000150, acc: 100%] [G loss: 2.843779, adv: 0.998599, recon: 0.036459, id: 0.025410] time: 12:07:39.202036 \n","[Epoch 45500/60000] [Batch 2/2] [D loss: 0.000207, acc: 100%] [G loss: 2.618855, adv: 0.999342, recon: 0.026553, id: 0.024475] time: 12:11:41.802853 \n","[Epoch 45750/60000] [Batch 2/2] [D loss: 0.000264, acc: 100%] [G loss: 2.892212, adv: 1.005243, recon: 0.037482, id: 0.024813] time: 12:15:43.996546 \n","[Epoch 46000/60000] [Batch 2/2] [D loss: 0.000181, acc: 100%] [G loss: 2.658465, adv: 1.002332, recon: 0.027181, id: 0.024313] time: 12:19:46.755374 \n","Model weights saved. combined_model\n","[Epoch 46250/60000] [Batch 2/2] [D loss: 0.000149, acc: 100%] [G loss: 2.751177, adv: 1.001126, recon: 0.030737, id: 0.024826] time: 12:23:50.570852 \n","[Epoch 46500/60000] [Batch 2/2] [D loss: 0.000103, acc: 100%] [G loss: 2.776626, adv: 1.000351, recon: 0.032738, id: 0.025987] time: 12:27:52.665493 \n","[Epoch 46750/60000] [Batch 2/2] [D loss: 0.000066, acc: 100%] [G loss: 3.116480, adv: 1.001978, recon: 0.048588, id: 0.036150] time: 12:31:54.008502 \n","[Epoch 47000/60000] [Batch 2/2] [D loss: 0.000203, acc: 100%] [G loss: 3.342921, adv: 0.997418, recon: 0.060483, id: 0.042380] time: 12:35:55.328470 \n","Model weights saved. combined_model\n","[Epoch 47250/60000] [Batch 2/2] [D loss: 0.000069, acc: 100%] [G loss: 2.950128, adv: 1.001305, recon: 0.041505, id: 0.033862] time: 12:39:59.542036 \n","[Epoch 47500/60000] [Batch 2/2] [D loss: 0.000066, acc: 100%] [G loss: 2.793454, adv: 0.997824, recon: 0.033870, id: 0.032309] time: 12:44:00.915602 \n","[Epoch 47750/60000] [Batch 2/2] [D loss: 0.000103, acc: 100%] [G loss: 3.066103, adv: 1.002013, recon: 0.045527, id: 0.031182] time: 12:48:02.226233 \n","[Epoch 48000/60000] [Batch 2/2] [D loss: 0.000125, acc: 100%] [G loss: 2.875661, adv: 1.002632, recon: 0.037042, id: 0.028308] time: 12:52:03.494905 \n","Model weights saved. combined_model\n","[Epoch 48250/60000] [Batch 2/2] [D loss: 0.000127, acc: 100%] [G loss: 2.799397, adv: 1.001644, recon: 0.033224, id: 0.027694] time: 12:56:07.027222 \n","[Epoch 48500/60000] [Batch 2/2] [D loss: 0.000198, acc: 100%] [G loss: 2.668561, adv: 1.003280, recon: 0.028037, id: 0.027559] time: 13:00:08.520198 \n","[Epoch 48750/60000] [Batch 2/2] [D loss: 0.000283, acc: 100%] [G loss: 2.708574, adv: 1.007014, recon: 0.028801, id: 0.026117] time: 13:04:09.615147 \n","[Epoch 49000/60000] [Batch 2/2] [D loss: 0.000130, acc: 100%] [G loss: 2.763206, adv: 0.999782, recon: 0.032285, id: 0.026824] time: 13:08:12.385486 \n","Model weights saved. combined_model\n","[Epoch 49250/60000] [Batch 2/2] [D loss: 0.000105, acc: 100%] [G loss: 2.730926, adv: 1.002147, recon: 0.030172, id: 0.025109] time: 13:12:15.970498 \n","[Epoch 49500/60000] [Batch 2/2] [D loss: 0.000116, acc: 100%] [G loss: 2.762058, adv: 0.996569, recon: 0.031301, id: 0.026019] time: 13:16:17.439476 \n","[Epoch 49750/60000] [Batch 2/2] [D loss: 0.000049, acc: 100%] [G loss: 4.025642, adv: 1.002286, recon: 0.092418, id: 0.024584] time: 13:20:19.025577 \n","[Epoch 50000/60000] [Batch 2/2] [D loss: 0.000078, acc: 100%] [G loss: 2.687179, adv: 0.999572, recon: 0.028712, id: 0.024538] time: 13:24:20.442476 \n","Model weights saved. combined_model\n","[Epoch 50250/60000] [Batch 2/2] [D loss: 0.000155, acc: 100%] [G loss: 2.552859, adv: 1.001104, recon: 0.023116, id: 0.023485] time: 13:28:23.794721 \n","[Epoch 50500/60000] [Batch 2/2] [D loss: 0.000153, acc: 100%] [G loss: 2.714079, adv: 1.001473, recon: 0.029795, id: 0.023512] time: 13:32:25.428012 \n","[Epoch 50750/60000] [Batch 2/2] [D loss: 0.000066, acc: 100%] [G loss: 2.706810, adv: 1.000211, recon: 0.030417, id: 0.024029] time: 13:36:28.122664 \n","[Epoch 51000/60000] [Batch 2/2] [D loss: 0.001257, acc: 100%] [G loss: 2.760128, adv: 1.003387, recon: 0.031885, id: 0.025232] time: 13:40:30.010199 \n","Model weights saved. combined_model\n","[Epoch 51250/60000] [Batch 2/2] [D loss: 0.000440, acc: 100%] [G loss: 2.879139, adv: 0.993982, recon: 0.038232, id: 0.030434] time: 13:44:33.469693 \n","[Epoch 51500/60000] [Batch 2/2] [D loss: 0.000213, acc: 100%] [G loss: 2.867650, adv: 0.999218, recon: 0.036793, id: 0.028917] time: 13:48:35.314289 \n","[Epoch 51750/60000] [Batch 2/2] [D loss: 0.000356, acc: 100%] [G loss: 2.809851, adv: 0.986261, recon: 0.032860, id: 0.026067] time: 13:52:37.104407 \n","[Epoch 52000/60000] [Batch 2/2] [D loss: 0.000211, acc: 100%] [G loss: 2.737833, adv: 1.003804, recon: 0.030342, id: 0.025113] time: 13:56:38.932894 \n","Model weights saved. combined_model\n","[Epoch 52250/60000] [Batch 2/2] [D loss: 0.000111, acc: 100%] [G loss: 2.708933, adv: 1.000629, recon: 0.029960, id: 0.024173] time: 14:00:42.236448 \n","[Epoch 52500/60000] [Batch 2/2] [D loss: 0.000125, acc: 100%] [G loss: 2.696284, adv: 0.999528, recon: 0.029521, id: 0.024836] time: 14:04:45.056674 \n","[Epoch 52750/60000] [Batch 2/2] [D loss: 0.000136, acc: 100%] [G loss: 2.730109, adv: 0.999770, recon: 0.031076, id: 0.024259] time: 14:08:47.064809 \n","[Epoch 53000/60000] [Batch 2/2] [D loss: 0.000058, acc: 100%] [G loss: 2.644142, adv: 1.002107, recon: 0.027249, id: 0.024563] time: 14:12:48.951104 \n","Model weights saved. combined_model\n","[Epoch 53250/60000] [Batch 2/2] [D loss: 0.000109, acc: 100%] [G loss: 2.824917, adv: 1.002205, recon: 0.034116, id: 0.024788] time: 14:16:52.482577 \n","[Epoch 53500/60000] [Batch 2/2] [D loss: 0.000341, acc: 100%] [G loss: 2.823001, adv: 0.998850, recon: 0.034924, id: 0.023959] time: 14:20:54.393568 \n","[Epoch 53750/60000] [Batch 2/2] [D loss: 0.000199, acc: 100%] [G loss: 2.727785, adv: 1.008532, recon: 0.030484, id: 0.023692] time: 14:24:57.222319 \n","[Epoch 54000/60000] [Batch 2/2] [D loss: 0.000051, acc: 100%] [G loss: 2.667024, adv: 0.999292, recon: 0.027845, id: 0.024204] time: 14:29:01.783016 \n","Model weights saved. combined_model\n","[Epoch 54250/60000] [Batch 2/2] [D loss: 0.000062, acc: 100%] [G loss: 2.801794, adv: 1.000848, recon: 0.033725, id: 0.024195] time: 14:33:08.867748 \n","[Epoch 54500/60000] [Batch 2/2] [D loss: 0.000134, acc: 100%] [G loss: 2.864821, adv: 1.003419, recon: 0.036445, id: 0.023318] time: 14:37:16.008276 \n","[Epoch 54750/60000] [Batch 2/2] [D loss: 0.000181, acc: 100%] [G loss: 2.762978, adv: 1.007908, recon: 0.032251, id: 0.023444] time: 14:41:22.663740 \n","[Epoch 55000/60000] [Batch 2/2] [D loss: 0.000110, acc: 100%] [G loss: 2.889487, adv: 1.000739, recon: 0.037308, id: 0.023551] time: 14:45:29.043896 \n","Model weights saved. combined_model\n","[Epoch 55250/60000] [Batch 2/2] [D loss: 0.000208, acc: 100%] [G loss: 2.675723, adv: 0.998790, recon: 0.029064, id: 0.022831] time: 14:49:37.360829 \n","[Epoch 55500/60000] [Batch 2/2] [D loss: 0.000052, acc: 100%] [G loss: 2.723768, adv: 1.001881, recon: 0.029902, id: 0.023906] time: 14:53:44.296272 \n","[Epoch 55750/60000] [Batch 2/2] [D loss: 0.000048, acc: 100%] [G loss: 2.590979, adv: 1.000085, recon: 0.025370, id: 0.023324] time: 14:57:51.217528 \n","[Epoch 56000/60000] [Batch 2/2] [D loss: 0.000065, acc: 100%] [G loss: 2.659408, adv: 0.998844, recon: 0.028618, id: 0.023080] time: 15:01:58.308396 \n","Model weights saved. combined_model\n","[Epoch 56250/60000] [Batch 2/2] [D loss: 0.000062, acc: 100%] [G loss: 2.687504, adv: 0.998133, recon: 0.029459, id: 0.023966] time: 15:06:07.792858 \n","[Epoch 56500/60000] [Batch 2/2] [D loss: 0.000037, acc: 100%] [G loss: 2.632476, adv: 1.002009, recon: 0.027102, id: 0.024317] time: 15:10:17.120024 \n","[Epoch 56750/60000] [Batch 2/2] [D loss: 0.000070, acc: 100%] [G loss: 2.692763, adv: 0.999555, recon: 0.029714, id: 0.022907] time: 15:14:25.061718 \n","[Epoch 57000/60000] [Batch 2/2] [D loss: 0.000063, acc: 100%] [G loss: 2.679851, adv: 1.001694, recon: 0.028439, id: 0.023651] time: 15:18:32.725703 \n","Model weights saved. combined_model\n","[Epoch 57250/60000] [Batch 2/2] [D loss: 0.000110, acc: 100%] [G loss: 2.693122, adv: 0.996059, recon: 0.030093, id: 0.022631] time: 15:22:42.183315 \n","[Epoch 57500/60000] [Batch 2/2] [D loss: 0.000119, acc: 100%] [G loss: 2.927507, adv: 1.003551, recon: 0.039085, id: 0.024343] time: 15:26:49.373834 \n","[Epoch 57750/60000] [Batch 2/2] [D loss: 0.000147, acc: 100%] [G loss: 2.678344, adv: 0.999776, recon: 0.028967, id: 0.022936] time: 15:30:54.125551 \n","[Epoch 58000/60000] [Batch 2/2] [D loss: 0.000070, acc: 100%] [G loss: 2.631256, adv: 1.004438, recon: 0.026417, id: 0.023284] time: 15:34:56.901903 \n","Model weights saved. combined_model\n","[Epoch 58250/60000] [Batch 2/2] [D loss: 0.000104, acc: 100%] [G loss: 2.600537, adv: 0.996015, recon: 0.026041, id: 0.022648] time: 15:39:00.753696 \n","[Epoch 58500/60000] [Batch 2/2] [D loss: 0.000062, acc: 100%] [G loss: 2.604297, adv: 0.997188, recon: 0.025901, id: 0.022743] time: 15:43:04.528163 \n","[Epoch 58750/60000] [Batch 2/2] [D loss: 0.000071, acc: 100%] [G loss: 2.663745, adv: 0.997600, recon: 0.028385, id: 0.022832] time: 15:47:06.879750 \n","[Epoch 59000/60000] [Batch 2/2] [D loss: 0.000186, acc: 100%] [G loss: 2.688444, adv: 1.002724, recon: 0.029309, id: 0.022361] time: 15:51:09.414142 \n","Model weights saved. combined_model\n","[Epoch 59250/60000] [Batch 2/2] [D loss: 0.000160, acc: 100%] [G loss: 2.763765, adv: 0.989437, recon: 0.033883, id: 0.024386] time: 15:55:13.367902 \n","[Epoch 59500/60000] [Batch 2/2] [D loss: 0.000067, acc: 100%] [G loss: 2.713545, adv: 0.998160, recon: 0.029929, id: 0.023701] time: 15:59:15.746051 \n","[Epoch 59750/60000] [Batch 2/2] [D loss: 0.000066, acc: 100%] [G loss: 2.693196, adv: 0.999426, recon: 0.029263, id: 0.023374] time: 16:03:18.053728 \n","[Epoch 60000/60000] [Batch 2/2] [D loss: 0.000050, acc: 100%] [G loss: 2.661345, adv: 1.001872, recon: 0.027731, id: 0.022422] time: 16:07:20.104662 \n","Model weights saved. combined_model\n","2020-08-19T05:24:59.136226 End\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"i-y5rcPFuVlZ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":265},"executionInfo":{"status":"ok","timestamp":1597814700224,"user_tz":-540,"elapsed":57895186,"user":{"displayName":"Noboru Koike","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggp8njUb4jc54JrzfM5cQBkfiCdlz6nY17y8-1szg=s64","userId":"05156582812995850159"}},"outputId":"c8d110b9-1fbb-4fc2-f77d-b3bb0b412bea"},"source":["gan.plot_hisotry()"],"execution_count":12,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"jVZmcRxNGYu8","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597814704483,"user_tz":-540,"elapsed":57897616,"user":{"displayName":"Noboru Koike","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggp8njUb4jc54JrzfM5cQBkfiCdlz6nY17y8-1szg=s64","userId":"05156582812995850159"}}},"source":["gan.history.to_csv(os.path.join(OUTPUT_DIR_PATH, 'history.csv'))"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"mzC90MhSqoO9","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}