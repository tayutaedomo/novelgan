{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"10_ukiyoe.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"10mPFXeYS32istQIkMf2kv0WSR6BVQ0VJ","authorship_tag":"ABX9TyNMkk9ofoFiR1QA0R/AumGy"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"zPFGSnYPcCcb","colab_type":"text"},"source":["### ukiyoe2novelモデルの作成、実装の確認"]},{"cell_type":"code","metadata":{"id":"aJJREIclkSwA","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":350},"executionInfo":{"status":"ok","timestamp":1597530618306,"user_tz":-540,"elapsed":7043,"user":{"displayName":"Noboru Koike","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggp8njUb4jc54JrzfM5cQBkfiCdlz6nY17y8-1szg=s64","userId":"05156582812995850159"}},"outputId":"46d9ffcd-f7fe-46fb-c3cc-49f574ab1d5c"},"source":["!nvidia-smi"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Sat Aug 15 22:30:12 2020       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 450.57       Driver Version: 418.67       CUDA Version: 10.1     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   40C    P0    28W / 250W |      0MiB / 16280MiB |      0%      Default |\n","|                               |                      |                 ERR! |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Q5r1RwHMarP0","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597530624360,"user_tz":-540,"elapsed":2506,"user":{"displayName":"Noboru Koike","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggp8njUb4jc54JrzfM5cQBkfiCdlz6nY17y8-1szg=s64","userId":"05156582812995850159"}}},"source":["from tensorflow_addons.layers import InstanceNormalization\n","from tensorflow.keras.layers import Input, Dropout, Concatenate\n","from tensorflow.keras.layers import LeakyReLU\n","from tensorflow.keras.layers import UpSampling2D, Conv2D\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.optimizers import Adam"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"fQUB04E2d4T3","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597530625682,"user_tz":-540,"elapsed":571,"user":{"displayName":"Noboru Koike","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggp8njUb4jc54JrzfM5cQBkfiCdlz6nY17y8-1szg=s64","userId":"05156582812995850159"}}},"source":["import matplotlib.pyplot as plt\n","import numpy as np\n","import pandas as pd\n","import datetime\n","import os"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"boJVXJj8d50Z","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597530627546,"user_tz":-540,"elapsed":1218,"user":{"displayName":"Noboru Koike","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggp8njUb4jc54JrzfM5cQBkfiCdlz6nY17y8-1szg=s64","userId":"05156582812995850159"}}},"source":["from glob import glob\n","import cv2\n","from matplotlib.pyplot import imread"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"vl7pN3a3d7ot","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597530628832,"user_tz":-540,"elapsed":1103,"user":{"displayName":"Noboru Koike","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggp8njUb4jc54JrzfM5cQBkfiCdlz6nY17y8-1szg=s64","userId":"05156582812995850159"}}},"source":["DATA_DIR_PATH = '/content/drive/My Drive/kikagaku/novelgan/data'\n","\n","OUTPUT_DIR_PATH = os.path.join(DATA_DIR_PATH, '10_out')"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"5kUMe2creB8t","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597530631106,"user_tz":-540,"elapsed":2406,"user":{"displayName":"Noboru Koike","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggp8njUb4jc54JrzfM5cQBkfiCdlz6nY17y8-1szg=s64","userId":"05156582812995850159"}}},"source":["#os.makedirs(os.path.join(DATA_DIR_PATH, 'datasets'), exist_ok=True)\n","\n","os.makedirs(os.path.join(OUTPUT_DIR_PATH, 'images'), exist_ok=True)\n","os.makedirs(os.path.join(OUTPUT_DIR_PATH, 'saved_models'), exist_ok=True)"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"XR_AzLmaeFiF","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597530632582,"user_tz":-540,"elapsed":922,"user":{"displayName":"Noboru Koike","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggp8njUb4jc54JrzfM5cQBkfiCdlz6nY17y8-1szg=s64","userId":"05156582812995850159"}}},"source":["class DataLoader():\n","    def __init__(self, dataset_name, img_res=(256, 256)):\n","        self.dataset_name = dataset_name\n","        self.img_res = img_res\n","        self.datasets_path = os.path.join(DATA_DIR_PATH, 'datasets')\n","\n","    def load_data(self, domain, batch_size=1, is_testing=False):\n","        data_type = \"train%s\" % domain if not is_testing else \"test%s\" % domain\n","        #path = glob('./datasets/%s/%s/*' % (self.dataset_name, data_type))\n","        path = glob(os.path.join(self.datasets_path, self.dataset_name, data_type, '*'))\n","\n","        batch_images = np.random.choice(path, size=batch_size)\n","\n","        imgs = []\n","        for img_path in batch_images:\n","            img = self.imread(img_path)\n","            if not is_testing:\n","                #img = scipy.misc.imresize(img, self.img_res)\n","                img = cv2.resize(img, self.img_res)\n","\n","                if np.random.random() > 0.5:\n","                    img = np.fliplr(img)\n","            else:\n","                #img = scipy.misc.imresize(img, self.img_res)\n","                img = cv2.resize(img, self.img_res)\n","            imgs.append(img)\n","\n","        imgs = np.array(imgs)/127.5 - 1.\n","\n","        return imgs\n","\n","    def load_batch(self, batch_size=1, is_testing=False):\n","        data_type = \"train\" if not is_testing else \"val\"\n","        #path_A = glob('./datasets/%s/%sA/*' % (self.dataset_name, data_type))\n","        #path_B = glob('./datasets/%s/%sB/*' % (self.dataset_name, data_type))\n","        path_A = glob(os.path.join(self.datasets_path, self.dataset_name, '{}A'.format(data_type), '*'))\n","        path_B = glob(os.path.join(self.datasets_path, self.dataset_name, '{}B'.format(data_type), '*'))\n","\n","        self.n_batches = int(min(len(path_A), len(path_B)) / batch_size)\n","        total_samples = self.n_batches * batch_size\n","\n","        # Sample n_batches * batch_size from each path list so that model sees all\n","        # samples from both domains\n","        path_A = np.random.choice(path_A, total_samples, replace=False)\n","        path_B = np.random.choice(path_B, total_samples, replace=False)\n","\n","        #for i in range(self.n_batches-1):\n","        for i in range(self.n_batches):\n","            batch_A = path_A[i*batch_size:(i+1)*batch_size]\n","            batch_B = path_B[i*batch_size:(i+1)*batch_size]\n","            imgs_A, imgs_B = [], []\n","\n","            for img_A, img_B in zip(batch_A, batch_B):\n","                img_A = self.imread(img_A)\n","                img_B = self.imread(img_B)\n","\n","                #img_A = scipy.misc.imresize(img_A, self.img_res)\n","                img_A = cv2.resize(img_A, self.img_res)\n","                #img_B = scipy.misc.imresize(img_B, self.img_res)\n","                img_B = cv2.resize(img_B, self.img_res)\n","\n","                if not is_testing and np.random.random() > 0.5:\n","                    img_A = np.fliplr(img_A)\n","                    img_B = np.fliplr(img_B)\n","\n","                imgs_A.append(img_A)\n","                imgs_B.append(img_B)\n","\n","            imgs_A = np.array(imgs_A)/127.5 - 1.\n","            imgs_B = np.array(imgs_B)/127.5 - 1.\n","\n","            yield imgs_A, imgs_B\n","\n","    def load_img(self, path):\n","        img = self.imread(path)\n","        #img = scipy.misc.imresize(img, self.img_res)\n","        img = cv2.resize(img, self.img_res)\n","        img = img/127.5 - 1.\n","        return img[np.newaxis, :, :, :]\n","\n","    def imread(self, path):\n","        #return scipy.misc.imread(path, mode='RGB').astype(np.float)\n","        return imread(path).astype(np.float)"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"tTGS5IrZeIFJ","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597530634591,"user_tz":-540,"elapsed":943,"user":{"displayName":"Noboru Koike","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggp8njUb4jc54JrzfM5cQBkfiCdlz6nY17y8-1szg=s64","userId":"05156582812995850159"}}},"source":["IMG_ROWS = 256\n","IMG_COLS = 256\n","\n","data_loader = DataLoader('ukiyoe2novel', img_res=(IMG_ROWS, IMG_COLS))"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"cpTVx-uXeMjl","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597530637532,"user_tz":-540,"elapsed":1839,"user":{"displayName":"Noboru Koike","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggp8njUb4jc54JrzfM5cQBkfiCdlz6nY17y8-1szg=s64","userId":"05156582812995850159"}}},"source":["class CycleGAN:\n","    def __init__(self):\n","        self.history = pd.DataFrame({}, columns=[\n","            'epoch', 'epochs', 'batch_idx', 'batch_num', 'd_loss', 'acc', 'g_loss',\n","            'adv', 'recon', 'id', 'elapsed_time'])\n","\n","        self.img_save_dir = os.path.join(OUTPUT_DIR_PATH, 'images')\n","        self.model_save_dir = os.path.join(OUTPUT_DIR_PATH, 'saved_models')\n","        self.combined_name = 'combined_model'\n","        self.g_AB_name = 'g_AB_model'\n","        self.g_BA_name = 'g_BA_model'\n","\n","        self.train_cnt = 0\n","\n","        # Input shape\n","        self.img_rows = IMG_ROWS\n","        self.img_cols = IMG_COLS\n","        self.channels = 3\n","        self.img_shape = (self.img_rows, self.img_cols, self.channels)\n","\n","        self.d_A = None\n","        self.d_B = None\n","        self.g_AB = None\n","        self.g_BA = None\n","        self.combined = None\n","\n","    def init(self, data_loader=None):\n","        # Configure data loader\n","        #self.dataset_name = 'apple2orange'\n","        #self.data_loader = DataLoader(dataset_name=self.dataset_name,\n","        #                              img_res=(self.img_rows, self.img_cols))\n","        if data_loader:\n","            self.data_loader = data_loader\n","            self.dataset_name = self.data_loader.dataset_name \n","\n","        # Calculate output shape of D (PatchGAN)\n","        patch = int(self.img_rows / 2**4)\n","        self.disc_patch = (patch, patch, 1)\n","\n","        # Number of filters in the first layer of G and D\n","        #self.gf = 32 # U-Net, 128\n","        self.gf = 64\n","        self.df = 64\n","\n","        # Loss weights\n","        self.lambda_cycle = 10.0                    # Cycle-consistency loss\n","        self.lambda_id = 0.1 * self.lambda_cycle    # Identity loss\n","\n","        optimizer = Adam(0.0002, 0.5)\n","\n","        # Build and compile the discriminators\n","        self.d_A = self.build_discriminator()\n","        self.d_B = self.build_discriminator()\n","        self.d_A.compile(loss='mse',\n","                         optimizer=optimizer,\n","                         metrics=['accuracy'])\n","        self.d_B.compile(loss='mse',\n","                         optimizer=optimizer,\n","                         metrics=['accuracy'])\n","\n","        # Build the generators\n","        self.g_AB = self.build_generator()\n","        self.g_BA = self.build_generator()\n","\n","        # Input images from both domains\n","        img_A = Input(shape=self.img_shape)\n","        img_B = Input(shape=self.img_shape)\n","\n","        # Translate images to the other domain\n","        fake_B = self.g_AB(img_A)\n","        fake_A = self.g_BA(img_B)\n","\n","        # Translate images back to original domain\n","        reconstr_A = self.g_BA(fake_B)\n","        reconstr_B = self.g_AB(fake_A)\n","\n","        # Identity mapping of images\n","        img_A_id = self.g_BA(img_A)\n","        img_B_id = self.g_AB(img_B)\n","\n","        # For the combined model we will only train the generators\n","        self.d_A.trainable = False\n","        self.d_B.trainable = False\n","\n","        # Discriminators determines validity of translated images\n","        valid_A = self.d_A(fake_A)\n","        valid_B = self.d_B(fake_B)\n","\n","        # Combined model trains generators to fool discriminators\n","        self.combined = Model(inputs=[img_A, img_B],\n","                              outputs=[valid_A, valid_B,\n","                                       reconstr_A, reconstr_B,\n","                                       img_A_id, img_B_id ])\n","        self.combined.compile(loss=['mse', 'mse',\n","                                    'mae', 'mae',\n","                                    'mae', 'mae'],\n","                              loss_weights=[1, 1,\n","                                            self.lambda_cycle, self.lambda_cycle,\n","                                            self.lambda_id, self.lambda_id ],\n","                              optimizer=optimizer)\n","\n","    def build_generator(self):\n","        \"\"\"U-Net Generator\"\"\"\n","\n","        def conv2d(layer_input, filters, f_size=4):\n","            \"\"\"Layers used during downsampling\"\"\"\n","            d = Conv2D(filters, kernel_size=f_size, strides=2, padding='same')(layer_input)\n","            d = LeakyReLU(alpha=0.2)(d)\n","            d = InstanceNormalization()(d)\n","            return d\n","\n","        def deconv2d(layer_input, skip_input, filters, f_size=4, dropout_rate=0):\n","            \"\"\"Layers used during upsampling\"\"\"\n","            u = UpSampling2D(size=2)(layer_input)\n","            u = Conv2D(filters, kernel_size=f_size, strides=1, padding='same', activation='relu')(u)\n","            if dropout_rate:\n","                u = Dropout(dropout_rate)(u)\n","            u = InstanceNormalization()(u)\n","            u = Concatenate()([u, skip_input])\n","            return u\n","\n","        # Image input\n","        d0 = Input(shape=self.img_shape)\n","\n","        # U-Net, 12\n","        ## Downsampling\n","        #d1 = conv2d(d0, self.gf)\n","        #d2 = conv2d(d1, self.gf*2)\n","        #d3 = conv2d(d2, self.gf*4)\n","        #d4 = conv2d(d3, self.gf*8)\n","        #\n","        ## Upsampling\n","        #u1 = deconv2d(d4, d3, self.gf*4)\n","        #u2 = deconv2d(u1, d2, self.gf*2)\n","        #u3 = deconv2d(u2, d1, self.gf)\n","        #\n","        #u4 = UpSampling2D(size=2)(u3)\n","        #output_img = Conv2D(self.channels, kernel_size=4, strides=1, padding='same', activation='tanh')(u4)\n","\n","        # Downsampling\n","        d1 = conv2d(d0, self.gf)\n","        d2 = conv2d(d1, self.gf*2)\n","        d3 = conv2d(d2, self.gf*4)\n","        d4 = conv2d(d3, self.gf*8)\n","        d5 = conv2d(d4, self.gf*8)\n","        d6 = conv2d(d5, self.gf*8)\n","        d7 = conv2d(d6, self.gf*8)\n","\n","        # Upsampling\n","        u1 = deconv2d(d7, d6, self.gf*8)\n","        u2 = deconv2d(u1, d5, self.gf*8)\n","        u3 = deconv2d(u2, d4, self.gf*8)\n","        u4 = deconv2d(u3, d3, self.gf*4)\n","        u5 = deconv2d(u4, d2, self.gf*2)\n","        u6 = deconv2d(u5, d1, self.gf)\n","\n","        u7 = UpSampling2D(size=2)(u6)\n","        output_img = Conv2D(self.channels, kernel_size=4, strides=1, padding='same', activation='tanh')(u7)\n","\n","        return Model(d0, output_img)\n","\n","    def build_discriminator(self):\n","\n","        def d_layer(layer_input, filters, f_size=4, normalization=True):\n","            \"\"\"Discriminator layer\"\"\"\n","            d = Conv2D(filters, kernel_size=f_size, strides=2, padding='same')(layer_input)\n","            d = LeakyReLU(alpha=0.2)(d)\n","            if normalization:\n","                d = InstanceNormalization()(d)\n","            return d\n","\n","        img = Input(shape=self.img_shape)\n","\n","        d1 = d_layer(img, self.df, normalization=False)\n","        d2 = d_layer(d1, self.df*2)\n","        d3 = d_layer(d2, self.df*4)\n","        d4 = d_layer(d3, self.df*8)\n","\n","        validity = Conv2D(1, kernel_size=4, strides=1, padding='same')(d4)\n","\n","        return Model(img, validity)\n","\n","    def train(self, epochs, batch_size=1, sample_interval=-1, save_interval=-1):\n","        self.train_cnt += 1\n","\n","        print(datetime.datetime.now().isoformat(), 'Start', self.train_cnt)\n","\n","        start_time = datetime.datetime.now()\n","\n","        # Adversarial loss ground truths\n","        valid = np.ones((batch_size,) + self.disc_patch)\n","        fake = np.zeros((batch_size,) + self.disc_patch)\n","\n","        step_cnt = 1\n","\n","        #for epoch in range(epochs):\n","        for epoch in range(1, epochs+1):\n","            #for batch_i, (imgs_A, imgs_B) in enumerate(self.data_loader.load_batch(batch_size)):\n","            for batch_i, (imgs_A, imgs_B) in enumerate(self.data_loader.load_batch(batch_size), 1):\n","\n","                # Translate images to opposite domain\n","                fake_B = self.g_AB.predict(imgs_A)\n","                fake_A = self.g_BA.predict(imgs_B)\n","\n","                # Train the discriminators (original images = real / translated = Fake)\n","                dA_loss_real = self.d_A.train_on_batch(imgs_A, valid)\n","                dA_loss_fake = self.d_A.train_on_batch(fake_A, fake)\n","                dA_loss = 0.5 * np.add(dA_loss_real, dA_loss_fake)\n","\n","                dB_loss_real = self.d_B.train_on_batch(imgs_B, valid)\n","                dB_loss_fake = self.d_B.train_on_batch(fake_B, fake)\n","                dB_loss = 0.5 * np.add(dB_loss_real, dB_loss_fake)\n","\n","                # Total disciminator loss\n","                d_loss = 0.5 * np.add(dA_loss, dB_loss)\n","\n","                # Train the generators\n","                g_loss = self.combined.train_on_batch([imgs_A, imgs_B],\n","                                                      [valid, valid,\n","                                                       imgs_A, imgs_B,\n","                                                       imgs_A, imgs_B])\n","\n","                elapsed_time = datetime.datetime.now() - start_time\n","\n","                # Plot the progress\n","                # print(\"[Epoch %d/%d] [Batch %d/%d] [D loss: %f, acc: %3d%%] [G loss: %05f, adv: %05f, recon: %05f, id: %05f] time: %s \" % (\n","                #     epoch, epochs,\n","                #     batch_i, self.data_loader.n_batches,\n","                #     d_loss[0], 100*d_loss[1],\n","                #     g_loss[0],\n","                #     np.mean(g_loss[1:3]),\n","                #     np.mean(g_loss[3:5]),\n","                #     np.mean(g_loss[5:6]),\n","                #     elapsed_time))\n","                self.history = self.history.append({\n","                    'epoch': epoch,\n","                    'epochs': epochs,\n","                    'batch_idx': batch_i,\n","                    'batch_num': self.data_loader.n_batches,\n","                    'd_loss': d_loss[0],\n","                    'acc': d_loss[1],\n","                    'g_loss': g_loss[0],\n","                    'adv': np.mean(g_loss[1:3]),\n","                    'recon': np.mean(g_loss[3:5]),\n","                    'id': np.mean(g_loss[5:6]),\n","                    'elapsed_time': elapsed_time\n","                }, ignore_index=True)\n","\n","                # If at save interval => save generated image samples\n","                #if sample_interval > 0 and batch_i % sample_interval == 0:\n","                if sample_interval > 0 and step_cnt % sample_interval == 0:\n","                    print(\"[Epoch %d/%d] [Batch %d/%d] [D loss: %f, acc: %3d%%] [G loss: %05f, adv: %05f, recon: %05f, id: %05f] time: %s \" % (\n","                        epoch, epochs,\n","                        batch_i, self.data_loader.n_batches,\n","                        d_loss[0], 100*d_loss[1],\n","                        g_loss[0],\n","                        np.mean(g_loss[1:3]),\n","                        np.mean(g_loss[3:5]),\n","                        np.mean(g_loss[5:6]),\n","                        elapsed_time))\n","\n","                    self.sample_images(epoch, batch_i)\n","\n","                #if save_interval > 0 and batch_i != 1 and (batch_i % save_interval) == 0:\n","                if save_interval > 0 and step_cnt % save_interval == 0:\n","                    file_suffix = '{}_{}_{}'.format(self.train_cnt, epoch, batch_i)\n","                    self.save_model_weights(self.combined, self.combined_name, file_suffix)\n","\n","                step_cnt += 1\n","\n","        print(datetime.datetime.now().isoformat(), 'End')\n","\n","    def generate_image_A(self, img):\n","        return self.g_AB.predict(img)\n","\n","    def generate_image_B(self, img):\n","        return self.g_BA.predict(img)\n","\n","    def sample_images(self, epoch, batch_i):\n","        dir_path = os.path.join(self.img_save_dir, self.dataset_name)\n","\n","        #os.makedirs('images/%s' % self.dataset_name, exist_ok=True)\n","        os.makedirs(dir_path, exist_ok=True)\n","\n","        r, c = 2, 3\n","\n","        imgs_A = self.data_loader.load_data(domain=\"A\", batch_size=1, is_testing=True)\n","        imgs_B = self.data_loader.load_data(domain=\"B\", batch_size=1, is_testing=True)\n","\n","        # Demo (for GIF)\n","        #imgs_A = self.data_loader.load_img('datasets/apple2orange/testA/n07740461_1541.jpg')\n","        #imgs_B = self.data_loader.load_img('datasets/apple2orange/testB/n07749192_4241.jpg')\n","\n","        # Translate images to the other domain\n","        fake_B = self.g_AB.predict(imgs_A)\n","        fake_A = self.g_BA.predict(imgs_B)\n","\n","        # Translate back to original domain\n","        reconstr_A = self.g_BA.predict(fake_B)\n","        reconstr_B = self.g_AB.predict(fake_A)\n","\n","        gen_imgs = np.concatenate([imgs_A, fake_B, reconstr_A, imgs_B, fake_A, reconstr_B])\n","\n","        # Rescale images 0 - 1\n","        gen_imgs = 0.5 * gen_imgs + 0.5\n","\n","        titles = ['Original', 'Translated', 'Reconstructed']\n","        fig, axs = plt.subplots(r, c)\n","        cnt = 0\n","\n","        for i in range(r):\n","            for j in range(c):\n","                axs[i, j].imshow(gen_imgs[cnt])\n","                axs[i, j].set_title(titles[j])\n","                axs[i, j].axis('off')\n","                cnt += 1\n","\n","        #fig.savefig(\"images/%s/%d_%d.png\" % (self.dataset_name, epoch, batch_i))\n","        file_path = os.path.join(dir_path, '{}_{}_{}.png'.format(self.train_cnt, epoch, batch_i))\n","        fig.savefig(file_path)\n","\n","        plt.close()\n","\n","    def plot_hisotry(self, columns=[]):\n","        if len(columns) == 0:\n","            columns = ['d_loss', 'g_loss']\n","            #columns = ['d_loss', 'acc', 'g_loss', 'adv', 'recon', 'id',]\n","        self.history[columns].plot()\n","\n","    def save_models(self, file_suffix=None):\n","        self.save_model_weights(self.combined, self.combined_name, file_suffix)\n","        #self.save_model_weights(self.g_AB, self.g_AB_name, file_suffix)\n","        #self.save_model_weights(self.g_BA, self.g_BA_name, file_suffix)\n","\n","    def save_model_weights(self, model, model_name, file_suffix=None):\n","        file_path = os.path.join(self.model_save_dir, self._create_h5_file_name(model_name, file_suffix))\n","        model.save_weights(file_path)\n","\n","        print('Model weights saved.', model_name)\n","\n","    def load_models(self, file_suffix=None):\n","        self.load_model_weights(self.combined_name, file_suffix)\n","        self.load_model_weights(self.g_AB_name, file_suffix)\n","        self.load_model_weights(self.g_BA_name, file_suffix)\n","\n","    def load_model_weights(self, model_name, file_suffix=None):\n","        model = None\n","\n","        if model_name == self.combined_name:\n","            model = self.combined\n","        elif model_name == self.g_AB_name:\n","            model = self.g_AB\n","        elif model_name == self.g_BA_name:\n","            model = self.g_BA\n","        else:\n","            print('Unsupported.', model_name)\n","            return\n","\n","        if not model:\n","            print('Not initialized.', model_name)\n","            return\n","\n","        file_path = os.path.join(self.model_save_dir, self._create_h5_file_name(model_name, file_suffix))\n","\n","        if not os.path.exists(file_path):\n","            print('File Not found.', model_name)\n","            return\n","\n","        model.load_weights(file_path)\n","\n","        print('Model weights loaded.', model_name)\n","\n","    def _create_h5_file_name(self, model_name, suffix=None):\n","        if suffix:\n","            return '{}_{}.h5'.format(model_name, suffix)\n","        else:\n","            return '{}.h5'.format(model_name)"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"LBz0qikRej1Q","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1597532327924,"user_tz":-540,"elapsed":1690521,"user":{"displayName":"Noboru Koike","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggp8njUb4jc54JrzfM5cQBkfiCdlz6nY17y8-1szg=s64","userId":"05156582812995850159"}},"outputId":"a9f55bcb-0288-453b-fd71-13a54d7e792e"},"source":["gan = CycleGAN()\n","gan.init(data_loader=data_loader)\n","\n","# Image A count: 560\n","gan.train(epochs=1, batch_size=1, sample_interval=1, save_interval=-1)\n","\n","#gan.history.to_csv(os.path.join(OUTPUT_DIR_PATH, 'history.csv'))"],"execution_count":10,"outputs":[{"output_type":"stream","text":["2020-08-15T22:30:46.890140 Start 1\n","[Epoch 1/1] [Batch 1/560] [D loss: 3.329383, acc:  45%] [G loss: 32.192642, adv: 6.800217, recon: 0.860866, id: 0.624777] time: 0:00:53.899007 \n","[Epoch 1/1] [Batch 2/560] [D loss: 7.931188, acc:  49%] [G loss: 49.723988, adv: 15.990820, recon: 0.810668, id: 0.616673] time: 0:01:03.999699 \n","[Epoch 1/1] [Batch 3/560] [D loss: 7.004171, acc:  49%] [G loss: 55.670673, adv: 19.728820, recon: 0.734047, id: 0.710410] time: 0:01:07.868774 \n","[Epoch 1/1] [Batch 4/560] [D loss: 7.800758, acc:  50%] [G loss: 32.137283, adv: 7.308360, recon: 0.798781, id: 0.588303] time: 0:01:11.757094 \n","[Epoch 1/1] [Batch 5/560] [D loss: 9.270095, acc:  49%] [G loss: 38.486797, adv: 11.004429, recon: 0.739473, id: 0.853065] time: 0:01:15.786533 \n","[Epoch 1/1] [Batch 6/560] [D loss: 6.294852, acc:  49%] [G loss: 24.750280, adv: 4.468147, recon: 0.709897, id: 0.809272] time: 0:01:19.637423 \n","[Epoch 1/1] [Batch 7/560] [D loss: 4.241166, acc:  46%] [G loss: 26.249926, adv: 5.460211, recon: 0.677660, id: 0.969312] time: 0:01:24.122193 \n","[Epoch 1/1] [Batch 8/560] [D loss: 3.933357, acc:  49%] [G loss: 24.029509, adv: 4.495327, recon: 0.663626, id: 0.938106] time: 0:01:28.605528 \n","[Epoch 1/1] [Batch 9/560] [D loss: 2.987237, acc:  50%] [G loss: 20.122555, adv: 2.733674, recon: 0.636794, id: 0.998088] time: 0:01:32.970297 \n","[Epoch 1/1] [Batch 10/560] [D loss: 2.492520, acc:  49%] [G loss: 16.920982, adv: 1.538147, recon: 0.603648, id: 0.922020] time: 0:01:36.845486 \n","[Epoch 1/1] [Batch 11/560] [D loss: 1.980425, acc:  49%] [G loss: 17.526749, adv: 2.224968, recon: 0.566749, id: 0.938114] time: 0:01:41.157272 \n","[Epoch 1/1] [Batch 12/560] [D loss: 2.025753, acc:  50%] [G loss: 16.831703, adv: 1.210433, recon: 0.633018, id: 0.903553] time: 0:01:45.423757 \n","[Epoch 1/1] [Batch 13/560] [D loss: 1.520749, acc:  53%] [G loss: 15.591228, adv: 1.114669, recon: 0.580310, id: 0.914749] time: 0:01:48.525739 \n","[Epoch 1/1] [Batch 14/560] [D loss: 1.726916, acc:  51%] [G loss: 15.592337, adv: 1.388023, recon: 0.565085, id: 0.797030] time: 0:01:52.115008 \n","[Epoch 1/1] [Batch 15/560] [D loss: 1.454945, acc:  50%] [G loss: 13.852758, adv: 1.207490, recon: 0.491134, id: 0.853781] time: 0:01:56.436397 \n","[Epoch 1/1] [Batch 16/560] [D loss: 1.676422, acc:  51%] [G loss: 14.472924, adv: 1.248818, recon: 0.517441, id: 0.808394] time: 0:02:00.262347 \n","[Epoch 1/1] [Batch 17/560] [D loss: 2.393861, acc:  50%] [G loss: 14.313834, adv: 1.860545, recon: 0.444747, id: 0.908756] time: 0:02:04.480941 \n","[Epoch 1/1] [Batch 18/560] [D loss: 2.705813, acc:  49%] [G loss: 15.380286, adv: 1.349823, recon: 0.549112, id: 0.916671] time: 0:02:09.080211 \n","[Epoch 1/1] [Batch 19/560] [D loss: 1.990484, acc:  52%] [G loss: 16.593172, adv: 1.368993, recon: 0.612968, id: 0.802436] time: 0:02:13.691040 \n","[Epoch 1/1] [Batch 20/560] [D loss: 1.604166, acc:  54%] [G loss: 14.439835, adv: 1.244488, recon: 0.518951, id: 0.783442] time: 0:02:17.653946 \n","[Epoch 1/1] [Batch 21/560] [D loss: 1.477683, acc:  53%] [G loss: 13.398314, adv: 1.356496, recon: 0.458365, id: 0.743436] time: 0:02:22.160619 \n","[Epoch 1/1] [Batch 22/560] [D loss: 1.238944, acc:  47%] [G loss: 13.544353, adv: 1.068859, recon: 0.501384, id: 0.672852] time: 0:02:26.384477 \n","[Epoch 1/1] [Batch 23/560] [D loss: 1.237369, acc:  51%] [G loss: 13.500254, adv: 1.547140, recon: 0.448664, id: 0.664910] time: 0:02:29.923232 \n","[Epoch 1/1] [Batch 24/560] [D loss: 0.999139, acc:  55%] [G loss: 13.068780, adv: 1.005025, recon: 0.488580, id: 0.613430] time: 0:02:33.695110 \n","[Epoch 1/1] [Batch 25/560] [D loss: 1.030056, acc:  52%] [G loss: 11.987859, adv: 1.305426, recon: 0.403361, id: 0.648328] time: 0:02:37.549678 \n","[Epoch 1/1] [Batch 26/560] [D loss: 0.966315, acc:  56%] [G loss: 12.631628, adv: 0.894316, recon: 0.469312, id: 0.773881] time: 0:02:41.335283 \n","[Epoch 1/1] [Batch 27/560] [D loss: 0.748750, acc:  55%] [G loss: 11.650137, adv: 1.220167, recon: 0.391851, id: 0.665667] time: 0:02:45.744794 \n","[Epoch 1/1] [Batch 28/560] [D loss: 0.781121, acc:  52%] [G loss: 10.904202, adv: 1.032849, recon: 0.375018, id: 0.674207] time: 0:02:50.137545 \n","[Epoch 1/1] [Batch 29/560] [D loss: 0.915673, acc:  52%] [G loss: 13.784525, adv: 1.454799, recon: 0.479507, id: 0.665125] time: 0:02:54.406718 \n","[Epoch 1/1] [Batch 30/560] [D loss: 0.725988, acc:  59%] [G loss: 14.144354, adv: 1.833975, recon: 0.456626, id: 0.657144] time: 0:02:58.569029 \n","[Epoch 1/1] [Batch 31/560] [D loss: 1.185867, acc:  53%] [G loss: 13.274717, adv: 1.002605, recon: 0.497069, id: 0.682307] time: 0:03:01.636799 \n","[Epoch 1/1] [Batch 32/560] [D loss: 1.524213, acc:  54%] [G loss: 17.357391, adv: 3.348876, recon: 0.474207, id: 0.549666] time: 0:03:04.886087 \n","[Epoch 1/1] [Batch 33/560] [D loss: 1.043622, acc:  54%] [G loss: 12.339533, adv: 1.126369, recon: 0.437993, id: 0.670542] time: 0:03:09.138023 \n","[Epoch 1/1] [Batch 34/560] [D loss: 0.685498, acc:  60%] [G loss: 11.895647, adv: 0.813908, recon: 0.443197, id: 0.740959] time: 0:03:13.009145 \n","[Epoch 1/1] [Batch 35/560] [D loss: 0.719364, acc:  53%] [G loss: 11.352783, adv: 0.768375, recon: 0.427769, id: 0.613218] time: 0:03:16.377796 \n","[Epoch 1/1] [Batch 36/560] [D loss: 0.652767, acc:  56%] [G loss: 13.189657, adv: 1.218968, recon: 0.475746, id: 0.630719] time: 0:03:21.084198 \n","[Epoch 1/1] [Batch 37/560] [D loss: 0.708900, acc:  51%] [G loss: 12.225777, adv: 0.903834, recon: 0.459521, id: 0.619349] time: 0:03:24.815575 \n","[Epoch 1/1] [Batch 38/560] [D loss: 0.636577, acc:  55%] [G loss: 12.457381, adv: 0.711644, recon: 0.489378, id: 0.584246] time: 0:03:27.967109 \n","[Epoch 1/1] [Batch 39/560] [D loss: 0.675408, acc:  49%] [G loss: 12.041142, adv: 0.659563, recon: 0.476120, id: 0.593099] time: 0:03:31.841770 \n","[Epoch 1/1] [Batch 40/560] [D loss: 0.504466, acc:  56%] [G loss: 10.586498, adv: 0.781042, recon: 0.392043, id: 0.604164] time: 0:03:36.206279 \n","[Epoch 1/1] [Batch 41/560] [D loss: 0.423543, acc:  67%] [G loss: 12.869036, adv: 0.721705, recon: 0.504405, id: 0.749068] time: 0:03:40.206758 \n","[Epoch 1/1] [Batch 42/560] [D loss: 0.627989, acc:  51%] [G loss: 14.513441, adv: 0.772666, recon: 0.580640, id: 0.643039] time: 0:03:45.500977 \n","[Epoch 1/1] [Batch 43/560] [D loss: 0.538263, acc:  55%] [G loss: 12.873512, adv: 0.824747, recon: 0.501555, id: 0.573176] time: 0:03:49.289920 \n","[Epoch 1/1] [Batch 44/560] [D loss: 0.533389, acc:  53%] [G loss: 11.709285, adv: 1.121096, recon: 0.418428, id: 0.580545] time: 0:03:52.857681 \n","[Epoch 1/1] [Batch 45/560] [D loss: 0.669594, acc:  51%] [G loss: 10.972878, adv: 0.848134, recon: 0.409886, id: 0.517694] time: 0:03:57.039830 \n","[Epoch 1/1] [Batch 46/560] [D loss: 0.497233, acc:  56%] [G loss: 9.961094, adv: 0.636476, recon: 0.382794, id: 0.453504] time: 0:04:01.621064 \n","[Epoch 1/1] [Batch 47/560] [D loss: 0.517756, acc:  56%] [G loss: 11.645015, adv: 0.843658, recon: 0.440058, id: 0.549701] time: 0:04:05.433205 \n","[Epoch 1/1] [Batch 48/560] [D loss: 0.415599, acc:  59%] [G loss: 10.752260, adv: 0.674730, recon: 0.412391, id: 0.585332] time: 0:04:09.054072 \n","[Epoch 1/1] [Batch 49/560] [D loss: 0.454198, acc:  50%] [G loss: 9.650768, adv: 0.704243, recon: 0.356931, id: 0.553166] time: 0:04:12.232690 \n","[Epoch 1/1] [Batch 50/560] [D loss: 0.454439, acc:  56%] [G loss: 9.769180, adv: 0.584178, recon: 0.380831, id: 0.438442] time: 0:04:16.958691 \n","[Epoch 1/1] [Batch 51/560] [D loss: 0.457084, acc:  54%] [G loss: 9.893840, adv: 0.645231, recon: 0.380947, id: 0.487196] time: 0:04:21.568018 \n","[Epoch 1/1] [Batch 52/560] [D loss: 0.450292, acc:  52%] [G loss: 9.814987, adv: 0.627835, recon: 0.377388, id: 0.458827] time: 0:04:25.475571 \n","[Epoch 1/1] [Batch 53/560] [D loss: 0.339547, acc:  62%] [G loss: 9.520364, adv: 0.550706, recon: 0.371361, id: 0.461561] time: 0:04:29.713906 \n","[Epoch 1/1] [Batch 54/560] [D loss: 0.435728, acc:  55%] [G loss: 11.515917, adv: 0.552212, recon: 0.466826, id: 0.501439] time: 0:04:33.532873 \n","[Epoch 1/1] [Batch 55/560] [D loss: 0.447073, acc:  47%] [G loss: 10.404439, adv: 0.472640, recon: 0.421361, id: 0.454908] time: 0:04:37.426323 \n","[Epoch 1/1] [Batch 56/560] [D loss: 0.441621, acc:  54%] [G loss: 10.653357, adv: 0.530723, recon: 0.430216, id: 0.496349] time: 0:04:41.071159 \n","[Epoch 1/1] [Batch 57/560] [D loss: 0.429827, acc:  48%] [G loss: 9.875160, adv: 0.439526, recon: 0.399545, id: 0.498369] time: 0:04:45.438575 \n","[Epoch 1/1] [Batch 58/560] [D loss: 0.423540, acc:  54%] [G loss: 11.084408, adv: 0.559641, recon: 0.448311, id: 0.558793] time: 0:04:49.922581 \n","[Epoch 1/1] [Batch 59/560] [D loss: 0.392842, acc:  59%] [G loss: 9.674319, adv: 0.653732, recon: 0.371143, id: 0.408656] time: 0:04:53.715543 \n","[Epoch 1/1] [Batch 60/560] [D loss: 0.404730, acc:  53%] [G loss: 10.316663, adv: 0.589812, recon: 0.408184, id: 0.494553] time: 0:04:56.747624 \n","[Epoch 1/1] [Batch 61/560] [D loss: 0.332962, acc:  67%] [G loss: 13.423405, adv: 0.704858, recon: 0.545616, id: 0.614101] time: 0:04:59.925254 \n","[Epoch 1/1] [Batch 62/560] [D loss: 0.439388, acc:  52%] [G loss: 9.238670, adv: 0.602364, recon: 0.364756, id: 0.364319] time: 0:05:04.117132 \n","[Epoch 1/1] [Batch 63/560] [D loss: 0.336259, acc:  57%] [G loss: 9.435156, adv: 0.609910, recon: 0.368992, id: 0.407239] time: 0:05:07.821263 \n","[Epoch 1/1] [Batch 64/560] [D loss: 0.451468, acc:  53%] [G loss: 11.204630, adv: 0.587481, recon: 0.455220, id: 0.468272] time: 0:05:11.536852 \n","[Epoch 1/1] [Batch 65/560] [D loss: 0.458613, acc:  55%] [G loss: 9.849205, adv: 0.682949, recon: 0.384885, id: 0.441195] time: 0:05:14.494231 \n","[Epoch 1/1] [Batch 66/560] [D loss: 0.349106, acc:  54%] [G loss: 8.807306, adv: 0.451101, recon: 0.360328, id: 0.341526] time: 0:05:19.312155 \n","[Epoch 1/1] [Batch 67/560] [D loss: 0.389596, acc:  51%] [G loss: 8.698308, adv: 0.542302, recon: 0.343640, id: 0.343485] time: 0:05:23.653019 \n","[Epoch 1/1] [Batch 68/560] [D loss: 0.418260, acc:  52%] [G loss: 10.314767, adv: 0.554832, recon: 0.414192, id: 0.468398] time: 0:05:27.658024 \n","[Epoch 1/1] [Batch 69/560] [D loss: 0.388700, acc:  51%] [G loss: 9.978749, adv: 0.505950, recon: 0.404829, id: 0.413704] time: 0:05:30.009233 \n","[Epoch 1/1] [Batch 70/560] [D loss: 0.452709, acc:  49%] [G loss: 9.716806, adv: 0.490662, recon: 0.395717, id: 0.372495] time: 0:05:34.213636 \n","[Epoch 1/1] [Batch 71/560] [D loss: 0.436340, acc:  54%] [G loss: 10.059378, adv: 0.515525, recon: 0.411518, id: 0.394830] time: 0:05:37.998828 \n","[Epoch 1/1] [Batch 72/560] [D loss: 0.379463, acc:  52%] [G loss: 8.626510, adv: 0.523934, recon: 0.340920, id: 0.356950] time: 0:05:42.448967 \n","[Epoch 1/1] [Batch 73/560] [D loss: 0.398202, acc:  49%] [G loss: 10.768138, adv: 0.538997, recon: 0.445003, id: 0.378066] time: 0:05:46.707061 \n","[Epoch 1/1] [Batch 74/560] [D loss: 0.438288, acc:  50%] [G loss: 9.712507, adv: 0.543309, recon: 0.387585, id: 0.407924] time: 0:05:49.858201 \n","[Epoch 1/1] [Batch 75/560] [D loss: 0.315432, acc:  54%] [G loss: 7.814632, adv: 0.522483, recon: 0.302112, id: 0.384386] time: 0:05:52.402343 \n","[Epoch 1/1] [Batch 76/560] [D loss: 0.332244, acc:  54%] [G loss: 8.304276, adv: 0.472968, recon: 0.331915, id: 0.386742] time: 0:05:55.919366 \n","[Epoch 1/1] [Batch 77/560] [D loss: 0.321558, acc:  54%] [G loss: 8.227287, adv: 0.619703, recon: 0.314810, id: 0.362875] time: 0:06:00.954823 \n","[Epoch 1/1] [Batch 78/560] [D loss: 0.316291, acc:  58%] [G loss: 10.174034, adv: 0.495488, recon: 0.418342, id: 0.463299] time: 0:06:04.862462 \n","[Epoch 1/1] [Batch 79/560] [D loss: 0.404507, acc:  50%] [G loss: 9.517799, adv: 0.521526, recon: 0.387769, id: 0.386118] time: 0:06:08.310766 \n","[Epoch 1/1] [Batch 80/560] [D loss: 0.296258, acc:  58%] [G loss: 8.910098, adv: 0.472160, recon: 0.359604, id: 0.413163] time: 0:06:12.317468 \n","[Epoch 1/1] [Batch 81/560] [D loss: 0.316165, acc:  61%] [G loss: 9.102608, adv: 0.672820, recon: 0.354653, id: 0.346892] time: 0:06:14.988263 \n","[Epoch 1/1] [Batch 82/560] [D loss: 0.415304, acc:  54%] [G loss: 9.141459, adv: 0.508340, recon: 0.370254, id: 0.380848] time: 0:06:18.607423 \n","[Epoch 1/1] [Batch 83/560] [D loss: 0.343527, acc:  56%] [G loss: 8.018897, adv: 0.511759, recon: 0.316455, id: 0.356307] time: 0:06:22.204369 \n","[Epoch 1/1] [Batch 84/560] [D loss: 0.287962, acc:  58%] [G loss: 10.632086, adv: 0.438266, recon: 0.445843, id: 0.308604] time: 0:06:26.267040 \n","[Epoch 1/1] [Batch 85/560] [D loss: 0.460654, acc:  50%] [G loss: 9.359024, adv: 0.568370, recon: 0.373677, id: 0.340539] time: 0:06:29.627899 \n","[Epoch 1/1] [Batch 86/560] [D loss: 0.408234, acc:  52%] [G loss: 9.893063, adv: 0.483180, recon: 0.407043, id: 0.454158] time: 0:06:33.058652 \n","[Epoch 1/1] [Batch 87/560] [D loss: 0.404070, acc:  54%] [G loss: 7.038701, adv: 0.466841, recon: 0.276733, id: 0.248194] time: 0:06:36.703226 \n","[Epoch 1/1] [Batch 88/560] [D loss: 0.418644, acc:  56%] [G loss: 8.818012, adv: 0.535975, recon: 0.351979, id: 0.376822] time: 0:06:39.758133 \n","[Epoch 1/1] [Batch 89/560] [D loss: 0.415158, acc:  51%] [G loss: 8.714003, adv: 0.463463, recon: 0.354298, id: 0.280335] time: 0:06:42.634636 \n","[Epoch 1/1] [Batch 90/560] [D loss: 0.274616, acc:  60%] [G loss: 9.596408, adv: 0.759647, recon: 0.366987, id: 0.314186] time: 0:06:46.554492 \n","[Epoch 1/1] [Batch 91/560] [D loss: 0.318965, acc:  58%] [G loss: 8.923700, adv: 0.452175, recon: 0.368464, id: 0.300562] time: 0:06:50.322671 \n","[Epoch 1/1] [Batch 92/560] [D loss: 0.346908, acc:  58%] [G loss: 8.974337, adv: 0.461649, recon: 0.364989, id: 0.343782] time: 0:06:53.582379 \n","[Epoch 1/1] [Batch 93/560] [D loss: 0.370252, acc:  54%] [G loss: 8.315845, adv: 0.485842, recon: 0.333792, id: 0.298793] time: 0:06:57.453498 \n","[Epoch 1/1] [Batch 94/560] [D loss: 0.347320, acc:  52%] [G loss: 7.068100, adv: 0.451136, recon: 0.278143, id: 0.271094] time: 0:07:01.028288 \n","[Epoch 1/1] [Batch 95/560] [D loss: 0.331527, acc:  53%] [G loss: 7.375669, adv: 0.557464, recon: 0.281993, id: 0.265723] time: 0:07:04.685320 \n","[Epoch 1/1] [Batch 96/560] [D loss: 0.392497, acc:  49%] [G loss: 8.629194, adv: 0.533479, recon: 0.343396, id: 0.341209] time: 0:07:07.944619 \n","[Epoch 1/1] [Batch 97/560] [D loss: 0.461956, acc:  54%] [G loss: 8.385066, adv: 0.507725, recon: 0.332611, id: 0.373182] time: 0:07:10.895333 \n","[Epoch 1/1] [Batch 98/560] [D loss: 0.349998, acc:  56%] [G loss: 8.758289, adv: 0.522529, recon: 0.352016, id: 0.298996] time: 0:07:15.211934 \n","[Epoch 1/1] [Batch 99/560] [D loss: 0.296787, acc:  59%] [G loss: 7.436573, adv: 0.569664, recon: 0.285405, id: 0.278302] time: 0:07:19.309972 \n","[Epoch 1/1] [Batch 100/560] [D loss: 0.254114, acc:  65%] [G loss: 10.004603, adv: 0.507720, recon: 0.409262, id: 0.316663] time: 0:07:23.838540 \n","[Epoch 1/1] [Batch 101/560] [D loss: 0.250492, acc:  63%] [G loss: 7.284039, adv: 0.432935, recon: 0.290303, id: 0.286998] time: 0:07:28.786507 \n","[Epoch 1/1] [Batch 102/560] [D loss: 0.335277, acc:  51%] [G loss: 10.689203, adv: 0.469767, recon: 0.446321, id: 0.294949] time: 0:07:32.676047 \n","[Epoch 1/1] [Batch 103/560] [D loss: 0.259876, acc:  65%] [G loss: 10.974889, adv: 0.426320, recon: 0.460991, id: 0.266014] time: 0:07:35.060263 \n","[Epoch 1/1] [Batch 104/560] [D loss: 0.324327, acc:  58%] [G loss: 9.462122, adv: 0.496024, recon: 0.388243, id: 0.322057] time: 0:07:38.498394 \n","[Epoch 1/1] [Batch 105/560] [D loss: 0.405570, acc:  52%] [G loss: 9.007336, adv: 0.457945, recon: 0.365308, id: 0.472090] time: 0:07:42.696544 \n","[Epoch 1/1] [Batch 106/560] [D loss: 0.338228, acc:  51%] [G loss: 7.770601, adv: 0.403494, recon: 0.315905, id: 0.294909] time: 0:07:45.214971 \n","[Epoch 1/1] [Batch 107/560] [D loss: 0.317861, acc:  57%] [G loss: 9.250141, adv: 0.490054, recon: 0.377746, id: 0.343941] time: 0:07:49.338043 \n","[Epoch 1/1] [Batch 108/560] [D loss: 0.338338, acc:  53%] [G loss: 8.351812, adv: 0.423621, recon: 0.343292, id: 0.307220] time: 0:07:53.185246 \n","[Epoch 1/1] [Batch 109/560] [D loss: 0.348435, acc:  56%] [G loss: 9.529099, adv: 0.470667, recon: 0.391037, id: 0.409584] time: 0:07:56.070685 \n","[Epoch 1/1] [Batch 110/560] [D loss: 0.319882, acc:  58%] [G loss: 8.803715, adv: 0.494087, recon: 0.353940, id: 0.299556] time: 0:07:59.704817 \n","[Epoch 1/1] [Batch 111/560] [D loss: 0.265138, acc:  60%] [G loss: 8.635929, adv: 0.430342, recon: 0.353418, id: 0.331977] time: 0:08:02.928842 \n","[Epoch 1/1] [Batch 112/560] [D loss: 0.270645, acc:  63%] [G loss: 8.241289, adv: 0.404284, recon: 0.338237, id: 0.336293] time: 0:08:06.748889 \n","[Epoch 1/1] [Batch 113/560] [D loss: 0.269907, acc:  61%] [G loss: 9.982676, adv: 0.441043, recon: 0.417520, id: 0.360910] time: 0:08:09.362972 \n","[Epoch 1/1] [Batch 114/560] [D loss: 0.268946, acc:  60%] [G loss: 7.858500, adv: 0.557270, recon: 0.307553, id: 0.265869] time: 0:08:13.012818 \n","[Epoch 1/1] [Batch 115/560] [D loss: 0.403501, acc:  50%] [G loss: 8.125114, adv: 0.437208, recon: 0.329907, id: 0.355404] time: 0:08:16.702592 \n","[Epoch 1/1] [Batch 116/560] [D loss: 0.417595, acc:  41%] [G loss: 9.103243, adv: 0.601089, recon: 0.359822, id: 0.372629] time: 0:08:19.672531 \n","[Epoch 1/1] [Batch 117/560] [D loss: 0.373467, acc:  52%] [G loss: 7.054947, adv: 0.470731, recon: 0.278494, id: 0.236217] time: 0:08:22.886044 \n","[Epoch 1/1] [Batch 118/560] [D loss: 0.355207, acc:  50%] [G loss: 8.865428, adv: 0.511775, recon: 0.356592, id: 0.383305] time: 0:08:26.845857 \n","[Epoch 1/1] [Batch 119/560] [D loss: 0.285079, acc:  56%] [G loss: 7.790042, adv: 0.564812, recon: 0.307162, id: 0.270712] time: 0:08:29.913809 \n","[Epoch 1/1] [Batch 120/560] [D loss: 0.318604, acc:  61%] [G loss: 11.416002, adv: 0.435152, recon: 0.484032, id: 0.494784] time: 0:08:34.137614 \n","[Epoch 1/1] [Batch 121/560] [D loss: 0.333744, acc:  52%] [G loss: 7.847065, adv: 0.655379, recon: 0.296930, id: 0.256211] time: 0:08:37.612012 \n","[Epoch 1/1] [Batch 122/560] [D loss: 0.370249, acc:  65%] [G loss: 7.413562, adv: 0.611329, recon: 0.281053, id: 0.269864] time: 0:08:40.708116 \n","[Epoch 1/1] [Batch 123/560] [D loss: 0.314748, acc:  57%] [G loss: 8.468496, adv: 0.445937, recon: 0.343908, id: 0.330320] time: 0:08:44.543878 \n","[Epoch 1/1] [Batch 124/560] [D loss: 0.306199, acc:  59%] [G loss: 9.532527, adv: 0.549302, recon: 0.385528, id: 0.401679] time: 0:08:48.476762 \n","[Epoch 1/1] [Batch 125/560] [D loss: 0.274717, acc:  55%] [G loss: 6.825787, adv: 0.358100, recon: 0.277053, id: 0.229543] time: 0:08:50.922092 \n","[Epoch 1/1] [Batch 126/560] [D loss: 0.346289, acc:  56%] [G loss: 9.371551, adv: 0.693251, recon: 0.363203, id: 0.314331] time: 0:08:53.502665 \n","[Epoch 1/1] [Batch 127/560] [D loss: 0.367718, acc:  58%] [G loss: 6.922012, adv: 0.391129, recon: 0.279301, id: 0.262316] time: 0:08:57.065766 \n","[Epoch 1/1] [Batch 128/560] [D loss: 0.388890, acc:  49%] [G loss: 11.057053, adv: 0.501423, recon: 0.459021, id: 0.637797] time: 0:09:00.017409 \n","[Epoch 1/1] [Batch 129/560] [D loss: 0.296481, acc:  56%] [G loss: 6.402495, adv: 0.402163, recon: 0.254744, id: 0.242704] time: 0:09:02.658597 \n","[Epoch 1/1] [Batch 130/560] [D loss: 0.279817, acc:  63%] [G loss: 7.879299, adv: 0.567960, recon: 0.308821, id: 0.294844] time: 0:09:06.177262 \n","[Epoch 1/1] [Batch 131/560] [D loss: 0.340643, acc:  55%] [G loss: 9.897568, adv: 0.449332, recon: 0.411437, id: 0.319941] time: 0:09:09.379843 \n","[Epoch 1/1] [Batch 132/560] [D loss: 0.336742, acc:  56%] [G loss: 8.820297, adv: 0.580374, recon: 0.348086, id: 0.370318] time: 0:09:13.354221 \n","[Epoch 1/1] [Batch 133/560] [D loss: 0.354323, acc:  66%] [G loss: 7.729822, adv: 0.806706, recon: 0.280572, id: 0.219544] time: 0:09:17.196618 \n","[Epoch 1/1] [Batch 134/560] [D loss: 0.461372, acc:  58%] [G loss: 8.514845, adv: 0.428789, recon: 0.351902, id: 0.296692] time: 0:09:21.123045 \n","[Epoch 1/1] [Batch 135/560] [D loss: 0.352474, acc:  49%] [G loss: 7.380378, adv: 0.381009, recon: 0.301576, id: 0.307140] time: 0:09:25.336568 \n","[Epoch 1/1] [Batch 136/560] [D loss: 0.319047, acc:  55%] [G loss: 7.113286, adv: 0.345746, recon: 0.293218, id: 0.202239] time: 0:09:29.114658 \n","[Epoch 1/1] [Batch 137/560] [D loss: 0.385359, acc:  46%] [G loss: 7.569828, adv: 0.348098, recon: 0.311140, id: 0.379472] time: 0:09:32.590663 \n","[Epoch 1/1] [Batch 138/560] [D loss: 0.508726, acc:  45%] [G loss: 8.368954, adv: 0.527580, recon: 0.334075, id: 0.326059] time: 0:09:35.688242 \n","[Epoch 1/1] [Batch 139/560] [D loss: 0.355120, acc:  56%] [G loss: 9.656184, adv: 0.456078, recon: 0.398479, id: 0.361510] time: 0:09:39.141812 \n","[Epoch 1/1] [Batch 140/560] [D loss: 0.450446, acc:  51%] [G loss: 7.224455, adv: 0.469495, recon: 0.286392, id: 0.244651] time: 0:09:42.927419 \n","[Epoch 1/1] [Batch 141/560] [D loss: 0.367393, acc:  53%] [G loss: 10.656921, adv: 0.461200, recon: 0.442499, id: 0.566902] time: 0:09:46.843858 \n","[Epoch 1/1] [Batch 142/560] [D loss: 0.312961, acc:  54%] [G loss: 9.296008, adv: 0.460053, recon: 0.382766, id: 0.427653] time: 0:09:49.954214 \n","[Epoch 1/1] [Batch 143/560] [D loss: 0.319302, acc:  49%] [G loss: 8.533958, adv: 0.479515, recon: 0.344966, id: 0.311913] time: 0:09:53.621052 \n","[Epoch 1/1] [Batch 144/560] [D loss: 0.322106, acc:  58%] [G loss: 7.541500, adv: 0.501607, recon: 0.296703, id: 0.263940] time: 0:09:57.177841 \n","[Epoch 1/1] [Batch 145/560] [D loss: 0.297636, acc:  61%] [G loss: 9.015024, adv: 0.542696, recon: 0.362322, id: 0.314796] time: 0:10:00.727309 \n","[Epoch 1/1] [Batch 146/560] [D loss: 0.362335, acc:  47%] [G loss: 7.567958, adv: 0.403808, recon: 0.308369, id: 0.297674] time: 0:10:04.098712 \n","[Epoch 1/1] [Batch 147/560] [D loss: 0.374369, acc:  64%] [G loss: 9.154888, adv: 0.627355, recon: 0.358516, id: 0.490167] time: 0:10:08.116747 \n","[Epoch 1/1] [Batch 148/560] [D loss: 0.477207, acc:  49%] [G loss: 8.214035, adv: 0.548451, recon: 0.323388, id: 0.335010] time: 0:10:11.348310 \n","[Epoch 1/1] [Batch 149/560] [D loss: 0.344552, acc:  52%] [G loss: 5.571296, adv: 0.338261, recon: 0.220983, id: 0.217208] time: 0:10:14.991508 \n","[Epoch 1/1] [Batch 150/560] [D loss: 0.375571, acc:  46%] [G loss: 7.910692, adv: 0.403222, recon: 0.321906, id: 0.351459] time: 0:10:18.400431 \n","[Epoch 1/1] [Batch 151/560] [D loss: 0.246033, acc:  62%] [G loss: 7.920365, adv: 0.443449, recon: 0.322460, id: 0.274052] time: 0:10:21.745484 \n","[Epoch 1/1] [Batch 152/560] [D loss: 0.247511, acc:  61%] [G loss: 6.688104, adv: 0.446366, recon: 0.263191, id: 0.240309] time: 0:10:25.587289 \n","[Epoch 1/1] [Batch 153/560] [D loss: 0.274545, acc:  57%] [G loss: 6.121916, adv: 0.458188, recon: 0.235783, id: 0.224794] time: 0:10:30.592600 \n","[Epoch 1/1] [Batch 154/560] [D loss: 0.303326, acc:  56%] [G loss: 6.854937, adv: 0.408616, recon: 0.275736, id: 0.256490] time: 0:10:33.176413 \n","[Epoch 1/1] [Batch 155/560] [D loss: 0.294869, acc:  57%] [G loss: 7.574218, adv: 0.513932, recon: 0.300160, id: 0.232536] time: 0:10:36.367848 \n","[Epoch 1/1] [Batch 156/560] [D loss: 0.307128, acc:  56%] [G loss: 7.671748, adv: 0.441376, recon: 0.309124, id: 0.313813] time: 0:10:39.594798 \n","[Epoch 1/1] [Batch 157/560] [D loss: 0.205938, acc:  66%] [G loss: 8.703653, adv: 0.413716, recon: 0.364408, id: 0.346656] time: 0:10:43.334325 \n","[Epoch 1/1] [Batch 158/560] [D loss: 0.201305, acc:  70%] [G loss: 10.736265, adv: 0.436760, recon: 0.448349, id: 0.351352] time: 0:10:47.240541 \n","[Epoch 1/1] [Batch 159/560] [D loss: 0.311229, acc:  58%] [G loss: 10.780113, adv: 0.447993, recon: 0.453186, id: 0.476268] time: 0:10:50.201170 \n","[Epoch 1/1] [Batch 160/560] [D loss: 0.292937, acc:  54%] [G loss: 10.337034, adv: 0.454128, recon: 0.433642, id: 0.365091] time: 0:10:53.981366 \n","[Epoch 1/1] [Batch 161/560] [D loss: 0.289374, acc:  54%] [G loss: 7.008421, adv: 0.581588, recon: 0.266443, id: 0.247352] time: 0:10:57.931120 \n","[Epoch 1/1] [Batch 162/560] [D loss: 0.273721, acc:  68%] [G loss: 7.890702, adv: 0.449828, recon: 0.320594, id: 0.319385] time: 0:11:01.782755 \n","[Epoch 1/1] [Batch 163/560] [D loss: 0.279218, acc:  60%] [G loss: 8.720020, adv: 0.483822, recon: 0.351534, id: 0.310093] time: 0:11:05.603307 \n","[Epoch 1/1] [Batch 164/560] [D loss: 0.159096, acc:  77%] [G loss: 7.467970, adv: 0.592742, recon: 0.286220, id: 0.306065] time: 0:11:08.146212 \n","[Epoch 1/1] [Batch 165/560] [D loss: 0.281185, acc:  63%] [G loss: 7.217289, adv: 0.428477, recon: 0.291204, id: 0.280567] time: 0:11:11.453663 \n","[Epoch 1/1] [Batch 166/560] [D loss: 0.438751, acc:  49%] [G loss: 6.426895, adv: 0.577074, recon: 0.237962, id: 0.255373] time: 0:11:13.940179 \n","[Epoch 1/1] [Batch 167/560] [D loss: 0.361337, acc:  57%] [G loss: 8.598523, adv: 0.388655, recon: 0.356652, id: 0.334857] time: 0:11:17.591030 \n","[Epoch 1/1] [Batch 168/560] [D loss: 0.381200, acc:  58%] [G loss: 7.959123, adv: 0.544835, recon: 0.315717, id: 0.243973] time: 0:11:20.597589 \n","[Epoch 1/1] [Batch 169/560] [D loss: 0.447104, acc:  50%] [G loss: 7.632985, adv: 0.426702, recon: 0.311064, id: 0.295077] time: 0:11:23.528933 \n","[Epoch 1/1] [Batch 170/560] [D loss: 0.369408, acc:  54%] [G loss: 9.124800, adv: 0.880997, recon: 0.337202, id: 0.376984] time: 0:11:26.764505 \n","[Epoch 1/1] [Batch 171/560] [D loss: 0.487470, acc:  57%] [G loss: 7.241628, adv: 0.597683, recon: 0.274496, id: 0.270931] time: 0:11:29.065117 \n","[Epoch 1/1] [Batch 172/560] [D loss: 0.380014, acc:  55%] [G loss: 8.041839, adv: 0.516229, recon: 0.320970, id: 0.269891] time: 0:11:32.355556 \n","[Epoch 1/1] [Batch 173/560] [D loss: 0.375652, acc:  43%] [G loss: 7.392452, adv: 0.313473, recon: 0.311008, id: 0.199704] time: 0:11:35.838762 \n","[Epoch 1/1] [Batch 174/560] [D loss: 0.242567, acc:  60%] [G loss: 8.758921, adv: 0.335354, recon: 0.369980, id: 0.266721] time: 0:11:38.719009 \n","[Epoch 1/1] [Batch 175/560] [D loss: 0.306866, acc:  54%] [G loss: 7.405661, adv: 0.426799, recon: 0.297644, id: 0.278811] time: 0:11:42.375407 \n","[Epoch 1/1] [Batch 176/560] [D loss: 0.271077, acc:  57%] [G loss: 6.607035, adv: 0.319856, recon: 0.271462, id: 0.270395] time: 0:11:44.862883 \n","[Epoch 1/1] [Batch 177/560] [D loss: 0.271110, acc:  61%] [G loss: 10.981823, adv: 0.424795, recon: 0.464523, id: 0.361357] time: 0:11:47.722150 \n","[Epoch 1/1] [Batch 178/560] [D loss: 0.351147, acc:  47%] [G loss: 8.260925, adv: 0.386994, recon: 0.342235, id: 0.396468] time: 0:11:50.159423 \n","[Epoch 1/1] [Batch 179/560] [D loss: 0.413914, acc:  43%] [G loss: 7.025761, adv: 0.443681, recon: 0.282181, id: 0.242647] time: 0:11:53.484360 \n","[Epoch 1/1] [Batch 180/560] [D loss: 0.311789, acc:  53%] [G loss: 8.336544, adv: 0.417589, recon: 0.343249, id: 0.315464] time: 0:11:56.451080 \n","[Epoch 1/1] [Batch 181/560] [D loss: 0.393759, acc:  47%] [G loss: 8.685139, adv: 0.396104, recon: 0.360506, id: 0.447132] time: 0:11:58.925212 \n","[Epoch 1/1] [Batch 182/560] [D loss: 0.323715, acc:  58%] [G loss: 7.537587, adv: 0.623825, recon: 0.287942, id: 0.290481] time: 0:12:01.992901 \n","[Epoch 1/1] [Batch 183/560] [D loss: 0.387052, acc:  54%] [G loss: 9.494337, adv: 0.397853, recon: 0.396710, id: 0.412709] time: 0:12:05.392513 \n","[Epoch 1/1] [Batch 184/560] [D loss: 0.329269, acc:  67%] [G loss: 9.262724, adv: 0.843022, recon: 0.349361, id: 0.323277] time: 0:12:09.801526 \n","[Epoch 1/1] [Batch 185/560] [D loss: 0.364316, acc:  57%] [G loss: 8.760754, adv: 1.008519, recon: 0.308070, id: 0.282469] time: 0:12:12.894643 \n","[Epoch 1/1] [Batch 186/560] [D loss: 0.962069, acc:  62%] [G loss: 11.626255, adv: 1.516910, recon: 0.395104, id: 0.454140] time: 0:12:15.294834 \n","[Epoch 1/1] [Batch 187/560] [D loss: 0.718904, acc:  42%] [G loss: 10.692699, adv: 1.606738, recon: 0.342637, id: 0.327239] time: 0:12:18.299573 \n","[Epoch 1/1] [Batch 188/560] [D loss: 0.743635, acc:  60%] [G loss: 8.271700, adv: 0.415075, recon: 0.338930, id: 0.337166] time: 0:12:21.436050 \n","[Epoch 1/1] [Batch 189/560] [D loss: 0.401660, acc:  49%] [G loss: 11.137262, adv: 0.445132, recon: 0.470422, id: 0.469682] time: 0:12:24.131898 \n","[Epoch 1/1] [Batch 190/560] [D loss: 0.384460, acc:  49%] [G loss: 6.311290, adv: 0.464379, recon: 0.246462, id: 0.222978] time: 0:12:28.630015 \n","[Epoch 1/1] [Batch 191/560] [D loss: 0.342313, acc:  53%] [G loss: 8.340744, adv: 0.509913, recon: 0.333792, id: 0.321521] time: 0:12:31.374534 \n","[Epoch 1/1] [Batch 192/560] [D loss: 0.271934, acc:  54%] [G loss: 9.156967, adv: 0.457077, recon: 0.375873, id: 0.419386] time: 0:12:34.453680 \n","[Epoch 1/1] [Batch 193/560] [D loss: 0.219893, acc:  68%] [G loss: 8.453609, adv: 0.488944, recon: 0.341441, id: 0.378533] time: 0:12:36.878126 \n","[Epoch 1/1] [Batch 194/560] [D loss: 0.243254, acc:  65%] [G loss: 6.972023, adv: 0.495393, recon: 0.273156, id: 0.277396] time: 0:12:41.145208 \n","[Epoch 1/1] [Batch 195/560] [D loss: 0.262601, acc:  64%] [G loss: 8.670807, adv: 0.496123, recon: 0.349608, id: 0.455528] time: 0:12:45.180435 \n","[Epoch 1/1] [Batch 196/560] [D loss: 0.342333, acc:  49%] [G loss: 6.966537, adv: 0.423713, recon: 0.277792, id: 0.258832] time: 0:12:48.751885 \n","[Epoch 1/1] [Batch 197/560] [D loss: 0.278049, acc:  61%] [G loss: 6.780747, adv: 0.445849, recon: 0.268318, id: 0.304292] time: 0:12:51.507535 \n","[Epoch 1/1] [Batch 198/560] [D loss: 0.295021, acc:  58%] [G loss: 8.400855, adv: 0.777637, recon: 0.314781, id: 0.240533] time: 0:12:54.151216 \n","[Epoch 1/1] [Batch 199/560] [D loss: 0.460705, acc:  45%] [G loss: 5.931627, adv: 0.369315, recon: 0.236388, id: 0.212663] time: 0:12:56.213921 \n","[Epoch 1/1] [Batch 200/560] [D loss: 0.366212, acc:  56%] [G loss: 6.507268, adv: 0.517767, recon: 0.249230, id: 0.260016] time: 0:12:59.292733 \n","[Epoch 1/1] [Batch 201/560] [D loss: 0.272504, acc:  69%] [G loss: 11.924453, adv: 0.390215, recon: 0.507627, id: 0.505759] time: 0:13:01.780994 \n","[Epoch 1/1] [Batch 202/560] [D loss: 0.313381, acc:  52%] [G loss: 6.542843, adv: 0.386681, recon: 0.262788, id: 0.263457] time: 0:13:04.545064 \n","[Epoch 1/1] [Batch 203/560] [D loss: 0.299396, acc:  53%] [G loss: 7.164932, adv: 0.400971, recon: 0.287014, id: 0.361811] time: 0:13:06.595210 \n","[Epoch 1/1] [Batch 204/560] [D loss: 0.274709, acc:  58%] [G loss: 8.016825, adv: 0.436747, recon: 0.325671, id: 0.324921] time: 0:13:09.772733 \n","[Epoch 1/1] [Batch 205/560] [D loss: 0.332746, acc:  49%] [G loss: 9.160995, adv: 0.522734, recon: 0.369092, id: 0.505495] time: 0:13:13.207889 \n","[Epoch 1/1] [Batch 206/560] [D loss: 0.371649, acc:  50%] [G loss: 6.064920, adv: 0.395186, recon: 0.239501, id: 0.238741] time: 0:13:16.423004 \n","[Epoch 1/1] [Batch 207/560] [D loss: 0.308396, acc:  53%] [G loss: 8.773819, adv: 0.421063, recon: 0.359846, id: 0.490528] time: 0:13:19.555977 \n","[Epoch 1/1] [Batch 208/560] [D loss: 0.333472, acc:  55%] [G loss: 7.845898, adv: 0.543341, recon: 0.308405, id: 0.365895] time: 0:13:22.668876 \n","[Epoch 1/1] [Batch 209/560] [D loss: 0.383099, acc:  54%] [G loss: 7.574563, adv: 0.384071, recon: 0.310145, id: 0.289835] time: 0:13:25.247483 \n","[Epoch 1/1] [Batch 210/560] [D loss: 0.227380, acc:  66%] [G loss: 8.539819, adv: 0.478715, recon: 0.345301, id: 0.376300] time: 0:13:27.682752 \n","[Epoch 1/1] [Batch 211/560] [D loss: 0.224940, acc:  66%] [G loss: 9.628965, adv: 0.468343, recon: 0.397903, id: 0.467719] time: 0:13:29.518890 \n","[Epoch 1/1] [Batch 212/560] [D loss: 0.308201, acc:  50%] [G loss: 6.875545, adv: 0.628955, recon: 0.256017, id: 0.214592] time: 0:13:32.612892 \n","[Epoch 1/1] [Batch 213/560] [D loss: 0.322025, acc:  57%] [G loss: 6.291574, adv: 0.556070, recon: 0.236079, id: 0.230536] time: 0:13:35.859079 \n","[Epoch 1/1] [Batch 214/560] [D loss: 0.350466, acc:  60%] [G loss: 6.877754, adv: 0.537186, recon: 0.263885, id: 0.224422] time: 0:13:39.648271 \n","[Epoch 1/1] [Batch 215/560] [D loss: 0.305006, acc:  60%] [G loss: 10.042955, adv: 0.405365, recon: 0.422201, id: 0.254239] time: 0:13:43.187811 \n","[Epoch 1/1] [Batch 216/560] [D loss: 0.321149, acc:  56%] [G loss: 6.929175, adv: 0.393685, recon: 0.280191, id: 0.284079] time: 0:13:45.735592 \n","[Epoch 1/1] [Batch 217/560] [D loss: 0.262918, acc:  62%] [G loss: 7.099980, adv: 0.439106, recon: 0.283599, id: 0.263862] time: 0:13:48.650797 \n","[Epoch 1/1] [Batch 218/560] [D loss: 0.331335, acc:  50%] [G loss: 7.913831, adv: 0.352645, recon: 0.326454, id: 0.306400] time: 0:13:51.789870 \n","[Epoch 1/1] [Batch 219/560] [D loss: 0.349042, acc:  41%] [G loss: 6.618160, adv: 0.345982, recon: 0.266926, id: 0.334920] time: 0:13:54.662703 \n","[Epoch 1/1] [Batch 220/560] [D loss: 0.225373, acc:  65%] [G loss: 10.256811, adv: 0.429059, recon: 0.432840, id: 0.336663] time: 0:13:57.840621 \n","[Epoch 1/1] [Batch 221/560] [D loss: 0.196189, acc:  71%] [G loss: 7.800756, adv: 0.405524, recon: 0.321062, id: 0.294010] time: 0:14:00.769836 \n","[Epoch 1/1] [Batch 222/560] [D loss: 0.304355, acc:  53%] [G loss: 7.362472, adv: 0.402742, recon: 0.298621, id: 0.382967] time: 0:14:04.392603 \n","[Epoch 1/1] [Batch 223/560] [D loss: 0.383016, acc:  48%] [G loss: 7.705703, adv: 0.362769, recon: 0.319908, id: 0.370015] time: 0:14:06.894755 \n","[Epoch 1/1] [Batch 224/560] [D loss: 0.222677, acc:  64%] [G loss: 6.467792, adv: 0.436838, recon: 0.255265, id: 0.173859] time: 0:14:09.423954 \n","[Epoch 1/1] [Batch 225/560] [D loss: 0.206253, acc:  65%] [G loss: 8.763856, adv: 0.393404, recon: 0.363467, id: 0.467093] time: 0:14:11.982058 \n","[Epoch 1/1] [Batch 226/560] [D loss: 0.320071, acc:  54%] [G loss: 7.488954, adv: 0.384761, recon: 0.309018, id: 0.314384] time: 0:14:14.890385 \n","[Epoch 1/1] [Batch 227/560] [D loss: 0.278827, acc:  60%] [G loss: 7.151590, adv: 0.433560, recon: 0.285015, id: 0.341862] time: 0:14:17.799983 \n","[Epoch 1/1] [Batch 228/560] [D loss: 0.232112, acc:  65%] [G loss: 5.426392, adv: 0.469392, recon: 0.202434, id: 0.211847] time: 0:14:20.855420 \n","[Epoch 1/1] [Batch 229/560] [D loss: 0.245893, acc:  62%] [G loss: 6.083476, adv: 0.385705, recon: 0.241149, id: 0.179478] time: 0:14:23.558184 \n","[Epoch 1/1] [Batch 230/560] [D loss: 0.257097, acc:  58%] [G loss: 8.750429, adv: 0.322665, recon: 0.369625, id: 0.201100] time: 0:14:27.236033 \n","[Epoch 1/1] [Batch 231/560] [D loss: 0.213178, acc:  70%] [G loss: 6.925337, adv: 0.594856, recon: 0.261729, id: 0.249761] time: 0:14:29.677929 \n","[Epoch 1/1] [Batch 232/560] [D loss: 0.248692, acc:  60%] [G loss: 8.614511, adv: 0.394440, recon: 0.361375, id: 0.195562] time: 0:14:32.643321 \n","[Epoch 1/1] [Batch 233/560] [D loss: 0.453826, acc:  52%] [G loss: 7.168758, adv: 0.420190, recon: 0.291017, id: 0.176207] time: 0:14:34.664856 \n","[Epoch 1/1] [Batch 234/560] [D loss: 0.407410, acc:  56%] [G loss: 6.089022, adv: 0.584354, recon: 0.222804, id: 0.206715] time: 0:14:37.673922 \n","[Epoch 1/1] [Batch 235/560] [D loss: 0.382578, acc:  51%] [G loss: 5.375567, adv: 0.394102, recon: 0.208375, id: 0.165261] time: 0:14:40.172010 \n","[Epoch 1/1] [Batch 236/560] [D loss: 0.341879, acc:  56%] [G loss: 8.168421, adv: 0.582330, recon: 0.318604, id: 0.235312] time: 0:14:42.665662 \n","[Epoch 1/1] [Batch 237/560] [D loss: 0.424178, acc:  57%] [G loss: 5.790050, adv: 0.486142, recon: 0.220648, id: 0.205566] time: 0:14:45.222432 \n","[Epoch 1/1] [Batch 238/560] [D loss: 0.389338, acc:  49%] [G loss: 9.779980, adv: 0.487425, recon: 0.399811, id: 0.545187] time: 0:14:49.341714 \n","[Epoch 1/1] [Batch 239/560] [D loss: 0.282860, acc:  60%] [G loss: 6.095424, adv: 0.411467, recon: 0.238566, id: 0.249981] time: 0:14:51.364616 \n","[Epoch 1/1] [Batch 240/560] [D loss: 0.286872, acc:  56%] [G loss: 6.213941, adv: 0.534171, recon: 0.233555, id: 0.202926] time: 0:14:53.675670 \n","[Epoch 1/1] [Batch 241/560] [D loss: 0.277937, acc:  67%] [G loss: 5.840995, adv: 0.466487, recon: 0.224182, id: 0.174486] time: 0:14:56.802414 \n","[Epoch 1/1] [Batch 242/560] [D loss: 0.367876, acc:  48%] [G loss: 5.649837, adv: 0.397060, recon: 0.220712, id: 0.222376] time: 0:14:59.720405 \n","[Epoch 1/1] [Batch 243/560] [D loss: 0.248661, acc:  66%] [G loss: 7.768831, adv: 0.596943, recon: 0.301729, id: 0.276793] time: 0:15:03.009872 \n","[Epoch 1/1] [Batch 244/560] [D loss: 0.341188, acc:  57%] [G loss: 6.090787, adv: 0.394666, recon: 0.240514, id: 0.229479] time: 0:15:05.715569 \n","[Epoch 1/1] [Batch 245/560] [D loss: 0.452519, acc:  54%] [G loss: 5.989545, adv: 0.564236, recon: 0.221780, id: 0.208721] time: 0:15:08.859653 \n","[Epoch 1/1] [Batch 246/560] [D loss: 0.449750, acc:  49%] [G loss: 8.580334, adv: 0.339388, recon: 0.357886, id: 0.462077] time: 0:15:11.688246 \n","[Epoch 1/1] [Batch 247/560] [D loss: 0.245680, acc:  64%] [G loss: 5.813972, adv: 0.395655, recon: 0.227189, id: 0.198562] time: 0:15:13.856113 \n","[Epoch 1/1] [Batch 248/560] [D loss: 0.197876, acc:  70%] [G loss: 6.619087, adv: 0.497891, recon: 0.256009, id: 0.221752] time: 0:15:16.184325 \n","[Epoch 1/1] [Batch 249/560] [D loss: 0.253462, acc:  62%] [G loss: 6.174543, adv: 0.424235, recon: 0.242586, id: 0.246609] time: 0:15:19.498058 \n","[Epoch 1/1] [Batch 250/560] [D loss: 0.303213, acc:  50%] [G loss: 9.656831, adv: 0.363856, recon: 0.407195, id: 0.179480] time: 0:15:22.545490 \n","[Epoch 1/1] [Batch 251/560] [D loss: 0.264067, acc:  61%] [G loss: 6.029229, adv: 0.468319, recon: 0.232086, id: 0.246848] time: 0:15:24.378806 \n","[Epoch 1/1] [Batch 252/560] [D loss: 0.269466, acc:  58%] [G loss: 5.946086, adv: 0.410664, recon: 0.232378, id: 0.207619] time: 0:15:28.214897 \n","[Epoch 1/1] [Batch 253/560] [D loss: 0.251917, acc:  59%] [G loss: 6.197384, adv: 0.422683, recon: 0.244236, id: 0.172984] time: 0:15:30.513112 \n","[Epoch 1/1] [Batch 254/560] [D loss: 0.168097, acc:  75%] [G loss: 7.178788, adv: 0.439479, recon: 0.289385, id: 0.212520] time: 0:15:32.392710 \n","[Epoch 1/1] [Batch 255/560] [D loss: 0.314371, acc:  46%] [G loss: 10.169680, adv: 0.309761, recon: 0.435992, id: 0.490391] time: 0:15:35.326623 \n","[Epoch 1/1] [Batch 256/560] [D loss: 0.209016, acc:  65%] [G loss: 5.953111, adv: 0.349780, recon: 0.240234, id: 0.245651] time: 0:15:37.289881 \n","[Epoch 1/1] [Batch 257/560] [D loss: 0.299927, acc:  56%] [G loss: 7.260215, adv: 0.430837, recon: 0.291792, id: 0.310067] time: 0:15:39.646073 \n","[Epoch 1/1] [Batch 258/560] [D loss: 0.380688, acc:  48%] [G loss: 7.434258, adv: 0.444171, recon: 0.298183, id: 0.323765] time: 0:15:42.416152 \n","[Epoch 1/1] [Batch 259/560] [D loss: 0.281956, acc:  55%] [G loss: 6.834232, adv: 0.372845, recon: 0.278758, id: 0.232551] time: 0:15:46.081475 \n","[Epoch 1/1] [Batch 260/560] [D loss: 0.262448, acc:  61%] [G loss: 6.418454, adv: 0.363774, recon: 0.259496, id: 0.230855] time: 0:15:49.229151 \n","[Epoch 1/1] [Batch 261/560] [D loss: 0.228648, acc:  62%] [G loss: 7.205067, adv: 0.418911, recon: 0.290586, id: 0.219392] time: 0:15:52.769855 \n","[Epoch 1/1] [Batch 262/560] [D loss: 0.337282, acc:  50%] [G loss: 6.474281, adv: 0.358035, recon: 0.262016, id: 0.290830] time: 0:15:54.603047 \n","[Epoch 1/1] [Batch 263/560] [D loss: 0.249034, acc:  59%] [G loss: 5.967290, adv: 0.412430, recon: 0.234861, id: 0.296895] time: 0:15:57.142633 \n","[Epoch 1/1] [Batch 264/560] [D loss: 0.187169, acc:  71%] [G loss: 6.447855, adv: 0.545092, recon: 0.242554, id: 0.242973] time: 0:15:59.628265 \n","[Epoch 1/1] [Batch 265/560] [D loss: 0.390373, acc:  53%] [G loss: 7.400485, adv: 0.686219, recon: 0.274696, id: 0.244479] time: 0:16:02.325316 \n","[Epoch 1/1] [Batch 266/560] [D loss: 0.503435, acc:  50%] [G loss: 8.723216, adv: 0.536811, recon: 0.347429, id: 0.418416] time: 0:16:04.492587 \n","[Epoch 1/1] [Batch 267/560] [D loss: 0.377183, acc:  51%] [G loss: 5.729805, adv: 0.399194, recon: 0.224621, id: 0.224795] time: 0:16:06.964113 \n","[Epoch 1/1] [Batch 268/560] [D loss: 0.343118, acc:  50%] [G loss: 5.465679, adv: 0.317153, recon: 0.220577, id: 0.218398] time: 0:16:08.995699 \n","[Epoch 1/1] [Batch 269/560] [D loss: 0.256279, acc:  61%] [G loss: 8.061146, adv: 0.422563, recon: 0.328202, id: 0.261629] time: 0:16:11.385688 \n","[Epoch 1/1] [Batch 270/560] [D loss: 0.391611, acc:  50%] [G loss: 6.519350, adv: 0.505949, recon: 0.250420, id: 0.229823] time: 0:16:14.320511 \n","[Epoch 1/1] [Batch 271/560] [D loss: 0.394404, acc:  60%] [G loss: 6.912704, adv: 0.410498, recon: 0.277062, id: 0.321168] time: 0:16:16.412807 \n","[Epoch 1/1] [Batch 272/560] [D loss: 0.248091, acc:  65%] [G loss: 7.015999, adv: 0.509596, recon: 0.272324, id: 0.298295] time: 0:16:18.982933 \n","[Epoch 1/1] [Batch 273/560] [D loss: 0.212699, acc:  70%] [G loss: 5.713442, adv: 0.502017, recon: 0.214520, id: 0.241375] time: 0:16:20.986419 \n","[Epoch 1/1] [Batch 274/560] [D loss: 0.193852, acc:  73%] [G loss: 4.559908, adv: 0.454308, recon: 0.166437, id: 0.158091] time: 0:16:23.522742 \n","[Epoch 1/1] [Batch 275/560] [D loss: 0.246283, acc:  60%] [G loss: 5.308995, adv: 0.415851, recon: 0.203763, id: 0.223089] time: 0:16:25.560903 \n","[Epoch 1/1] [Batch 276/560] [D loss: 0.296786, acc:  56%] [G loss: 6.781651, adv: 0.430742, recon: 0.270308, id: 0.270118] time: 0:16:27.972891 \n","[Epoch 1/1] [Batch 277/560] [D loss: 0.339611, acc:  56%] [G loss: 6.776902, adv: 0.364748, recon: 0.276353, id: 0.243439] time: 0:16:29.843587 \n","[Epoch 1/1] [Batch 278/560] [D loss: 0.365859, acc:  51%] [G loss: 5.973854, adv: 0.476267, recon: 0.228065, id: 0.247479] time: 0:16:32.818853 \n","[Epoch 1/1] [Batch 279/560] [D loss: 0.349568, acc:  51%] [G loss: 6.508956, adv: 0.474570, recon: 0.251599, id: 0.274618] time: 0:16:35.983801 \n","[Epoch 1/1] [Batch 280/560] [D loss: 0.401562, acc:  55%] [G loss: 6.670259, adv: 0.471300, recon: 0.260958, id: 0.304487] time: 0:16:38.005300 \n","[Epoch 1/1] [Batch 281/560] [D loss: 0.376742, acc:  51%] [G loss: 5.662122, adv: 0.419260, recon: 0.218933, id: 0.207242] time: 0:16:40.706709 \n","[Epoch 1/1] [Batch 282/560] [D loss: 0.250405, acc:  59%] [G loss: 6.371500, adv: 0.495537, recon: 0.245186, id: 0.203185] time: 0:16:42.697655 \n","[Epoch 1/1] [Batch 283/560] [D loss: 0.211483, acc:  69%] [G loss: 5.116066, adv: 0.502270, recon: 0.187781, id: 0.166277] time: 0:16:45.180881 \n","[Epoch 1/1] [Batch 284/560] [D loss: 0.315017, acc:  58%] [G loss: 7.126412, adv: 0.340665, recon: 0.294531, id: 0.337538] time: 0:16:47.830340 \n","[Epoch 1/1] [Batch 285/560] [D loss: 0.280472, acc:  60%] [G loss: 6.891037, adv: 0.395908, recon: 0.279197, id: 0.183522] time: 0:16:50.919708 \n","[Epoch 1/1] [Batch 286/560] [D loss: 0.256182, acc:  61%] [G loss: 6.492606, adv: 0.503775, recon: 0.248420, id: 0.244824] time: 0:16:53.656903 \n","[Epoch 1/1] [Batch 287/560] [D loss: 0.320668, acc:  54%] [G loss: 6.103426, adv: 0.361741, recon: 0.245870, id: 0.228466] time: 0:16:55.658827 \n","[Epoch 1/1] [Batch 288/560] [D loss: 0.319791, acc:  41%] [G loss: 9.217731, adv: 0.361223, recon: 0.386963, id: 0.498734] time: 0:16:57.614535 \n","[Epoch 1/1] [Batch 289/560] [D loss: 0.417130, acc:  36%] [G loss: 6.145738, adv: 0.279561, recon: 0.254412, id: 0.288438] time: 0:16:59.524208 \n","[Epoch 1/1] [Batch 290/560] [D loss: 0.254081, acc:  57%] [G loss: 6.092570, adv: 0.404921, recon: 0.239236, id: 0.254072] time: 0:17:02.025794 \n","[Epoch 1/1] [Batch 291/560] [D loss: 0.279454, acc:  58%] [G loss: 5.564169, adv: 0.335385, recon: 0.224928, id: 0.209771] time: 0:17:05.029378 \n","[Epoch 1/1] [Batch 292/560] [D loss: 0.220154, acc:  67%] [G loss: 5.408557, adv: 0.448936, recon: 0.205011, id: 0.186864] time: 0:17:06.942473 \n","[Epoch 1/1] [Batch 293/560] [D loss: 0.280149, acc:  56%] [G loss: 6.990843, adv: 0.369428, recon: 0.284822, id: 0.354440] time: 0:17:10.453350 \n","[Epoch 1/1] [Batch 294/560] [D loss: 0.209220, acc:  70%] [G loss: 7.187238, adv: 0.493411, recon: 0.282187, id: 0.284802] time: 0:17:13.596999 \n","[Epoch 1/1] [Batch 295/560] [D loss: 0.194302, acc:  72%] [G loss: 6.930924, adv: 0.510428, recon: 0.272700, id: 0.235410] time: 0:17:16.566197 \n","[Epoch 1/1] [Batch 296/560] [D loss: 0.225898, acc:  71%] [G loss: 6.686301, adv: 0.496938, recon: 0.257697, id: 0.276015] time: 0:17:19.005836 \n","[Epoch 1/1] [Batch 297/560] [D loss: 0.267144, acc:  71%] [G loss: 6.830393, adv: 0.731096, recon: 0.243303, id: 0.238748] time: 0:17:20.900483 \n","[Epoch 1/1] [Batch 298/560] [D loss: 0.544590, acc:  36%] [G loss: 5.854261, adv: 0.251120, recon: 0.244868, id: 0.209317] time: 0:17:23.296115 \n","[Epoch 1/1] [Batch 299/560] [D loss: 0.285156, acc:  62%] [G loss: 9.780189, adv: 0.551225, recon: 0.396231, id: 0.494754] time: 0:17:25.203544 \n","[Epoch 1/1] [Batch 300/560] [D loss: 0.288549, acc:  59%] [G loss: 7.854946, adv: 0.559769, recon: 0.308675, id: 0.301132] time: 0:17:28.268332 \n","[Epoch 1/1] [Batch 301/560] [D loss: 0.270478, acc:  58%] [G loss: 6.022907, adv: 0.470340, recon: 0.232026, id: 0.221165] time: 0:17:30.948937 \n","[Epoch 1/1] [Batch 302/560] [D loss: 0.262137, acc:  62%] [G loss: 11.156733, adv: 0.420055, recon: 0.471482, id: 0.602774] time: 0:17:34.836756 \n","[Epoch 1/1] [Batch 303/560] [D loss: 0.315064, acc:  51%] [G loss: 6.115800, adv: 0.444556, recon: 0.236988, id: 0.221823] time: 0:17:38.033109 \n","[Epoch 1/1] [Batch 304/560] [D loss: 0.333085, acc:  51%] [G loss: 11.608101, adv: 0.447090, recon: 0.488633, id: 0.487958] time: 0:17:41.355045 \n","[Epoch 1/1] [Batch 305/560] [D loss: 0.312197, acc:  55%] [G loss: 7.800250, adv: 0.405846, recon: 0.318491, id: 0.375237] time: 0:17:43.330334 \n","[Epoch 1/1] [Batch 306/560] [D loss: 0.231856, acc:  62%] [G loss: 9.761272, adv: 0.371934, recon: 0.418359, id: 0.339607] time: 0:17:45.200145 \n","[Epoch 1/1] [Batch 307/560] [D loss: 0.322319, acc:  56%] [G loss: 6.824255, adv: 0.381727, recon: 0.277033, id: 0.317621] time: 0:17:47.217670 \n","[Epoch 1/1] [Batch 308/560] [D loss: 0.389244, acc:  55%] [G loss: 6.791718, adv: 0.535241, recon: 0.261400, id: 0.271603] time: 0:17:49.188794 \n","[Epoch 1/1] [Batch 309/560] [D loss: 0.332097, acc:  55%] [G loss: 10.965420, adv: 0.386777, recon: 0.464187, id: 0.593305] time: 0:17:51.893325 \n","[Epoch 1/1] [Batch 310/560] [D loss: 0.407111, acc:  35%] [G loss: 6.670812, adv: 0.269038, recon: 0.281921, id: 0.286844] time: 0:17:54.426314 \n","[Epoch 1/1] [Batch 311/560] [D loss: 0.312071, acc:  45%] [G loss: 6.048044, adv: 0.328251, recon: 0.246296, id: 0.259320] time: 0:17:56.933251 \n","[Epoch 1/1] [Batch 312/560] [D loss: 0.241119, acc:  60%] [G loss: 6.385634, adv: 0.450137, recon: 0.248140, id: 0.293213] time: 0:18:00.133129 \n","[Epoch 1/1] [Batch 313/560] [D loss: 0.245835, acc:  57%] [G loss: 6.586910, adv: 0.492802, recon: 0.255287, id: 0.256856] time: 0:18:02.044669 \n","[Epoch 1/1] [Batch 314/560] [D loss: 0.325256, acc:  57%] [G loss: 4.999402, adv: 0.396072, recon: 0.191636, id: 0.193164] time: 0:18:06.015162 \n","[Epoch 1/1] [Batch 315/560] [D loss: 0.248607, acc:  63%] [G loss: 11.099724, adv: 0.515374, recon: 0.457453, id: 0.327750] time: 0:18:08.934420 \n","[Epoch 1/1] [Batch 316/560] [D loss: 0.416772, acc:  45%] [G loss: 7.261855, adv: 0.322694, recon: 0.303145, id: 0.322006] time: 0:18:12.231486 \n","[Epoch 1/1] [Batch 317/560] [D loss: 0.300807, acc:  62%] [G loss: 6.392200, adv: 0.620706, recon: 0.237389, id: 0.224956] time: 0:18:15.628215 \n","[Epoch 1/1] [Batch 318/560] [D loss: 0.332014, acc:  55%] [G loss: 8.567183, adv: 0.337076, recon: 0.361275, id: 0.344227] time: 0:18:17.531648 \n","[Epoch 1/1] [Batch 319/560] [D loss: 0.432566, acc:  42%] [G loss: 7.159309, adv: 0.303808, recon: 0.299054, id: 0.322981] time: 0:18:20.017645 \n","[Epoch 1/1] [Batch 320/560] [D loss: 0.331978, acc:  48%] [G loss: 7.615868, adv: 0.366226, recon: 0.313192, id: 0.342419] time: 0:18:22.659268 \n","[Epoch 1/1] [Batch 321/560] [D loss: 0.285084, acc:  57%] [G loss: 8.318669, adv: 0.492754, recon: 0.334462, id: 0.384691] time: 0:18:24.980579 \n","[Epoch 1/1] [Batch 322/560] [D loss: 0.390888, acc:  43%] [G loss: 5.779163, adv: 0.437006, recon: 0.223705, id: 0.175223] time: 0:18:27.959925 \n","[Epoch 1/1] [Batch 323/560] [D loss: 0.242929, acc:  61%] [G loss: 7.356703, adv: 0.528027, recon: 0.290345, id: 0.237055] time: 0:18:30.436314 \n","[Epoch 1/1] [Batch 324/560] [D loss: 0.424044, acc:  55%] [G loss: 8.443405, adv: 0.900088, recon: 0.307348, id: 0.262607] time: 0:18:32.704211 \n","[Epoch 1/1] [Batch 325/560] [D loss: 0.573917, acc:  61%] [G loss: 7.342115, adv: 0.745511, recon: 0.270516, id: 0.180862] time: 0:18:35.197061 \n","[Epoch 1/1] [Batch 326/560] [D loss: 0.412202, acc:  58%] [G loss: 7.000288, adv: 0.481569, recon: 0.275484, id: 0.288839] time: 0:18:37.528264 \n","[Epoch 1/1] [Batch 327/560] [D loss: 0.513116, acc:  48%] [G loss: 8.384546, adv: 0.370304, recon: 0.348668, id: 0.356780] time: 0:18:39.505928 \n","[Epoch 1/1] [Batch 328/560] [D loss: 0.286796, acc:  55%] [G loss: 6.113414, adv: 0.349008, recon: 0.247206, id: 0.244704] time: 0:18:41.960189 \n","[Epoch 1/1] [Batch 329/560] [D loss: 0.292022, acc:  60%] [G loss: 5.640861, adv: 0.620674, recon: 0.202101, id: 0.148375] time: 0:18:46.684404 \n","[Epoch 1/1] [Batch 330/560] [D loss: 0.353637, acc:  55%] [G loss: 6.169023, adv: 0.454778, recon: 0.239187, id: 0.283062] time: 0:18:49.167274 \n","[Epoch 1/1] [Batch 331/560] [D loss: 0.511862, acc:  39%] [G loss: 6.813174, adv: 0.365847, recon: 0.276476, id: 0.335263] time: 0:18:51.802847 \n","[Epoch 1/1] [Batch 332/560] [D loss: 0.386336, acc:  47%] [G loss: 6.108161, adv: 0.428723, recon: 0.238766, id: 0.240739] time: 0:18:54.206763 \n","[Epoch 1/1] [Batch 333/560] [D loss: 0.340983, acc:  59%] [G loss: 7.787099, adv: 0.776307, recon: 0.286719, id: 0.261711] time: 0:18:56.926928 \n","[Epoch 1/1] [Batch 334/560] [D loss: 0.483291, acc:  51%] [G loss: 6.268774, adv: 0.373228, recon: 0.250453, id: 0.310849] time: 0:18:59.051734 \n","[Epoch 1/1] [Batch 335/560] [D loss: 0.291362, acc:  55%] [G loss: 6.605265, adv: 0.455081, recon: 0.258876, id: 0.326130] time: 0:19:02.572705 \n","[Epoch 1/1] [Batch 336/560] [D loss: 0.336843, acc:  48%] [G loss: 5.026782, adv: 0.371351, recon: 0.194838, id: 0.124363] time: 0:19:05.174295 \n","[Epoch 1/1] [Batch 337/560] [D loss: 0.323889, acc:  54%] [G loss: 7.254786, adv: 0.426080, recon: 0.292499, id: 0.289301] time: 0:19:07.082290 \n","[Epoch 1/1] [Batch 338/560] [D loss: 0.223787, acc:  68%] [G loss: 4.975615, adv: 0.468430, recon: 0.183086, id: 0.139415] time: 0:19:09.403571 \n","[Epoch 1/1] [Batch 339/560] [D loss: 0.290092, acc:  61%] [G loss: 8.556393, adv: 0.397129, recon: 0.353748, id: 0.305279] time: 0:19:11.503390 \n","[Epoch 1/1] [Batch 340/560] [D loss: 0.208423, acc:  70%] [G loss: 7.108454, adv: 0.396237, recon: 0.288514, id: 0.332298] time: 0:19:13.641419 \n","[Epoch 1/1] [Batch 341/560] [D loss: 0.281394, acc:  59%] [G loss: 7.133888, adv: 0.466896, recon: 0.283520, id: 0.246717] time: 0:19:16.873077 \n","[Epoch 1/1] [Batch 342/560] [D loss: 0.243504, acc:  58%] [G loss: 9.083506, adv: 0.377250, recon: 0.377814, id: 0.411394] time: 0:19:19.494252 \n","[Epoch 1/1] [Batch 343/560] [D loss: 0.324014, acc:  40%] [G loss: 5.853354, adv: 0.320576, recon: 0.238037, id: 0.201142] time: 0:19:22.168177 \n","[Epoch 1/1] [Batch 344/560] [D loss: 0.271272, acc:  49%] [G loss: 5.786406, adv: 0.339263, recon: 0.233646, id: 0.166401] time: 0:19:25.144294 \n","[Epoch 1/1] [Batch 345/560] [D loss: 0.224825, acc:  63%] [G loss: 8.438920, adv: 0.327298, recon: 0.356108, id: 0.448748] time: 0:19:27.578655 \n","[Epoch 1/1] [Batch 346/560] [D loss: 0.313752, acc:  47%] [G loss: 5.482676, adv: 0.465997, recon: 0.207977, id: 0.169070] time: 0:19:29.535580 \n","[Epoch 1/1] [Batch 347/560] [D loss: 0.341787, acc:  62%] [G loss: 6.326872, adv: 0.575268, recon: 0.235481, id: 0.210755] time: 0:19:32.262541 \n","[Epoch 1/1] [Batch 348/560] [D loss: 0.424739, acc:  50%] [G loss: 6.776453, adv: 0.536971, recon: 0.260288, id: 0.235804] time: 0:19:34.755391 \n","[Epoch 1/1] [Batch 349/560] [D loss: 0.287627, acc:  58%] [G loss: 6.007679, adv: 0.396757, recon: 0.235510, id: 0.291450] time: 0:19:37.919469 \n","[Epoch 1/1] [Batch 350/560] [D loss: 0.264384, acc:  57%] [G loss: 5.986065, adv: 0.377869, recon: 0.237782, id: 0.241136] time: 0:19:41.438868 \n","[Epoch 1/1] [Batch 351/560] [D loss: 0.281334, acc:  58%] [G loss: 6.441973, adv: 0.425868, recon: 0.254619, id: 0.176632] time: 0:19:44.388855 \n","[Epoch 1/1] [Batch 352/560] [D loss: 0.261669, acc:  58%] [G loss: 5.380982, adv: 0.366331, recon: 0.209675, id: 0.239589] time: 0:19:46.733204 \n","[Epoch 1/1] [Batch 353/560] [D loss: 0.328764, acc:  51%] [G loss: 5.352449, adv: 0.293448, recon: 0.215465, id: 0.205439] time: 0:19:48.575979 \n","[Epoch 1/1] [Batch 354/560] [D loss: 0.265079, acc:  60%] [G loss: 7.863330, adv: 0.425091, recon: 0.320613, id: 0.317472] time: 0:19:50.486137 \n","[Epoch 1/1] [Batch 355/560] [D loss: 0.229462, acc:  62%] [G loss: 5.836315, adv: 0.402943, recon: 0.230431, id: 0.210435] time: 0:19:53.204876 \n","[Epoch 1/1] [Batch 356/560] [D loss: 0.181437, acc:  75%] [G loss: 11.143717, adv: 0.438696, recon: 0.468575, id: 0.642381] time: 0:19:55.209832 \n","[Epoch 1/1] [Batch 357/560] [D loss: 0.258704, acc:  57%] [G loss: 6.590704, adv: 0.358927, recon: 0.268460, id: 0.213129] time: 0:19:58.268099 \n","[Epoch 1/1] [Batch 358/560] [D loss: 0.238611, acc:  60%] [G loss: 5.513418, adv: 0.464851, recon: 0.210662, id: 0.158593] time: 0:20:00.180355 \n","[Epoch 1/1] [Batch 359/560] [D loss: 0.278826, acc:  57%] [G loss: 9.349468, adv: 0.418726, recon: 0.390188, id: 0.272313] time: 0:20:02.293934 \n","[Epoch 1/1] [Batch 360/560] [D loss: 0.322172, acc:  54%] [G loss: 6.658598, adv: 0.374731, recon: 0.270075, id: 0.243170] time: 0:20:04.274356 \n","[Epoch 1/1] [Batch 361/560] [D loss: 0.334222, acc:  49%] [G loss: 5.801742, adv: 0.355292, recon: 0.233346, id: 0.201893] time: 0:20:06.222919 \n","[Epoch 1/1] [Batch 362/560] [D loss: 0.248608, acc:  66%] [G loss: 5.873096, adv: 0.413215, recon: 0.231298, id: 0.190601] time: 0:20:08.684827 \n","[Epoch 1/1] [Batch 363/560] [D loss: 0.322211, acc:  46%] [G loss: 8.254127, adv: 0.386243, recon: 0.341666, id: 0.424822] time: 0:20:10.676696 \n","[Epoch 1/1] [Batch 364/560] [D loss: 0.209322, acc:  67%] [G loss: 7.534945, adv: 0.377705, recon: 0.307302, id: 0.369630] time: 0:20:13.363493 \n","[Epoch 1/1] [Batch 365/560] [D loss: 0.247115, acc:  59%] [G loss: 5.825927, adv: 0.371309, recon: 0.230400, id: 0.198824] time: 0:20:16.444821 \n","[Epoch 1/1] [Batch 366/560] [D loss: 0.223341, acc:  65%] [G loss: 6.791255, adv: 0.388646, recon: 0.272618, id: 0.340328] time: 0:20:18.495532 \n","[Epoch 1/1] [Batch 367/560] [D loss: 0.210998, acc:  67%] [G loss: 6.582831, adv: 0.450817, recon: 0.260222, id: 0.205532] time: 0:20:21.067436 \n","[Epoch 1/1] [Batch 368/560] [D loss: 0.311878, acc:  53%] [G loss: 6.899464, adv: 0.352266, recon: 0.281215, id: 0.279517] time: 0:20:23.071997 \n","[Epoch 1/1] [Batch 369/560] [D loss: 0.254436, acc:  60%] [G loss: 5.670415, adv: 0.552199, recon: 0.208026, id: 0.200589] time: 0:20:25.848269 \n","[Epoch 1/1] [Batch 370/560] [D loss: 0.252036, acc:  64%] [G loss: 7.096798, adv: 0.399278, recon: 0.288382, id: 0.165269] time: 0:20:28.247165 \n","[Epoch 1/1] [Batch 371/560] [D loss: 0.236859, acc:  60%] [G loss: 8.238874, adv: 0.451699, recon: 0.334638, id: 0.294396] time: 0:20:31.601041 \n","[Epoch 1/1] [Batch 372/560] [D loss: 0.181206, acc:  73%] [G loss: 8.195568, adv: 0.417120, recon: 0.335867, id: 0.443888] time: 0:20:34.028997 \n","[Epoch 1/1] [Batch 373/560] [D loss: 0.314416, acc:  62%] [G loss: 10.049513, adv: 0.686472, recon: 0.395692, id: 0.440476] time: 0:20:36.608399 \n","[Epoch 1/1] [Batch 374/560] [D loss: 0.411318, acc:  54%] [G loss: 5.718648, adv: 0.391691, recon: 0.223538, id: 0.237352] time: 0:20:39.444521 \n","[Epoch 1/1] [Batch 375/560] [D loss: 0.197627, acc:  72%] [G loss: 5.616905, adv: 0.420515, recon: 0.218586, id: 0.203940] time: 0:20:42.265567 \n","[Epoch 1/1] [Batch 376/560] [D loss: 0.268285, acc:  59%] [G loss: 6.288196, adv: 0.325266, recon: 0.256163, id: 0.224301] time: 0:20:44.329919 \n","[Epoch 1/1] [Batch 377/560] [D loss: 0.355674, acc:  36%] [G loss: 7.266785, adv: 0.304003, recon: 0.302659, id: 0.369078] time: 0:20:47.126942 \n","[Epoch 1/1] [Batch 378/560] [D loss: 0.439240, acc:  43%] [G loss: 5.748224, adv: 0.718701, recon: 0.196154, id: 0.213405] time: 0:20:50.010084 \n","[Epoch 1/1] [Batch 379/560] [D loss: 0.389130, acc:  56%] [G loss: 4.876556, adv: 0.375514, recon: 0.188564, id: 0.137637] time: 0:20:51.909709 \n","[Epoch 1/1] [Batch 380/560] [D loss: 0.256625, acc:  59%] [G loss: 7.045034, adv: 0.399335, recon: 0.285208, id: 0.293745] time: 0:20:54.510296 \n","[Epoch 1/1] [Batch 381/560] [D loss: 0.213178, acc:  66%] [G loss: 6.820298, adv: 0.404111, recon: 0.272580, id: 0.366245] time: 0:20:59.160411 \n","[Epoch 1/1] [Batch 382/560] [D loss: 0.204021, acc:  67%] [G loss: 5.741884, adv: 0.479886, recon: 0.217700, id: 0.226505] time: 0:21:02.719216 \n","[Epoch 1/1] [Batch 383/560] [D loss: 0.212149, acc:  67%] [G loss: 6.513529, adv: 0.367307, recon: 0.263827, id: 0.210634] time: 0:21:05.676620 \n","[Epoch 1/1] [Batch 384/560] [D loss: 0.256844, acc:  55%] [G loss: 4.918300, adv: 0.346069, recon: 0.191636, id: 0.185557] time: 0:21:07.841463 \n","[Epoch 1/1] [Batch 385/560] [D loss: 0.241928, acc:  59%] [G loss: 5.839064, adv: 0.371605, recon: 0.232122, id: 0.236502] time: 0:21:09.807573 \n","[Epoch 1/1] [Batch 386/560] [D loss: 0.318366, acc:  45%] [G loss: 5.256534, adv: 0.321305, recon: 0.209262, id: 0.206497] time: 0:21:12.634559 \n","[Epoch 1/1] [Batch 387/560] [D loss: 0.359957, acc:  45%] [G loss: 6.902266, adv: 0.402637, recon: 0.276293, id: 0.391182] time: 0:21:14.662523 \n","[Epoch 1/1] [Batch 388/560] [D loss: 0.277451, acc:  57%] [G loss: 6.148839, adv: 0.372481, recon: 0.245366, id: 0.254443] time: 0:21:17.517962 \n","[Epoch 1/1] [Batch 389/560] [D loss: 0.220273, acc:  66%] [G loss: 5.507858, adv: 0.416264, recon: 0.212592, id: 0.206643] time: 0:21:19.424614 \n","[Epoch 1/1] [Batch 390/560] [D loss: 0.258975, acc:  59%] [G loss: 6.921354, adv: 0.357321, recon: 0.282292, id: 0.356159] time: 0:21:21.307801 \n","[Epoch 1/1] [Batch 391/560] [D loss: 0.304199, acc:  48%] [G loss: 5.222467, adv: 0.308940, recon: 0.209598, id: 0.212942] time: 0:21:23.655370 \n","[Epoch 1/1] [Batch 392/560] [D loss: 0.157332, acc:  77%] [G loss: 7.238719, adv: 0.461566, recon: 0.290495, id: 0.170736] time: 0:21:25.685297 \n","[Epoch 1/1] [Batch 393/560] [D loss: 0.272796, acc:  56%] [G loss: 6.941853, adv: 0.354895, recon: 0.284496, id: 0.355383] time: 0:21:27.620850 \n","[Epoch 1/1] [Batch 394/560] [D loss: 0.226699, acc:  67%] [G loss: 6.700579, adv: 0.471686, recon: 0.262697, id: 0.206368] time: 0:21:30.045744 \n","[Epoch 1/1] [Batch 395/560] [D loss: 0.294775, acc:  56%] [G loss: 8.326572, adv: 0.337853, recon: 0.350596, id: 0.257930] time: 0:21:32.857932 \n","[Epoch 1/1] [Batch 396/560] [D loss: 0.211755, acc:  72%] [G loss: 6.906342, adv: 0.422700, recon: 0.277340, id: 0.315871] time: 0:21:34.868662 \n","[Epoch 1/1] [Batch 397/560] [D loss: 0.291566, acc:  51%] [G loss: 10.114805, adv: 0.353911, recon: 0.427363, id: 0.601071] time: 0:21:37.534314 \n","[Epoch 1/1] [Batch 398/560] [D loss: 0.230174, acc:  64%] [G loss: 7.189988, adv: 0.381423, recon: 0.292642, id: 0.352221] time: 0:21:40.173061 \n","[Epoch 1/1] [Batch 399/560] [D loss: 0.212065, acc:  68%] [G loss: 7.139122, adv: 0.385237, recon: 0.289851, id: 0.306533] time: 0:21:43.106497 \n","[Epoch 1/1] [Batch 400/560] [D loss: 0.232554, acc:  66%] [G loss: 6.897174, adv: 0.409707, recon: 0.279721, id: 0.242994] time: 0:21:45.097551 \n","[Epoch 1/1] [Batch 401/560] [D loss: 0.282743, acc:  56%] [G loss: 5.974385, adv: 0.415663, recon: 0.234873, id: 0.232931] time: 0:21:48.258955 \n","[Epoch 1/1] [Batch 402/560] [D loss: 0.228001, acc:  65%] [G loss: 6.009962, adv: 0.432974, recon: 0.232473, id: 0.207021] time: 0:21:50.304112 \n","[Epoch 1/1] [Batch 403/560] [D loss: 0.297114, acc:  49%] [G loss: 5.411411, adv: 0.326999, recon: 0.216502, id: 0.209058] time: 0:21:52.434929 \n","[Epoch 1/1] [Batch 404/560] [D loss: 0.379312, acc:  50%] [G loss: 6.611421, adv: 0.463598, recon: 0.257425, id: 0.300999] time: 0:21:55.565306 \n","[Epoch 1/1] [Batch 405/560] [D loss: 0.192386, acc:  72%] [G loss: 5.619434, adv: 0.556037, recon: 0.206063, id: 0.158504] time: 0:21:57.520051 \n","[Epoch 1/1] [Batch 406/560] [D loss: 0.383203, acc:  49%] [G loss: 5.583717, adv: 0.336296, recon: 0.223432, id: 0.188982] time: 0:22:00.424699 \n","[Epoch 1/1] [Batch 407/560] [D loss: 0.248787, acc:  60%] [G loss: 5.769688, adv: 0.553783, recon: 0.213539, id: 0.145395] time: 0:22:02.708518 \n","[Epoch 1/1] [Batch 408/560] [D loss: 0.395301, acc:  54%] [G loss: 5.836243, adv: 0.462761, recon: 0.222885, id: 0.266970] time: 0:22:04.688900 \n","[Epoch 1/1] [Batch 409/560] [D loss: 0.270335, acc:  58%] [G loss: 6.088794, adv: 0.390762, recon: 0.243063, id: 0.212553] time: 0:22:07.327944 \n","[Epoch 1/1] [Batch 410/560] [D loss: 0.237521, acc:  59%] [G loss: 6.501553, adv: 0.381714, recon: 0.259374, id: 0.286470] time: 0:22:09.309959 \n","[Epoch 1/1] [Batch 411/560] [D loss: 0.266750, acc:  62%] [G loss: 9.070257, adv: 0.548144, recon: 0.365128, id: 0.440764] time: 0:22:12.181271 \n","[Epoch 1/1] [Batch 412/560] [D loss: 0.283172, acc:  65%] [G loss: 8.942076, adv: 0.511589, recon: 0.362327, id: 0.442847] time: 0:22:14.921742 \n","[Epoch 1/1] [Batch 413/560] [D loss: 0.525013, acc:  50%] [G loss: 6.177528, adv: 0.560642, recon: 0.231263, id: 0.226413] time: 0:22:17.123122 \n","[Epoch 1/1] [Batch 414/560] [D loss: 0.438266, acc:  47%] [G loss: 7.513548, adv: 0.542201, recon: 0.292459, id: 0.342187] time: 0:22:19.160021 \n","[Epoch 1/1] [Batch 415/560] [D loss: 0.618041, acc:  60%] [G loss: 9.620496, adv: 1.628636, recon: 0.290642, id: 0.223516] time: 0:22:21.269410 \n","[Epoch 1/1] [Batch 416/560] [D loss: 0.841186, acc:  47%] [G loss: 5.013442, adv: 0.403777, recon: 0.191568, id: 0.219301] time: 0:22:23.813657 \n","[Epoch 1/1] [Batch 417/560] [D loss: 0.284022, acc:  60%] [G loss: 5.095572, adv: 0.412756, recon: 0.193667, id: 0.194570] time: 0:22:26.107945 \n","[Epoch 1/1] [Batch 418/560] [D loss: 0.280814, acc:  53%] [G loss: 5.732440, adv: 0.431216, recon: 0.220804, id: 0.244261] time: 0:22:27.985261 \n","[Epoch 1/1] [Batch 419/560] [D loss: 0.236269, acc:  61%] [G loss: 8.580873, adv: 0.335211, recon: 0.359067, id: 0.507143] time: 0:22:30.642273 \n","[Epoch 1/1] [Batch 420/560] [D loss: 0.327783, acc:  52%] [G loss: 7.288040, adv: 0.392474, recon: 0.295433, id: 0.334985] time: 0:22:32.736710 \n","[Epoch 1/1] [Batch 421/560] [D loss: 0.237441, acc:  63%] [G loss: 13.370152, adv: 0.426680, recon: 0.568789, id: 0.299881] time: 0:22:35.740997 \n","[Epoch 1/1] [Batch 422/560] [D loss: 0.253323, acc:  60%] [G loss: 4.890832, adv: 0.373370, recon: 0.188189, id: 0.185099] time: 0:22:37.744812 \n","[Epoch 1/1] [Batch 423/560] [D loss: 0.226645, acc:  63%] [G loss: 7.819897, adv: 0.521999, recon: 0.307558, id: 0.372789] time: 0:22:39.686367 \n","[Epoch 1/1] [Batch 424/560] [D loss: 0.259128, acc:  65%] [G loss: 8.924316, adv: 0.512966, recon: 0.359307, id: 0.495376] time: 0:22:41.697167 \n","[Epoch 1/1] [Batch 425/560] [D loss: 0.416506, acc:  54%] [G loss: 6.573998, adv: 0.387612, recon: 0.263904, id: 0.246325] time: 0:22:45.818355 \n","[Epoch 1/1] [Batch 426/560] [D loss: 0.234213, acc:  65%] [G loss: 5.550991, adv: 0.477274, recon: 0.208343, id: 0.206237] time: 0:22:48.146380 \n","[Epoch 1/1] [Batch 427/560] [D loss: 0.288948, acc:  53%] [G loss: 8.889755, adv: 0.384192, recon: 0.369644, id: 0.489537] time: 0:22:50.133969 \n","[Epoch 1/1] [Batch 428/560] [D loss: 0.177317, acc:  74%] [G loss: 9.332950, adv: 0.425767, recon: 0.386137, id: 0.480200] time: 0:22:52.231011 \n","[Epoch 1/1] [Batch 429/560] [D loss: 0.265010, acc:  56%] [G loss: 7.554804, adv: 0.391816, recon: 0.307869, id: 0.362736] time: 0:22:55.072024 \n","[Epoch 1/1] [Batch 430/560] [D loss: 0.281461, acc:  54%] [G loss: 8.693608, adv: 0.409550, recon: 0.358162, id: 0.342538] time: 0:22:57.078306 \n","[Epoch 1/1] [Batch 431/560] [D loss: 0.240531, acc:  62%] [G loss: 11.044443, adv: 0.407397, recon: 0.469510, id: 0.442465] time: 0:23:00.237648 \n","[Epoch 1/1] [Batch 432/560] [D loss: 0.373610, acc:  49%] [G loss: 5.764187, adv: 0.396037, recon: 0.227110, id: 0.223798] time: 0:23:03.567728 \n","[Epoch 1/1] [Batch 433/560] [D loss: 0.237598, acc:  64%] [G loss: 5.614583, adv: 0.465371, recon: 0.213661, id: 0.177798] time: 0:23:05.597014 \n","[Epoch 1/1] [Batch 434/560] [D loss: 0.216410, acc:  65%] [G loss: 5.988300, adv: 0.422329, recon: 0.234864, id: 0.216429] time: 0:23:08.269560 \n","[Epoch 1/1] [Batch 435/560] [D loss: 0.214878, acc:  69%] [G loss: 6.179755, adv: 0.446336, recon: 0.240115, id: 0.229996] time: 0:23:10.215102 \n","[Epoch 1/1] [Batch 436/560] [D loss: 0.286568, acc:  54%] [G loss: 6.926027, adv: 0.502778, recon: 0.271857, id: 0.176879] time: 0:23:12.073526 \n","[Epoch 1/1] [Batch 437/560] [D loss: 0.222768, acc:  67%] [G loss: 8.681426, adv: 0.496504, recon: 0.353280, id: 0.289781] time: 0:23:14.752792 \n","[Epoch 1/1] [Batch 438/560] [D loss: 0.260542, acc:  60%] [G loss: 6.195620, adv: 0.367088, recon: 0.250295, id: 0.194039] time: 0:23:18.573680 \n","[Epoch 1/1] [Batch 439/560] [D loss: 0.293573, acc:  55%] [G loss: 5.604290, adv: 0.363509, recon: 0.221753, id: 0.213378] time: 0:23:20.655567 \n","[Epoch 1/1] [Batch 440/560] [D loss: 0.242341, acc:  61%] [G loss: 7.510418, adv: 0.651589, recon: 0.282604, id: 0.279343] time: 0:23:24.397218 \n","[Epoch 1/1] [Batch 441/560] [D loss: 0.414719, acc:  63%] [G loss: 8.248805, adv: 1.013400, recon: 0.283873, id: 0.346803] time: 0:23:26.340844 \n","[Epoch 1/1] [Batch 442/560] [D loss: 1.268746, acc:  55%] [G loss: 10.759863, adv: 2.982808, recon: 0.218152, id: 0.213314] time: 0:23:28.738339 \n","[Epoch 1/1] [Batch 443/560] [D loss: 1.227824, acc:  63%] [G loss: 6.439721, adv: 0.594707, recon: 0.238568, id: 0.195088] time: 0:23:30.690817 \n","[Epoch 1/1] [Batch 444/560] [D loss: 0.726083, acc:  54%] [G loss: 7.524058, adv: 1.490724, recon: 0.206384, id: 0.156629] time: 0:23:32.614547 \n","[Epoch 1/1] [Batch 445/560] [D loss: 0.662896, acc:  52%] [G loss: 8.784176, adv: 0.563854, recon: 0.348577, id: 0.373482] time: 0:23:35.430788 \n","[Epoch 1/1] [Batch 446/560] [D loss: 0.311223, acc:  64%] [G loss: 8.708437, adv: 0.598900, recon: 0.343863, id: 0.398755] time: 0:23:38.381120 \n","[Epoch 1/1] [Batch 447/560] [D loss: 0.420497, acc:  37%] [G loss: 5.220123, adv: 0.284331, recon: 0.211955, id: 0.203697] time: 0:23:40.259435 \n","[Epoch 1/1] [Batch 448/560] [D loss: 0.211317, acc:  66%] [G loss: 6.103395, adv: 0.391332, recon: 0.243739, id: 0.185648] time: 0:23:42.622627 \n","[Epoch 1/1] [Batch 449/560] [D loss: 0.213790, acc:  68%] [G loss: 6.131801, adv: 0.378190, recon: 0.245160, id: 0.213088] time: 0:23:45.306690 \n","[Epoch 1/1] [Batch 450/560] [D loss: 0.201508, acc:  70%] [G loss: 6.398355, adv: 0.452677, recon: 0.251776, id: 0.215252] time: 0:23:47.868188 \n","[Epoch 1/1] [Batch 451/560] [D loss: 0.218009, acc:  68%] [G loss: 7.395275, adv: 0.494433, recon: 0.291822, id: 0.257111] time: 0:23:49.976407 \n","[Epoch 1/1] [Batch 452/560] [D loss: 0.347069, acc:  44%] [G loss: 6.004786, adv: 0.365438, recon: 0.239238, id: 0.292340] time: 0:23:52.009226 \n","[Epoch 1/1] [Batch 453/560] [D loss: 0.285396, acc:  62%] [G loss: 8.186060, adv: 0.438305, recon: 0.336616, id: 0.331360] time: 0:23:54.655266 \n","[Epoch 1/1] [Batch 454/560] [D loss: 0.224354, acc:  64%] [G loss: 7.100577, adv: 0.365663, recon: 0.292412, id: 0.201337] time: 0:23:56.795750 \n","[Epoch 1/1] [Batch 455/560] [D loss: 0.314026, acc:  49%] [G loss: 7.329577, adv: 0.367391, recon: 0.302370, id: 0.354351] time: 0:23:58.801743 \n","[Epoch 1/1] [Batch 456/560] [D loss: 0.250711, acc:  56%] [G loss: 5.673833, adv: 0.373818, recon: 0.224958, id: 0.212817] time: 0:24:00.784567 \n","[Epoch 1/1] [Batch 457/560] [D loss: 0.241153, acc:  61%] [G loss: 9.989728, adv: 0.411252, recon: 0.417763, id: 0.560871] time: 0:24:02.756353 \n","[Epoch 1/1] [Batch 458/560] [D loss: 0.281866, acc:  55%] [G loss: 5.858405, adv: 0.367982, recon: 0.234459, id: 0.272168] time: 0:24:04.967147 \n","[Epoch 1/1] [Batch 459/560] [D loss: 0.244130, acc:  60%] [G loss: 7.489651, adv: 0.385484, recon: 0.306470, id: 0.399883] time: 0:24:06.867935 \n","[Epoch 1/1] [Batch 460/560] [D loss: 0.271009, acc:  61%] [G loss: 6.769080, adv: 0.394735, recon: 0.270223, id: 0.304011] time: 0:24:08.798050 \n","[Epoch 1/1] [Batch 461/560] [D loss: 0.201396, acc:  70%] [G loss: 7.984127, adv: 0.411445, recon: 0.325734, id: 0.409537] time: 0:24:10.754650 \n","[Epoch 1/1] [Batch 462/560] [D loss: 0.260189, acc:  57%] [G loss: 7.756889, adv: 0.552942, recon: 0.303623, id: 0.353524] time: 0:24:12.813556 \n","[Epoch 1/1] [Batch 463/560] [D loss: 0.328237, acc:  59%] [G loss: 4.723767, adv: 0.421663, recon: 0.178179, id: 0.134888] time: 0:24:15.964021 \n","[Epoch 1/1] [Batch 464/560] [D loss: 0.349960, acc:  49%] [G loss: 9.162459, adv: 0.375618, recon: 0.383094, id: 0.457495] time: 0:24:18.554828 \n","[Epoch 1/1] [Batch 465/560] [D loss: 0.197512, acc:  71%] [G loss: 6.134424, adv: 0.534045, recon: 0.228550, id: 0.224398] time: 0:24:20.505704 \n","[Epoch 1/1] [Batch 466/560] [D loss: 0.239934, acc:  65%] [G loss: 6.057271, adv: 0.433940, recon: 0.235815, id: 0.271094] time: 0:24:22.684971 \n","[Epoch 1/1] [Batch 467/560] [D loss: 0.323370, acc:  42%] [G loss: 5.147147, adv: 0.369781, recon: 0.199661, id: 0.180964] time: 0:24:24.656016 \n","[Epoch 1/1] [Batch 468/560] [D loss: 0.279855, acc:  63%] [G loss: 7.906766, adv: 0.439053, recon: 0.321111, id: 0.410200] time: 0:24:26.769511 \n","[Epoch 1/1] [Batch 469/560] [D loss: 0.160743, acc:  79%] [G loss: 6.386186, adv: 0.476230, recon: 0.249921, id: 0.197546] time: 0:24:28.716551 \n","[Epoch 1/1] [Batch 470/560] [D loss: 0.271150, acc:  59%] [G loss: 5.932465, adv: 0.374584, recon: 0.236710, id: 0.121113] time: 0:24:31.257666 \n","[Epoch 1/1] [Batch 471/560] [D loss: 0.254458, acc:  57%] [G loss: 5.617058, adv: 0.385911, recon: 0.220163, id: 0.207359] time: 0:24:33.324888 \n","[Epoch 1/1] [Batch 472/560] [D loss: 0.399587, acc:  43%] [G loss: 5.573343, adv: 0.527107, recon: 0.204266, id: 0.181200] time: 0:24:35.294985 \n","[Epoch 1/1] [Batch 473/560] [D loss: 0.357335, acc:  54%] [G loss: 8.999868, adv: 0.385682, recon: 0.374300, id: 0.471610] time: 0:24:37.697519 \n","[Epoch 1/1] [Batch 474/560] [D loss: 0.255295, acc:  55%] [G loss: 6.076558, adv: 0.347008, recon: 0.245956, id: 0.244967] time: 0:24:40.286348 \n","[Epoch 1/1] [Batch 475/560] [D loss: 0.224806, acc:  63%] [G loss: 5.790394, adv: 0.401636, recon: 0.227257, id: 0.139107] time: 0:24:42.325374 \n","[Epoch 1/1] [Batch 476/560] [D loss: 0.285356, acc:  57%] [G loss: 5.320150, adv: 0.335803, recon: 0.211889, id: 0.229885] time: 0:24:45.654119 \n","[Epoch 1/1] [Batch 477/560] [D loss: 0.336056, acc:  56%] [G loss: 6.235577, adv: 0.637058, recon: 0.226223, id: 0.179775] time: 0:24:47.469691 \n","[Epoch 1/1] [Batch 478/560] [D loss: 0.556204, acc:  49%] [G loss: 8.166380, adv: 0.530395, recon: 0.325823, id: 0.354341] time: 0:24:49.987079 \n","[Epoch 1/1] [Batch 479/560] [D loss: 0.308780, acc:  54%] [G loss: 8.124841, adv: 0.389180, recon: 0.335215, id: 0.240058] time: 0:24:53.071026 \n","[Epoch 1/1] [Batch 480/560] [D loss: 0.272883, acc:  62%] [G loss: 5.539419, adv: 0.449052, recon: 0.212804, id: 0.161654] time: 0:24:54.996521 \n","[Epoch 1/1] [Batch 481/560] [D loss: 0.295370, acc:  51%] [G loss: 7.031320, adv: 0.344338, recon: 0.288634, id: 0.350741] time: 0:24:56.872245 \n","[Epoch 1/1] [Batch 482/560] [D loss: 0.257262, acc:  57%] [G loss: 6.524595, adv: 0.341940, recon: 0.264640, id: 0.208222] time: 0:24:59.478788 \n","[Epoch 1/1] [Batch 483/560] [D loss: 0.361991, acc:  50%] [G loss: 5.788659, adv: 0.362106, recon: 0.229904, id: 0.242318] time: 0:25:01.519249 \n","[Epoch 1/1] [Batch 484/560] [D loss: 0.189202, acc:  72%] [G loss: 5.365940, adv: 0.503388, recon: 0.198902, id: 0.201449] time: 0:25:03.513650 \n","[Epoch 1/1] [Batch 485/560] [D loss: 0.288289, acc:  56%] [G loss: 6.746920, adv: 0.552596, recon: 0.256077, id: 0.277045] time: 0:25:06.023677 \n","[Epoch 1/1] [Batch 486/560] [D loss: 0.232612, acc:  71%] [G loss: 5.935520, adv: 0.415557, recon: 0.233816, id: 0.192966] time: 0:25:07.817271 \n","[Epoch 1/1] [Batch 487/560] [D loss: 0.351588, acc:  51%] [G loss: 7.677079, adv: 0.443255, recon: 0.310218, id: 0.298734] time: 0:25:09.759785 \n","[Epoch 1/1] [Batch 488/560] [D loss: 0.278082, acc:  61%] [G loss: 7.568265, adv: 0.438601, recon: 0.306073, id: 0.347995] time: 0:25:11.773808 \n","[Epoch 1/1] [Batch 489/560] [D loss: 0.189271, acc:  72%] [G loss: 5.107880, adv: 0.470939, recon: 0.189441, id: 0.141853] time: 0:25:14.416941 \n","[Epoch 1/1] [Batch 490/560] [D loss: 0.254296, acc:  61%] [G loss: 7.648304, adv: 0.326284, recon: 0.317803, id: 0.487768] time: 0:25:17.001369 \n","[Epoch 1/1] [Batch 491/560] [D loss: 0.171161, acc:  76%] [G loss: 6.576258, adv: 0.538546, recon: 0.253711, id: 0.210782] time: 0:25:18.942692 \n","[Epoch 1/1] [Batch 492/560] [D loss: 0.288258, acc:  46%] [G loss: 6.304630, adv: 0.305988, recon: 0.259699, id: 0.142299] time: 0:25:21.564083 \n","[Epoch 1/1] [Batch 493/560] [D loss: 0.159312, acc:  81%] [G loss: 6.556512, adv: 0.444937, recon: 0.258855, id: 0.239148] time: 0:25:24.407524 \n","[Epoch 1/1] [Batch 494/560] [D loss: 0.184505, acc:  72%] [G loss: 5.864150, adv: 0.411053, recon: 0.230018, id: 0.277939] time: 0:25:26.632913 \n","[Epoch 1/1] [Batch 495/560] [D loss: 0.313792, acc:  50%] [G loss: 6.725127, adv: 0.382741, recon: 0.271948, id: 0.308138] time: 0:25:28.923413 \n","[Epoch 1/1] [Batch 496/560] [D loss: 0.316807, acc:  50%] [G loss: 5.886365, adv: 0.491365, recon: 0.223695, id: 0.208302] time: 0:25:31.587023 \n","[Epoch 1/1] [Batch 497/560] [D loss: 0.208881, acc:  67%] [G loss: 4.807296, adv: 0.468087, recon: 0.175473, id: 0.191680] time: 0:25:34.871772 \n","[Epoch 1/1] [Batch 498/560] [D loss: 0.246702, acc:  58%] [G loss: 6.010479, adv: 0.375283, recon: 0.237315, id: 0.269785] time: 0:25:37.027026 \n","[Epoch 1/1] [Batch 499/560] [D loss: 0.248654, acc:  60%] [G loss: 5.155713, adv: 0.345863, recon: 0.204177, id: 0.208558] time: 0:25:39.428751 \n","[Epoch 1/1] [Batch 500/560] [D loss: 0.176510, acc:  73%] [G loss: 4.439752, adv: 0.412115, recon: 0.165040, id: 0.170339] time: 0:25:41.404083 \n","[Epoch 1/1] [Batch 501/560] [D loss: 0.176055, acc:  77%] [G loss: 7.112950, adv: 0.488379, recon: 0.280397, id: 0.292630] time: 0:25:43.481272 \n","[Epoch 1/1] [Batch 502/560] [D loss: 0.182333, acc:  75%] [G loss: 5.382170, adv: 0.485603, recon: 0.202382, id: 0.188075] time: 0:25:45.987192 \n","[Epoch 1/1] [Batch 503/560] [D loss: 0.223034, acc:  64%] [G loss: 6.540466, adv: 0.421532, recon: 0.259012, id: 0.293154] time: 0:25:47.898284 \n","[Epoch 1/1] [Batch 504/560] [D loss: 0.355638, acc:  32%] [G loss: 6.999235, adv: 0.251299, recon: 0.295721, id: 0.394620] time: 0:25:49.817931 \n","[Epoch 1/1] [Batch 505/560] [D loss: 0.144396, acc:  83%] [G loss: 7.278772, adv: 0.478048, recon: 0.289641, id: 0.300930] time: 0:25:53.107835 \n","[Epoch 1/1] [Batch 506/560] [D loss: 0.297812, acc:  48%] [G loss: 6.074547, adv: 0.326648, recon: 0.248238, id: 0.261905] time: 0:25:55.695852 \n","[Epoch 1/1] [Batch 507/560] [D loss: 0.309399, acc:  48%] [G loss: 7.897162, adv: 0.344483, recon: 0.328061, id: 0.403134] time: 0:25:57.659392 \n","[Epoch 1/1] [Batch 508/560] [D loss: 0.372282, acc:  43%] [G loss: 5.205647, adv: 0.345022, recon: 0.204202, id: 0.231991] time: 0:25:59.629176 \n","[Epoch 1/1] [Batch 509/560] [D loss: 0.279051, acc:  53%] [G loss: 7.632127, adv: 0.350737, recon: 0.315839, id: 0.294021] time: 0:26:01.470159 \n","[Epoch 1/1] [Batch 510/560] [D loss: 0.195921, acc:  70%] [G loss: 6.370379, adv: 0.439588, recon: 0.249532, id: 0.263463] time: 0:26:03.385024 \n","[Epoch 1/1] [Batch 511/560] [D loss: 0.297430, acc:  47%] [G loss: 5.634476, adv: 0.289886, recon: 0.230761, id: 0.293164] time: 0:26:05.927167 \n","[Epoch 1/1] [Batch 512/560] [D loss: 0.333773, acc:  38%] [G loss: 4.281279, adv: 0.296072, recon: 0.166661, id: 0.160517] time: 0:26:07.937884 \n","[Epoch 1/1] [Batch 513/560] [D loss: 0.212368, acc:  68%] [G loss: 7.099607, adv: 0.381520, recon: 0.289021, id: 0.317239] time: 0:26:09.900854 \n","[Epoch 1/1] [Batch 514/560] [D loss: 0.349312, acc:  50%] [G loss: 4.731778, adv: 0.335822, recon: 0.184588, id: 0.152734] time: 0:26:12.723786 \n","[Epoch 1/1] [Batch 515/560] [D loss: 0.293461, acc:  54%] [G loss: 5.003294, adv: 0.413153, recon: 0.188873, id: 0.185880] time: 0:26:14.844457 \n","[Epoch 1/1] [Batch 516/560] [D loss: 0.373842, acc:  42%] [G loss: 4.437356, adv: 0.309385, recon: 0.174311, id: 0.157602] time: 0:26:16.825227 \n","[Epoch 1/1] [Batch 517/560] [D loss: 0.234024, acc:  66%] [G loss: 5.697814, adv: 0.470031, recon: 0.215329, id: 0.259798] time: 0:26:19.646778 \n","[Epoch 1/1] [Batch 518/560] [D loss: 0.196356, acc:  68%] [G loss: 6.232641, adv: 0.440326, recon: 0.244108, id: 0.216238] time: 0:26:22.328042 \n","[Epoch 1/1] [Batch 519/560] [D loss: 0.229177, acc:  68%] [G loss: 5.406434, adv: 0.442051, recon: 0.205101, id: 0.235537] time: 0:26:24.284043 \n","[Epoch 1/1] [Batch 520/560] [D loss: 0.256678, acc:  58%] [G loss: 5.732739, adv: 0.397308, recon: 0.224603, id: 0.176591] time: 0:26:26.433350 \n","[Epoch 1/1] [Batch 521/560] [D loss: 0.347393, acc:  41%] [G loss: 7.603387, adv: 0.275870, recon: 0.321065, id: 0.376112] time: 0:26:28.390701 \n","[Epoch 1/1] [Batch 522/560] [D loss: 0.248603, acc:  57%] [G loss: 5.019732, adv: 0.352095, recon: 0.196750, id: 0.183672] time: 0:26:30.443883 \n","[Epoch 1/1] [Batch 523/560] [D loss: 0.177912, acc:  71%] [G loss: 7.064165, adv: 0.436859, recon: 0.282451, id: 0.273890] time: 0:26:32.511706 \n","[Epoch 1/1] [Batch 524/560] [D loss: 0.161433, acc:  77%] [G loss: 6.457820, adv: 0.443291, recon: 0.254646, id: 0.257080] time: 0:26:34.427954 \n","[Epoch 1/1] [Batch 525/560] [D loss: 0.197146, acc:  68%] [G loss: 6.544479, adv: 0.539519, recon: 0.250585, id: 0.172418] time: 0:26:36.306760 \n","[Epoch 1/1] [Batch 526/560] [D loss: 0.339148, acc:  45%] [G loss: 8.000056, adv: 0.305377, recon: 0.337555, id: 0.309412] time: 0:26:38.630092 \n","[Epoch 1/1] [Batch 527/560] [D loss: 0.273721, acc:  52%] [G loss: 6.827418, adv: 0.413950, recon: 0.274897, id: 0.266656] time: 0:26:40.951782 \n","[Epoch 1/1] [Batch 528/560] [D loss: 0.386329, acc:  38%] [G loss: 9.442540, adv: 0.274739, recon: 0.404935, id: 0.455040] time: 0:26:43.335864 \n","[Epoch 1/1] [Batch 529/560] [D loss: 0.263776, acc:  52%] [G loss: 6.157773, adv: 0.400833, recon: 0.245980, id: 0.219769] time: 0:26:45.854205 \n","[Epoch 1/1] [Batch 530/560] [D loss: 0.273173, acc:  60%] [G loss: 8.111219, adv: 0.757124, recon: 0.303435, id: 0.326757] time: 0:26:47.748525 \n","[Epoch 1/1] [Batch 531/560] [D loss: 0.288531, acc:  63%] [G loss: 7.022672, adv: 0.434695, recon: 0.279663, id: 0.322032] time: 0:26:50.366044 \n","[Epoch 1/1] [Batch 532/560] [D loss: 0.342837, acc:  52%] [G loss: 5.295406, adv: 0.369842, recon: 0.209249, id: 0.160722] time: 0:26:52.339073 \n","[Epoch 1/1] [Batch 533/560] [D loss: 0.249526, acc:  63%] [G loss: 6.228593, adv: 0.346105, recon: 0.253093, id: 0.272056] time: 0:26:54.255878 \n","[Epoch 1/1] [Batch 534/560] [D loss: 0.256832, acc:  57%] [G loss: 5.534588, adv: 0.287093, recon: 0.227072, id: 0.221122] time: 0:26:56.899412 \n","[Epoch 1/1] [Batch 535/560] [D loss: 0.335006, acc:  60%] [G loss: 8.753146, adv: 0.704998, recon: 0.338116, id: 0.375483] time: 0:26:59.462984 \n","[Epoch 1/1] [Batch 536/560] [D loss: 0.474480, acc:  65%] [G loss: 7.282778, adv: 0.686546, recon: 0.269165, id: 0.334237] time: 0:27:01.393320 \n","[Epoch 1/1] [Batch 537/560] [D loss: 0.333397, acc:  58%] [G loss: 7.835194, adv: 0.492242, recon: 0.311758, id: 0.314493] time: 0:27:03.834708 \n","[Epoch 1/1] [Batch 538/560] [D loss: 0.322841, acc:  51%] [G loss: 6.531167, adv: 0.389465, recon: 0.261899, id: 0.261020] time: 0:27:05.886862 \n","[Epoch 1/1] [Batch 539/560] [D loss: 0.371738, acc:  33%] [G loss: 7.540382, adv: 0.220478, recon: 0.324760, id: 0.250279] time: 0:27:08.906674 \n","[Epoch 1/1] [Batch 540/560] [D loss: 0.242835, acc:  62%] [G loss: 4.879415, adv: 0.369364, recon: 0.187616, id: 0.204609] time: 0:27:10.883306 \n","[Epoch 1/1] [Batch 541/560] [D loss: 0.237038, acc:  59%] [G loss: 5.651893, adv: 0.396031, recon: 0.220812, id: 0.219354] time: 0:27:13.501383 \n","[Epoch 1/1] [Batch 542/560] [D loss: 0.293441, acc:  48%] [G loss: 4.896417, adv: 0.377675, recon: 0.188054, id: 0.196194] time: 0:27:16.461872 \n","[Epoch 1/1] [Batch 543/560] [D loss: 0.219546, acc:  67%] [G loss: 5.894714, adv: 0.455456, recon: 0.226928, id: 0.281189] time: 0:27:21.772045 \n","[Epoch 1/1] [Batch 544/560] [D loss: 0.312747, acc:  51%] [G loss: 5.839185, adv: 0.401829, recon: 0.230616, id: 0.178724] time: 0:27:24.014375 \n","[Epoch 1/1] [Batch 545/560] [D loss: 0.253654, acc:  61%] [G loss: 6.387193, adv: 0.358434, recon: 0.258609, id: 0.274937] time: 0:27:26.564111 \n","[Epoch 1/1] [Batch 546/560] [D loss: 0.217561, acc:  68%] [G loss: 5.444984, adv: 0.474873, recon: 0.205667, id: 0.200545] time: 0:27:28.862801 \n","[Epoch 1/1] [Batch 547/560] [D loss: 0.205805, acc:  70%] [G loss: 5.361400, adv: 0.465078, recon: 0.201943, id: 0.177806] time: 0:27:31.502692 \n","[Epoch 1/1] [Batch 548/560] [D loss: 0.271121, acc:  52%] [G loss: 6.150790, adv: 0.355612, recon: 0.249179, id: 0.202335] time: 0:27:33.410846 \n","[Epoch 1/1] [Batch 549/560] [D loss: 0.246226, acc:  61%] [G loss: 7.908425, adv: 0.362799, recon: 0.325495, id: 0.220386] time: 0:27:35.301147 \n","[Epoch 1/1] [Batch 550/560] [D loss: 0.314917, acc:  60%] [G loss: 7.732962, adv: 0.553718, recon: 0.303163, id: 0.296612] time: 0:27:37.699004 \n","[Epoch 1/1] [Batch 551/560] [D loss: 0.325022, acc:  52%] [G loss: 6.935420, adv: 0.339455, recon: 0.287260, id: 0.316603] time: 0:27:39.680593 \n","[Epoch 1/1] [Batch 552/560] [D loss: 0.203819, acc:  64%] [G loss: 6.853681, adv: 0.454315, recon: 0.272371, id: 0.249944] time: 0:27:42.485582 \n","[Epoch 1/1] [Batch 553/560] [D loss: 0.296481, acc:  57%] [G loss: 6.945961, adv: 0.491509, recon: 0.271240, id: 0.294449] time: 0:27:44.557608 \n","[Epoch 1/1] [Batch 554/560] [D loss: 0.342276, acc:  57%] [G loss: 6.574765, adv: 0.447022, recon: 0.261133, id: 0.267025] time: 0:27:47.323583 \n","[Epoch 1/1] [Batch 555/560] [D loss: 0.401489, acc:  51%] [G loss: 7.356559, adv: 0.357274, recon: 0.304606, id: 0.285438] time: 0:27:49.621750 \n","[Epoch 1/1] [Batch 556/560] [D loss: 0.245453, acc:  60%] [G loss: 9.229588, adv: 0.552424, recon: 0.371053, id: 0.421022] time: 0:27:51.560343 \n","[Epoch 1/1] [Batch 557/560] [D loss: 0.378438, acc:  59%] [G loss: 6.731971, adv: 0.354906, recon: 0.274535, id: 0.324169] time: 0:27:54.304213 \n","[Epoch 1/1] [Batch 558/560] [D loss: 0.277772, acc:  58%] [G loss: 5.113298, adv: 0.292429, recon: 0.206993, id: 0.168331] time: 0:27:56.210749 \n","[Epoch 1/1] [Batch 559/560] [D loss: 0.259216, acc:  56%] [G loss: 6.478786, adv: 0.351167, recon: 0.262964, id: 0.215898] time: 0:27:58.225456 \n","[Epoch 1/1] [Batch 560/560] [D loss: 0.178714, acc:  75%] [G loss: 5.150227, adv: 0.480235, recon: 0.190194, id: 0.196144] time: 0:28:00.088169 \n","2020-08-15T22:58:47.355835 End\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"pMvDYOhggPaY","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":264},"executionInfo":{"status":"ok","timestamp":1597532424710,"user_tz":-540,"elapsed":14052,"user":{"displayName":"Noboru Koike","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggp8njUb4jc54JrzfM5cQBkfiCdlz6nY17y8-1szg=s64","userId":"05156582812995850159"}},"outputId":"a983c0e5-39d3-4ee1-e8bc-c266dced6de9"},"source":["gan.plot_hisotry()"],"execution_count":12,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"K74TW9cbWeGE","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":453},"executionInfo":{"status":"error","timestamp":1597532707917,"user_tz":-540,"elapsed":253517,"user":{"displayName":"Noboru Koike","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggp8njUb4jc54JrzfM5cQBkfiCdlz6nY17y8-1szg=s64","userId":"05156582812995850159"}},"outputId":"f208ed9d-3351-4db9-c6a1-beca6121572a"},"source":["# Image A count: 560\n","gan.train(epochs=1, batch_size=20, sample_interval=20, save_interval=-1)"],"execution_count":13,"outputs":[{"output_type":"stream","text":["2020-08-15T23:00:54.571821 Start 2\n"],"name":"stdout"},{"output_type":"error","ename":"ResourceExhaustedError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)","\u001b[0;32m<ipython-input-13-fa38a5dc150f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Image A count: 560\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mgan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_interval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_interval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-9-a1af02f421ae>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, epochs, batch_size, sample_interval, save_interval)\u001b[0m\n\u001b[1;32m    219\u001b[0m                                                       [valid, valid,\n\u001b[1;32m    220\u001b[0m                                                        \u001b[0mimgs_A\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimgs_B\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m                                                        imgs_A, imgs_B])\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m                 \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics, return_dict)\u001b[0m\n\u001b[1;32m   1693\u001b[0m                                                     class_weight)\n\u001b[1;32m   1694\u001b[0m       \u001b[0mtrain_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1695\u001b[0;31m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1697\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mResourceExhaustedError\u001b[0m:  OOM when allocating tensor with shape[20,128,257,257] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node functional_9/functional_7/conv2d_37/Conv2D_2 (defined at <ipython-input-9-a1af02f421ae>:221) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n [Op:__inference_train_function_279592]\n\nFunction call stack:\ntrain_function\n"]}]},{"cell_type":"code","metadata":{"id":"ITHenWUlWr2k","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":133},"executionInfo":{"status":"ok","timestamp":1597533166866,"user_tz":-540,"elapsed":402303,"user":{"displayName":"Noboru Koike","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggp8njUb4jc54JrzfM5cQBkfiCdlz6nY17y8-1szg=s64","userId":"05156582812995850159"}},"outputId":"af84009a-660e-428b-957c-6ff1fbfdb321"},"source":["# Image A count: 560\n","gan.train(epochs=1, batch_size=10, sample_interval=10, save_interval=-1)"],"execution_count":15,"outputs":[{"output_type":"stream","text":["2020-08-15T23:06:04.752650 Start 3\n","[Epoch 1/1] [Batch 10/56] [D loss: 0.227379, acc:  64%] [G loss: 5.805872, adv: 0.343330, recon: 0.232094, id: 0.245777] time: 0:01:27.603686 \n","[Epoch 1/1] [Batch 20/56] [D loss: 0.238186, acc:  60%] [G loss: 5.084332, adv: 0.342492, recon: 0.199420, id: 0.210367] time: 0:02:36.220670 \n","[Epoch 1/1] [Batch 30/56] [D loss: 0.229503, acc:  61%] [G loss: 5.776100, adv: 0.337807, recon: 0.231915, id: 0.243236] time: 0:03:45.001395 \n","[Epoch 1/1] [Batch 40/56] [D loss: 0.221449, acc:  64%] [G loss: 5.154845, adv: 0.352305, recon: 0.201228, id: 0.212701] time: 0:04:56.508150 \n","[Epoch 1/1] [Batch 50/56] [D loss: 0.197312, acc:  71%] [G loss: 5.440647, adv: 0.391563, recon: 0.211624, id: 0.231294] time: 0:05:59.975021 \n","2020-08-15T23:12:45.359093 End\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"nsr-tbBQX0tP","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":183},"executionInfo":{"status":"ok","timestamp":1597533592161,"user_tz":-540,"elapsed":349842,"user":{"displayName":"Noboru Koike","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggp8njUb4jc54JrzfM5cQBkfiCdlz6nY17y8-1szg=s64","userId":"05156582812995850159"}},"outputId":"cb5a9460-34a2-458d-afff-7d7baf0615f1"},"source":["# Image A count: 560\n","gan.train(epochs=1, batch_size=8, sample_interval=8, save_interval=-1)"],"execution_count":16,"outputs":[{"output_type":"stream","text":["2020-08-15T23:14:02.504208 Start 4\n","[Epoch 1/1] [Batch 8/70] [D loss: 0.195425, acc:  72%] [G loss: 6.165210, adv: 0.387493, recon: 0.243976, id: 0.250181] time: 0:00:43.636952 \n","[Epoch 1/1] [Batch 16/70] [D loss: 0.172874, acc:  76%] [G loss: 6.363391, adv: 0.411182, recon: 0.251536, id: 0.290556] time: 0:01:19.893540 \n","[Epoch 1/1] [Batch 24/70] [D loss: 0.236669, acc:  60%] [G loss: 6.470014, adv: 0.321917, recon: 0.264106, id: 0.323066] time: 0:02:00.923299 \n","[Epoch 1/1] [Batch 32/70] [D loss: 0.241315, acc:  60%] [G loss: 5.305826, adv: 0.352408, recon: 0.209009, id: 0.223692] time: 0:02:42.111159 \n","[Epoch 1/1] [Batch 40/70] [D loss: 0.203380, acc:  68%] [G loss: 5.914784, adv: 0.409419, recon: 0.231197, id: 0.247947] time: 0:03:23.477604 \n","[Epoch 1/1] [Batch 48/70] [D loss: 0.225752, acc:  66%] [G loss: 6.556933, adv: 0.373410, recon: 0.263402, id: 0.319100] time: 0:04:03.180466 \n","[Epoch 1/1] [Batch 56/70] [D loss: 0.230117, acc:  63%] [G loss: 6.642514, adv: 0.360082, recon: 0.268648, id: 0.302987] time: 0:04:43.019327 \n","[Epoch 1/1] [Batch 64/70] [D loss: 0.228401, acc:  61%] [G loss: 5.564681, adv: 0.380654, recon: 0.217610, id: 0.255931] time: 0:05:18.411060 \n","2020-08-15T23:19:51.512200 End\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"xr9sHPvSZsNW","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}