{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"12_vangogh.ipynb","provenance":[],"mount_file_id":"1BA7WQ2_A0AzdJlmnWZCZMgNChVSyiTPh","authorship_tag":"ABX9TyN2HLuOcJ+yXdqvKOEikzUh"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"lOzwv5AssLuz","colab_type":"text"},"source":["### vanvogh2novel モデル作成、保存"]},{"cell_type":"code","metadata":{"id":"4u8Wf5j_r8qr","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":350},"executionInfo":{"status":"ok","timestamp":1597555330533,"user_tz":-540,"elapsed":2705,"user":{"displayName":"Noboru Koike","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggp8njUb4jc54JrzfM5cQBkfiCdlz6nY17y8-1szg=s64","userId":"05156582812995850159"}},"outputId":"d77a3be3-63db-4262-8407-008db445cc6c"},"source":["!nvidia-smi"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Sun Aug 16 05:22:08 2020       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 450.57       Driver Version: 418.67       CUDA Version: 10.1     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   32C    P0    25W / 250W |      0MiB / 16280MiB |      0%      Default |\n","|                               |                      |                 ERR! |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"nDuVbZjksTOy","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597555336839,"user_tz":-540,"elapsed":2164,"user":{"displayName":"Noboru Koike","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggp8njUb4jc54JrzfM5cQBkfiCdlz6nY17y8-1szg=s64","userId":"05156582812995850159"}}},"source":["from tensorflow_addons.layers import InstanceNormalization\n","from tensorflow.keras.layers import Input, Dropout, Concatenate\n","from tensorflow.keras.layers import LeakyReLU\n","from tensorflow.keras.layers import UpSampling2D, Conv2D\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.optimizers import Adam"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"mNa37SULsXm-","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597555338012,"user_tz":-540,"elapsed":561,"user":{"displayName":"Noboru Koike","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggp8njUb4jc54JrzfM5cQBkfiCdlz6nY17y8-1szg=s64","userId":"05156582812995850159"}}},"source":["import matplotlib.pyplot as plt\n","import numpy as np\n","import pandas as pd\n","import datetime\n","import os"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"knAJGu-csZ-g","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597555339493,"user_tz":-540,"elapsed":517,"user":{"displayName":"Noboru Koike","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggp8njUb4jc54JrzfM5cQBkfiCdlz6nY17y8-1szg=s64","userId":"05156582812995850159"}}},"source":["from glob import glob\n","import cv2\n","from matplotlib.pyplot import imread"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"fIdTxQKPsb0r","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597555340817,"user_tz":-540,"elapsed":490,"user":{"displayName":"Noboru Koike","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggp8njUb4jc54JrzfM5cQBkfiCdlz6nY17y8-1szg=s64","userId":"05156582812995850159"}}},"source":["DATA_DIR_PATH = '/content/drive/My Drive/kikagaku/novelgan/data'\n","\n","OUTPUT_DIR_PATH = os.path.join(DATA_DIR_PATH, '12_out')"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"Z4aFC8oHsgwu","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597555343194,"user_tz":-540,"elapsed":730,"user":{"displayName":"Noboru Koike","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggp8njUb4jc54JrzfM5cQBkfiCdlz6nY17y8-1szg=s64","userId":"05156582812995850159"}}},"source":["#os.makedirs(os.path.join(DATA_DIR_PATH, 'datasets'), exist_ok=True)\n","\n","os.makedirs(os.path.join(OUTPUT_DIR_PATH, 'images'), exist_ok=True)\n","os.makedirs(os.path.join(OUTPUT_DIR_PATH, 'saved_models'), exist_ok=True)"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"ppAnPzoIsl6z","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597555344713,"user_tz":-540,"elapsed":844,"user":{"displayName":"Noboru Koike","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggp8njUb4jc54JrzfM5cQBkfiCdlz6nY17y8-1szg=s64","userId":"05156582812995850159"}}},"source":["class DataLoader():\n","    def __init__(self, dataset_name, img_res=(256, 256)):\n","        self.dataset_name = dataset_name\n","        self.img_res = img_res\n","        self.datasets_path = os.path.join(DATA_DIR_PATH, 'datasets')\n","\n","    def load_data(self, domain, batch_size=1, is_testing=False):\n","        data_type = \"train%s\" % domain if not is_testing else \"test%s\" % domain\n","        #path = glob('./datasets/%s/%s/*' % (self.dataset_name, data_type))\n","        path = glob(os.path.join(self.datasets_path, self.dataset_name, data_type, '*'))\n","\n","        batch_images = np.random.choice(path, size=batch_size)\n","\n","        imgs = []\n","        for img_path in batch_images:\n","            img = self.imread(img_path)\n","            if not is_testing:\n","                #img = scipy.misc.imresize(img, self.img_res)\n","                img = cv2.resize(img, self.img_res)\n","\n","                if np.random.random() > 0.5:\n","                    img = np.fliplr(img)\n","            else:\n","                #img = scipy.misc.imresize(img, self.img_res)\n","                img = cv2.resize(img, self.img_res)\n","            imgs.append(img)\n","\n","        imgs = np.array(imgs)/127.5 - 1.\n","\n","        return imgs\n","\n","    def load_batch(self, batch_size=1, is_testing=False):\n","        data_type = \"train\" if not is_testing else \"val\"\n","        #path_A = glob('./datasets/%s/%sA/*' % (self.dataset_name, data_type))\n","        #path_B = glob('./datasets/%s/%sB/*' % (self.dataset_name, data_type))\n","        path_A = glob(os.path.join(self.datasets_path, self.dataset_name, '{}A'.format(data_type), '*'))\n","        path_B = glob(os.path.join(self.datasets_path, self.dataset_name, '{}B'.format(data_type), '*'))\n","\n","        self.n_batches = int(min(len(path_A), len(path_B)) / batch_size)\n","        total_samples = self.n_batches * batch_size\n","\n","        # Sample n_batches * batch_size from each path list so that model sees all\n","        # samples from both domains\n","        path_A = np.random.choice(path_A, total_samples, replace=False)\n","        path_B = np.random.choice(path_B, total_samples, replace=False)\n","\n","        #for i in range(self.n_batches-1):\n","        for i in range(self.n_batches):\n","            batch_A = path_A[i*batch_size:(i+1)*batch_size]\n","            batch_B = path_B[i*batch_size:(i+1)*batch_size]\n","            imgs_A, imgs_B = [], []\n","\n","            for img_A, img_B in zip(batch_A, batch_B):\n","                img_A = self.imread(img_A)\n","                img_B = self.imread(img_B)\n","\n","                #img_A = scipy.misc.imresize(img_A, self.img_res)\n","                img_A = cv2.resize(img_A, self.img_res)\n","                #img_B = scipy.misc.imresize(img_B, self.img_res)\n","                img_B = cv2.resize(img_B, self.img_res)\n","\n","                if not is_testing and np.random.random() > 0.5:\n","                    img_A = np.fliplr(img_A)\n","                    img_B = np.fliplr(img_B)\n","\n","                imgs_A.append(img_A)\n","                imgs_B.append(img_B)\n","\n","            imgs_A = np.array(imgs_A)/127.5 - 1.\n","            imgs_B = np.array(imgs_B)/127.5 - 1.\n","\n","            yield imgs_A, imgs_B\n","\n","    def load_img(self, path):\n","        img = self.imread(path)\n","        #img = scipy.misc.imresize(img, self.img_res)\n","        img = cv2.resize(img, self.img_res)\n","        img = img/127.5 - 1.\n","        return img[np.newaxis, :, :, :]\n","\n","    def imread(self, path):\n","        #return scipy.misc.imread(path, mode='RGB').astype(np.float)\n","        return imread(path).astype(np.float)"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"x86W1mhwspDR","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597555346438,"user_tz":-540,"elapsed":772,"user":{"displayName":"Noboru Koike","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggp8njUb4jc54JrzfM5cQBkfiCdlz6nY17y8-1szg=s64","userId":"05156582812995850159"}}},"source":["IMG_ROWS = 256\n","IMG_COLS = 256\n","\n","data_loader = DataLoader('vangogh2novel', img_res=(IMG_ROWS, IMG_COLS))"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"SvahgPums0Zr","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597555350840,"user_tz":-540,"elapsed":1481,"user":{"displayName":"Noboru Koike","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggp8njUb4jc54JrzfM5cQBkfiCdlz6nY17y8-1szg=s64","userId":"05156582812995850159"}}},"source":["class CycleGAN:\n","    def __init__(self):\n","        self.history = pd.DataFrame({}, columns=[\n","            'epoch', 'epochs', 'batch_idx', 'batch_num', 'd_loss', 'acc', 'g_loss',\n","            'adv', 'recon', 'id', 'elapsed_time'])\n","\n","        self.img_save_dir = os.path.join(OUTPUT_DIR_PATH, 'images')\n","        self.model_save_dir = os.path.join(OUTPUT_DIR_PATH, 'saved_models')\n","        self.combined_name = 'combined_model'\n","        self.g_AB_name = 'g_AB_model'\n","        self.g_BA_name = 'g_BA_model'\n","\n","        self.train_cnt = 0\n","\n","        # Input shape\n","        self.img_rows = IMG_ROWS\n","        self.img_cols = IMG_COLS\n","        self.channels = 3\n","        self.img_shape = (self.img_rows, self.img_cols, self.channels)\n","\n","        self.d_A = None\n","        self.d_B = None\n","        self.g_AB = None\n","        self.g_BA = None\n","        self.combined = None\n","\n","    def init(self, data_loader=None):\n","        # Configure data loader\n","        #self.dataset_name = 'apple2orange'\n","        #self.data_loader = DataLoader(dataset_name=self.dataset_name,\n","        #                              img_res=(self.img_rows, self.img_cols))\n","        if data_loader:\n","            self.data_loader = data_loader\n","            self.dataset_name = self.data_loader.dataset_name \n","\n","        # Calculate output shape of D (PatchGAN)\n","        patch = int(self.img_rows / 2**4)\n","        self.disc_patch = (patch, patch, 1)\n","\n","        # Number of filters in the first layer of G and D\n","        #self.gf = 32 # U-Net, 128\n","        self.gf = 64\n","        self.df = 64\n","\n","        # Loss weights\n","        self.lambda_cycle = 10.0                    # Cycle-consistency loss\n","        self.lambda_id = 0.1 * self.lambda_cycle    # Identity loss\n","\n","        optimizer = Adam(0.0002, 0.5)\n","\n","        # Build and compile the discriminators\n","        self.d_A = self.build_discriminator()\n","        self.d_B = self.build_discriminator()\n","        self.d_A.compile(loss='mse',\n","                         optimizer=optimizer,\n","                         metrics=['accuracy'])\n","        self.d_B.compile(loss='mse',\n","                         optimizer=optimizer,\n","                         metrics=['accuracy'])\n","\n","        # Build the generators\n","        self.g_AB = self.build_generator()\n","        self.g_BA = self.build_generator()\n","\n","        # Input images from both domains\n","        img_A = Input(shape=self.img_shape)\n","        img_B = Input(shape=self.img_shape)\n","\n","        # Translate images to the other domain\n","        fake_B = self.g_AB(img_A)\n","        fake_A = self.g_BA(img_B)\n","\n","        # Translate images back to original domain\n","        reconstr_A = self.g_BA(fake_B)\n","        reconstr_B = self.g_AB(fake_A)\n","\n","        # Identity mapping of images\n","        img_A_id = self.g_BA(img_A)\n","        img_B_id = self.g_AB(img_B)\n","\n","        # For the combined model we will only train the generators\n","        self.d_A.trainable = False\n","        self.d_B.trainable = False\n","\n","        # Discriminators determines validity of translated images\n","        valid_A = self.d_A(fake_A)\n","        valid_B = self.d_B(fake_B)\n","\n","        # Combined model trains generators to fool discriminators\n","        self.combined = Model(inputs=[img_A, img_B],\n","                              outputs=[valid_A, valid_B,\n","                                       reconstr_A, reconstr_B,\n","                                       img_A_id, img_B_id ])\n","        self.combined.compile(loss=['mse', 'mse',\n","                                    'mae', 'mae',\n","                                    'mae', 'mae'],\n","                              loss_weights=[1, 1,\n","                                            self.lambda_cycle, self.lambda_cycle,\n","                                            self.lambda_id, self.lambda_id ],\n","                              optimizer=optimizer)\n","\n","    def build_generator(self):\n","        \"\"\"U-Net Generator\"\"\"\n","\n","        def conv2d(layer_input, filters, f_size=4):\n","            \"\"\"Layers used during downsampling\"\"\"\n","            d = Conv2D(filters, kernel_size=f_size, strides=2, padding='same')(layer_input)\n","            d = LeakyReLU(alpha=0.2)(d)\n","            d = InstanceNormalization()(d)\n","            return d\n","\n","        def deconv2d(layer_input, skip_input, filters, f_size=4, dropout_rate=0):\n","            \"\"\"Layers used during upsampling\"\"\"\n","            u = UpSampling2D(size=2)(layer_input)\n","            u = Conv2D(filters, kernel_size=f_size, strides=1, padding='same', activation='relu')(u)\n","            if dropout_rate:\n","                u = Dropout(dropout_rate)(u)\n","            u = InstanceNormalization()(u)\n","            u = Concatenate()([u, skip_input])\n","            return u\n","\n","        # Image input\n","        d0 = Input(shape=self.img_shape)\n","\n","        # U-Net, 12\n","        ## Downsampling\n","        #d1 = conv2d(d0, self.gf)\n","        #d2 = conv2d(d1, self.gf*2)\n","        #d3 = conv2d(d2, self.gf*4)\n","        #d4 = conv2d(d3, self.gf*8)\n","        #\n","        ## Upsampling\n","        #u1 = deconv2d(d4, d3, self.gf*4)\n","        #u2 = deconv2d(u1, d2, self.gf*2)\n","        #u3 = deconv2d(u2, d1, self.gf)\n","        #\n","        #u4 = UpSampling2D(size=2)(u3)\n","        #output_img = Conv2D(self.channels, kernel_size=4, strides=1, padding='same', activation='tanh')(u4)\n","\n","        # Downsampling\n","        d1 = conv2d(d0, self.gf)\n","        d2 = conv2d(d1, self.gf*2)\n","        d3 = conv2d(d2, self.gf*4)\n","        d4 = conv2d(d3, self.gf*8)\n","        d5 = conv2d(d4, self.gf*8)\n","        d6 = conv2d(d5, self.gf*8)\n","        d7 = conv2d(d6, self.gf*8)\n","\n","        # Upsampling\n","        u1 = deconv2d(d7, d6, self.gf*8)\n","        u2 = deconv2d(u1, d5, self.gf*8)\n","        u3 = deconv2d(u2, d4, self.gf*8)\n","        u4 = deconv2d(u3, d3, self.gf*4)\n","        u5 = deconv2d(u4, d2, self.gf*2)\n","        u6 = deconv2d(u5, d1, self.gf)\n","\n","        u7 = UpSampling2D(size=2)(u6)\n","        output_img = Conv2D(self.channels, kernel_size=4, strides=1, padding='same', activation='tanh')(u7)\n","\n","        return Model(d0, output_img)\n","\n","    def build_discriminator(self):\n","\n","        def d_layer(layer_input, filters, f_size=4, normalization=True):\n","            \"\"\"Discriminator layer\"\"\"\n","            d = Conv2D(filters, kernel_size=f_size, strides=2, padding='same')(layer_input)\n","            d = LeakyReLU(alpha=0.2)(d)\n","            if normalization:\n","                d = InstanceNormalization()(d)\n","            return d\n","\n","        img = Input(shape=self.img_shape)\n","\n","        d1 = d_layer(img, self.df, normalization=False)\n","        d2 = d_layer(d1, self.df*2)\n","        d3 = d_layer(d2, self.df*4)\n","        d4 = d_layer(d3, self.df*8)\n","\n","        validity = Conv2D(1, kernel_size=4, strides=1, padding='same')(d4)\n","\n","        return Model(img, validity)\n","\n","    def train(self, epochs, batch_size=1, sample_interval=-1, save_interval=-1):\n","        self.train_cnt += 1\n","\n","        print(datetime.datetime.now().isoformat(), 'Start', self.train_cnt)\n","\n","        start_time = datetime.datetime.now()\n","\n","        # Adversarial loss ground truths\n","        valid = np.ones((batch_size,) + self.disc_patch)\n","        fake = np.zeros((batch_size,) + self.disc_patch)\n","\n","        step_cnt = 1\n","\n","        #for epoch in range(epochs):\n","        for epoch in range(1, epochs+1):\n","            #for batch_i, (imgs_A, imgs_B) in enumerate(self.data_loader.load_batch(batch_size)):\n","            for batch_i, (imgs_A, imgs_B) in enumerate(self.data_loader.load_batch(batch_size), 1):\n","\n","                # Translate images to opposite domain\n","                fake_B = self.g_AB.predict(imgs_A)\n","                fake_A = self.g_BA.predict(imgs_B)\n","\n","                # Train the discriminators (original images = real / translated = Fake)\n","                dA_loss_real = self.d_A.train_on_batch(imgs_A, valid)\n","                dA_loss_fake = self.d_A.train_on_batch(fake_A, fake)\n","                dA_loss = 0.5 * np.add(dA_loss_real, dA_loss_fake)\n","\n","                dB_loss_real = self.d_B.train_on_batch(imgs_B, valid)\n","                dB_loss_fake = self.d_B.train_on_batch(fake_B, fake)\n","                dB_loss = 0.5 * np.add(dB_loss_real, dB_loss_fake)\n","\n","                # Total disciminator loss\n","                d_loss = 0.5 * np.add(dA_loss, dB_loss)\n","\n","                # Train the generators\n","                g_loss = self.combined.train_on_batch([imgs_A, imgs_B],\n","                                                      [valid, valid,\n","                                                       imgs_A, imgs_B,\n","                                                       imgs_A, imgs_B])\n","\n","                elapsed_time = datetime.datetime.now() - start_time\n","\n","                # Plot the progress\n","                # print(\"[Epoch %d/%d] [Batch %d/%d] [D loss: %f, acc: %3d%%] [G loss: %05f, adv: %05f, recon: %05f, id: %05f] time: %s \" % (\n","                #     epoch, epochs,\n","                #     batch_i, self.data_loader.n_batches,\n","                #     d_loss[0], 100*d_loss[1],\n","                #     g_loss[0],\n","                #     np.mean(g_loss[1:3]),\n","                #     np.mean(g_loss[3:5]),\n","                #     np.mean(g_loss[5:6]),\n","                #     elapsed_time))\n","                self.history = self.history.append({\n","                    'epoch': epoch,\n","                    'epochs': epochs,\n","                    'batch_idx': batch_i,\n","                    'batch_num': self.data_loader.n_batches,\n","                    'd_loss': d_loss[0],\n","                    'acc': d_loss[1],\n","                    'g_loss': g_loss[0],\n","                    'adv': np.mean(g_loss[1:3]),\n","                    'recon': np.mean(g_loss[3:5]),\n","                    'id': np.mean(g_loss[5:6]),\n","                    'elapsed_time': elapsed_time\n","                }, ignore_index=True)\n","\n","                # If at save interval => save generated image samples\n","                #if sample_interval > 0 and batch_i % sample_interval == 0:\n","                if sample_interval > 0 and step_cnt % sample_interval == 0:\n","                    print(\"[Epoch %d/%d] [Batch %d/%d] [D loss: %f, acc: %3d%%] [G loss: %05f, adv: %05f, recon: %05f, id: %05f] time: %s \" % (\n","                        epoch, epochs,\n","                        batch_i, self.data_loader.n_batches,\n","                        d_loss[0], 100*d_loss[1],\n","                        g_loss[0],\n","                        np.mean(g_loss[1:3]),\n","                        np.mean(g_loss[3:5]),\n","                        np.mean(g_loss[5:6]),\n","                        elapsed_time))\n","\n","                    self.sample_images(epoch, batch_i)\n","\n","                #if save_interval > 0 and batch_i != 1 and (batch_i % save_interval) == 0:\n","                if save_interval > 0 and step_cnt % save_interval == 0:\n","                    file_suffix = '{}_{}_{}'.format(self.train_cnt, epoch, batch_i)\n","                    self.save_model_weights(self.combined, self.combined_name, file_suffix)\n","\n","                step_cnt += 1\n","\n","        print(datetime.datetime.now().isoformat(), 'End')\n","\n","    def generate_image_A(self, img):\n","        return self.g_AB.predict(img)\n","\n","    def generate_image_B(self, img):\n","        return self.g_BA.predict(img)\n","\n","    def sample_images(self, epoch, batch_i):\n","        dir_path = os.path.join(self.img_save_dir, self.dataset_name)\n","\n","        #os.makedirs('images/%s' % self.dataset_name, exist_ok=True)\n","        os.makedirs(dir_path, exist_ok=True)\n","\n","        r, c = 2, 3\n","\n","        imgs_A = self.data_loader.load_data(domain=\"A\", batch_size=1, is_testing=True)\n","        imgs_B = self.data_loader.load_data(domain=\"B\", batch_size=1, is_testing=True)\n","\n","        # Demo (for GIF)\n","        #imgs_A = self.data_loader.load_img('datasets/apple2orange/testA/n07740461_1541.jpg')\n","        #imgs_B = self.data_loader.load_img('datasets/apple2orange/testB/n07749192_4241.jpg')\n","\n","        # Translate images to the other domain\n","        fake_B = self.g_AB.predict(imgs_A)\n","        fake_A = self.g_BA.predict(imgs_B)\n","\n","        # Translate back to original domain\n","        reconstr_A = self.g_BA.predict(fake_B)\n","        reconstr_B = self.g_AB.predict(fake_A)\n","\n","        gen_imgs = np.concatenate([imgs_A, fake_B, reconstr_A, imgs_B, fake_A, reconstr_B])\n","\n","        # Rescale images 0 - 1\n","        gen_imgs = 0.5 * gen_imgs + 0.5\n","\n","        titles = ['Original', 'Translated', 'Reconstructed']\n","        fig, axs = plt.subplots(r, c)\n","        cnt = 0\n","\n","        for i in range(r):\n","            for j in range(c):\n","                axs[i, j].imshow(gen_imgs[cnt])\n","                axs[i, j].set_title(titles[j])\n","                axs[i, j].axis('off')\n","                cnt += 1\n","\n","        #fig.savefig(\"images/%s/%d_%d.png\" % (self.dataset_name, epoch, batch_i))\n","        file_path = os.path.join(dir_path, '{}_{}_{}.png'.format(self.train_cnt, epoch, batch_i))\n","        fig.savefig(file_path)\n","\n","        plt.close()\n","\n","    def plot_hisotry(self, columns=[]):\n","        if len(columns) == 0:\n","            columns = ['d_loss', 'g_loss']\n","            #columns = ['d_loss', 'acc', 'g_loss', 'adv', 'recon', 'id',]\n","        self.history[columns].plot()\n","\n","    def save_models(self, file_suffix=None):\n","        self.save_model_weights(self.combined, self.combined_name, file_suffix)\n","        #self.save_model_weights(self.g_AB, self.g_AB_name, file_suffix)\n","        #self.save_model_weights(self.g_BA, self.g_BA_name, file_suffix)\n","\n","    def save_model_weights(self, model, model_name, file_suffix=None):\n","        file_path = os.path.join(self.model_save_dir, self._create_h5_file_name(model_name, file_suffix))\n","        model.save_weights(file_path)\n","\n","        print('Model weights saved.', model_name)\n","\n","    def load_models(self, file_suffix=None):\n","        self.load_model_weights(self.combined_name, file_suffix)\n","        self.load_model_weights(self.g_AB_name, file_suffix)\n","        self.load_model_weights(self.g_BA_name, file_suffix)\n","\n","    def load_model_weights(self, model_name, file_suffix=None):\n","        model = None\n","\n","        if model_name == self.combined_name:\n","            model = self.combined\n","        elif model_name == self.g_AB_name:\n","            model = self.g_AB\n","        elif model_name == self.g_BA_name:\n","            model = self.g_BA\n","        else:\n","            print('Unsupported.', model_name)\n","            return\n","\n","        if not model:\n","            print('Not initialized.', model_name)\n","            return\n","\n","        file_path = os.path.join(self.model_save_dir, self._create_h5_file_name(model_name, file_suffix))\n","\n","        if not os.path.exists(file_path):\n","            print('File Not found.', model_name)\n","            return\n","\n","        model.load_weights(file_path)\n","\n","        print('Model weights loaded.', model_name)\n","\n","    def _create_h5_file_name(self, model_name, suffix=None):\n","        if suffix:\n","            return '{}_{}.h5'.format(model_name, suffix)\n","        else:\n","            return '{}.h5'.format(model_name)"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"5lusbTYOs_gW","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":66},"executionInfo":{"status":"ok","timestamp":1597556092128,"user_tz":-540,"elapsed":740021,"user":{"displayName":"Noboru Koike","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggp8njUb4jc54JrzfM5cQBkfiCdlz6nY17y8-1szg=s64","userId":"05156582812995850159"}},"outputId":"fe9420ac-f0ad-4bec-a4d8-a914fbf0570b"},"source":["gan = CycleGAN()\n","gan.init(data_loader=data_loader)\n","\n","# Image A Count: 400, BatchSize:8, 400/8=50\n","gan.train(epochs=1, batch_size=8, sample_interval=50, save_interval=50*5)\n","\n","gan.history.to_csv(os.path.join(OUTPUT_DIR_PATH, 'history.csv'))"],"execution_count":11,"outputs":[{"output_type":"stream","text":["2020-08-16T05:22:36.732382 Start 1\n","[Epoch 1/1] [Batch 50/50] [D loss: 0.435797, acc:  51%] [G loss: 8.194581, adv: 0.823967, recon: 0.296470, id: 0.291579] time: 0:12:05.777390 \n","2020-08-16T05:34:50.506692 End\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"t3LcgibYuCHF","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1597567144031,"user_tz":-540,"elapsed":10930458,"user":{"displayName":"Noboru Koike","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggp8njUb4jc54JrzfM5cQBkfiCdlz6nY17y8-1szg=s64","userId":"05156582812995850159"}},"outputId":"77278ea9-5217-44c8-8665-ffb9da2bbb52"},"source":["gan.train(epochs=100, batch_size=8, sample_interval=50, save_interval=50*20)\n","\n","gan.history.to_csv(os.path.join(OUTPUT_DIR_PATH, 'history.csv'))"],"execution_count":12,"outputs":[{"output_type":"stream","text":["2020-08-16T05:36:53.814080 Start 2\n","[Epoch 1/100] [Batch 50/50] [D loss: 0.286409, acc:  59%] [G loss: 7.346870, adv: 0.485989, recon: 0.288379, id: 0.272377] time: 0:05:32.173423 \n","[Epoch 2/100] [Batch 50/50] [D loss: 0.321098, acc:  56%] [G loss: 6.707238, adv: 0.485857, recon: 0.258804, id: 0.260124] time: 0:10:32.007153 \n","[Epoch 3/100] [Batch 50/50] [D loss: 0.289366, acc:  55%] [G loss: 6.163964, adv: 0.361450, recon: 0.245684, id: 0.252841] time: 0:15:04.411716 \n","[Epoch 4/100] [Batch 50/50] [D loss: 0.215972, acc:  66%] [G loss: 6.662675, adv: 0.400043, recon: 0.266664, id: 0.281498] time: 0:19:00.845544 \n","[Epoch 5/100] [Batch 50/50] [D loss: 0.260063, acc:  57%] [G loss: 6.524342, adv: 0.365059, recon: 0.261936, id: 0.286574] time: 0:22:29.206950 \n","[Epoch 6/100] [Batch 50/50] [D loss: 0.250907, acc:  58%] [G loss: 6.592806, adv: 0.357952, recon: 0.264811, id: 0.256565] time: 0:25:47.880331 \n","[Epoch 7/100] [Batch 50/50] [D loss: 0.235476, acc:  62%] [G loss: 5.227167, adv: 0.368774, recon: 0.200894, id: 0.250479] time: 0:28:41.339743 \n","[Epoch 8/100] [Batch 50/50] [D loss: 0.223544, acc:  64%] [G loss: 5.241267, adv: 0.400864, recon: 0.199233, id: 0.205449] time: 0:31:34.133948 \n","[Epoch 9/100] [Batch 50/50] [D loss: 0.253966, acc:  58%] [G loss: 4.991386, adv: 0.404351, recon: 0.186180, id: 0.206574] time: 0:34:23.753713 \n","[Epoch 10/100] [Batch 50/50] [D loss: 0.243868, acc:  62%] [G loss: 4.941341, adv: 0.466596, recon: 0.178580, id: 0.209073] time: 0:36:50.877894 \n","[Epoch 11/100] [Batch 50/50] [D loss: 0.221842, acc:  65%] [G loss: 5.652120, adv: 0.431886, recon: 0.214729, id: 0.225333] time: 0:39:08.698322 \n","[Epoch 12/100] [Batch 50/50] [D loss: 0.174939, acc:  74%] [G loss: 5.563455, adv: 0.491525, recon: 0.205302, id: 0.217957] time: 0:41:25.144374 \n","[Epoch 13/100] [Batch 50/50] [D loss: 0.195559, acc:  71%] [G loss: 5.975281, adv: 0.466543, recon: 0.225710, id: 0.204006] time: 0:43:31.806549 \n","[Epoch 14/100] [Batch 50/50] [D loss: 0.226085, acc:  67%] [G loss: 5.960188, adv: 0.599060, recon: 0.213649, id: 0.175749] time: 0:45:31.557849 \n","[Epoch 15/100] [Batch 50/50] [D loss: 0.191985, acc:  72%] [G loss: 5.875340, adv: 0.556885, recon: 0.212171, id: 0.260045] time: 0:47:27.146799 \n","[Epoch 16/100] [Batch 50/50] [D loss: 0.179920, acc:  73%] [G loss: 5.399565, adv: 0.602798, recon: 0.187663, id: 0.193844] time: 0:49:27.932844 \n","[Epoch 17/100] [Batch 50/50] [D loss: 0.191554, acc:  73%] [G loss: 5.289303, adv: 0.590284, recon: 0.183260, id: 0.230881] time: 0:51:31.428564 \n","[Epoch 18/100] [Batch 50/50] [D loss: 0.165684, acc:  77%] [G loss: 5.755711, adv: 0.600631, recon: 0.202736, id: 0.221089] time: 0:53:16.423678 \n","[Epoch 19/100] [Batch 50/50] [D loss: 0.151411, acc:  78%] [G loss: 5.298716, adv: 0.635393, recon: 0.179129, id: 0.201231] time: 0:54:57.854479 \n","[Epoch 20/100] [Batch 50/50] [D loss: 0.184093, acc:  75%] [G loss: 5.326183, adv: 0.629297, recon: 0.181329, id: 0.217190] time: 0:56:43.182465 \n","Model weights saved. combined_model\n","[Epoch 21/100] [Batch 50/50] [D loss: 0.151259, acc:  81%] [G loss: 5.725834, adv: 0.690661, recon: 0.194601, id: 0.217399] time: 0:58:24.840230 \n","[Epoch 22/100] [Batch 50/50] [D loss: 0.168754, acc:  75%] [G loss: 5.737332, adv: 0.760329, recon: 0.187704, id: 0.217656] time: 1:00:09.040847 \n","[Epoch 23/100] [Batch 50/50] [D loss: 0.119818, acc:  86%] [G loss: 5.297892, adv: 0.726056, recon: 0.171700, id: 0.204287] time: 1:01:48.598592 \n","[Epoch 24/100] [Batch 50/50] [D loss: 0.201992, acc:  67%] [G loss: 5.017727, adv: 0.587612, recon: 0.170961, id: 0.219046] time: 1:03:29.335678 \n","[Epoch 25/100] [Batch 50/50] [D loss: 0.160828, acc:  78%] [G loss: 5.406813, adv: 0.676680, recon: 0.179865, id: 0.216327] time: 1:05:11.361874 \n","[Epoch 26/100] [Batch 50/50] [D loss: 0.301438, acc:  77%] [G loss: 7.091761, adv: 0.845625, recon: 0.241872, id: 0.296483] time: 1:06:46.991021 \n","[Epoch 27/100] [Batch 50/50] [D loss: 0.124005, acc:  85%] [G loss: 5.842286, adv: 0.878949, recon: 0.183320, id: 0.204370] time: 1:08:22.666125 \n","[Epoch 28/100] [Batch 50/50] [D loss: 0.193504, acc:  73%] [G loss: 6.008918, adv: 0.703846, recon: 0.206976, id: 0.226962] time: 1:09:59.858711 \n","[Epoch 29/100] [Batch 50/50] [D loss: 0.243250, acc:  63%] [G loss: 4.839425, adv: 0.637522, recon: 0.158404, id: 0.174119] time: 1:11:35.143181 \n","[Epoch 30/100] [Batch 50/50] [D loss: 0.175160, acc:  74%] [G loss: 6.273282, adv: 0.806889, recon: 0.209885, id: 0.235044] time: 1:13:09.029492 \n","[Epoch 31/100] [Batch 50/50] [D loss: 0.240725, acc:  72%] [G loss: 5.776585, adv: 0.913480, recon: 0.176382, id: 0.192179] time: 1:14:44.148095 \n","[Epoch 32/100] [Batch 50/50] [D loss: 0.146568, acc:  81%] [G loss: 5.989667, adv: 0.747639, recon: 0.200403, id: 0.237840] time: 1:16:18.777694 \n","[Epoch 33/100] [Batch 50/50] [D loss: 0.102124, acc:  89%] [G loss: 6.367410, adv: 0.831470, recon: 0.210796, id: 0.223577] time: 1:17:52.754446 \n","[Epoch 34/100] [Batch 50/50] [D loss: 0.132890, acc:  85%] [G loss: 6.976685, adv: 0.889034, recon: 0.234779, id: 0.222949] time: 1:19:29.656793 \n","[Epoch 35/100] [Batch 50/50] [D loss: 0.153055, acc:  79%] [G loss: 5.702674, adv: 0.768343, recon: 0.183795, id: 0.230062] time: 1:21:04.190052 \n","[Epoch 36/100] [Batch 50/50] [D loss: 0.152813, acc:  79%] [G loss: 6.110770, adv: 0.816174, recon: 0.201484, id: 0.233575] time: 1:22:38.540378 \n","[Epoch 37/100] [Batch 50/50] [D loss: 0.191678, acc:  76%] [G loss: 5.779660, adv: 0.909742, recon: 0.174620, id: 0.241717] time: 1:24:11.714663 \n","[Epoch 38/100] [Batch 50/50] [D loss: 0.205905, acc:  72%] [G loss: 6.018125, adv: 0.871171, recon: 0.191601, id: 0.191810] time: 1:25:45.705078 \n","[Epoch 39/100] [Batch 50/50] [D loss: 0.201936, acc:  72%] [G loss: 5.783863, adv: 0.831637, recon: 0.184389, id: 0.213290] time: 1:27:19.778398 \n","[Epoch 40/100] [Batch 50/50] [D loss: 0.109313, acc:  87%] [G loss: 6.205990, adv: 0.926128, recon: 0.195107, id: 0.213337] time: 1:28:53.846022 \n","Model weights saved. combined_model\n","[Epoch 41/100] [Batch 50/50] [D loss: 0.132838, acc:  84%] [G loss: 5.685891, adv: 0.815456, recon: 0.181143, id: 0.194061] time: 1:30:28.075178 \n","[Epoch 42/100] [Batch 50/50] [D loss: 0.136073, acc:  82%] [G loss: 6.672340, adv: 0.898829, recon: 0.218885, id: 0.241637] time: 1:32:00.627996 \n","[Epoch 43/100] [Batch 50/50] [D loss: 0.106679, acc:  89%] [G loss: 6.197222, adv: 0.970913, recon: 0.190583, id: 0.206869] time: 1:33:34.598397 \n","[Epoch 44/100] [Batch 50/50] [D loss: 0.132894, acc:  82%] [G loss: 5.931700, adv: 1.007104, recon: 0.173101, id: 0.224463] time: 1:35:08.091451 \n","[Epoch 45/100] [Batch 50/50] [D loss: 0.116621, acc:  86%] [G loss: 6.113387, adv: 0.949390, recon: 0.188725, id: 0.213246] time: 1:36:41.167276 \n","[Epoch 46/100] [Batch 50/50] [D loss: 0.078695, acc:  92%] [G loss: 6.631017, adv: 0.951843, recon: 0.212286, id: 0.228885] time: 1:38:14.676237 \n","[Epoch 47/100] [Batch 50/50] [D loss: 0.128422, acc:  84%] [G loss: 5.778159, adv: 0.928334, recon: 0.175605, id: 0.196697] time: 1:39:47.637856 \n","[Epoch 48/100] [Batch 50/50] [D loss: 0.096361, acc:  89%] [G loss: 5.942967, adv: 1.028454, recon: 0.173674, id: 0.202867] time: 1:41:20.392789 \n","[Epoch 49/100] [Batch 50/50] [D loss: 0.151861, acc:  80%] [G loss: 5.791228, adv: 1.016891, recon: 0.167123, id: 0.220958] time: 1:42:52.835183 \n","[Epoch 50/100] [Batch 50/50] [D loss: 0.093043, acc:  91%] [G loss: 6.354560, adv: 1.013341, recon: 0.192883, id: 0.244103] time: 1:44:26.845034 \n","[Epoch 51/100] [Batch 50/50] [D loss: 0.131025, acc:  85%] [G loss: 6.100430, adv: 0.998176, recon: 0.184472, id: 0.202277] time: 1:46:00.053931 \n","[Epoch 52/100] [Batch 50/50] [D loss: 0.065522, acc:  94%] [G loss: 6.327087, adv: 0.936128, recon: 0.199133, id: 0.216914] time: 1:47:31.961325 \n","[Epoch 53/100] [Batch 50/50] [D loss: 0.117688, acc:  84%] [G loss: 5.989183, adv: 0.960874, recon: 0.182537, id: 0.175227] time: 1:49:05.183589 \n","[Epoch 54/100] [Batch 50/50] [D loss: 0.160683, acc:  80%] [G loss: 6.114958, adv: 1.014641, recon: 0.183990, id: 0.207026] time: 1:50:39.394610 \n","[Epoch 55/100] [Batch 50/50] [D loss: 0.125887, acc:  85%] [G loss: 6.254474, adv: 0.996687, recon: 0.190934, id: 0.214942] time: 1:52:13.047212 \n","[Epoch 56/100] [Batch 50/50] [D loss: 0.099833, acc:  88%] [G loss: 6.307653, adv: 1.005321, recon: 0.193222, id: 0.224803] time: 1:53:46.097585 \n","[Epoch 57/100] [Batch 50/50] [D loss: 0.136547, acc:  84%] [G loss: 6.283781, adv: 1.126008, recon: 0.181171, id: 0.195791] time: 1:55:18.060481 \n","[Epoch 58/100] [Batch 50/50] [D loss: 0.082665, acc:  93%] [G loss: 6.236833, adv: 1.104413, recon: 0.180765, id: 0.204339] time: 1:56:50.745562 \n","[Epoch 59/100] [Batch 50/50] [D loss: 0.078314, acc:  93%] [G loss: 5.983588, adv: 1.047556, recon: 0.173044, id: 0.202365] time: 1:58:24.026476 \n","[Epoch 60/100] [Batch 50/50] [D loss: 0.074504, acc:  92%] [G loss: 6.166867, adv: 1.068585, recon: 0.177958, id: 0.208953] time: 1:59:57.236479 \n","Model weights saved. combined_model\n","[Epoch 61/100] [Batch 50/50] [D loss: 0.089150, acc:  91%] [G loss: 5.826879, adv: 1.005009, recon: 0.171405, id: 0.193785] time: 2:01:32.968801 \n","[Epoch 62/100] [Batch 50/50] [D loss: 0.067310, acc:  95%] [G loss: 6.361424, adv: 1.088833, recon: 0.187233, id: 0.190453] time: 2:03:06.520657 \n","[Epoch 63/100] [Batch 50/50] [D loss: 0.221485, acc:  71%] [G loss: 5.363235, adv: 0.780503, recon: 0.170234, id: 0.189551] time: 2:04:39.560543 \n","[Epoch 64/100] [Batch 50/50] [D loss: 0.155171, acc:  78%] [G loss: 4.899290, adv: 0.791324, recon: 0.146692, id: 0.189774] time: 2:06:12.466810 \n","[Epoch 65/100] [Batch 50/50] [D loss: 0.143714, acc:  80%] [G loss: 5.006691, adv: 0.787499, recon: 0.152401, id: 0.183771] time: 2:07:45.388193 \n","[Epoch 66/100] [Batch 50/50] [D loss: 0.121760, acc:  85%] [G loss: 5.135541, adv: 0.866657, recon: 0.151078, id: 0.180741] time: 2:09:17.960393 \n","[Epoch 67/100] [Batch 50/50] [D loss: 0.105131, acc:  88%] [G loss: 5.344846, adv: 0.874107, recon: 0.159065, id: 0.193663] time: 2:10:52.016024 \n","[Epoch 68/100] [Batch 50/50] [D loss: 0.183812, acc:  83%] [G loss: 5.428818, adv: 0.939910, recon: 0.156394, id: 0.187258] time: 2:12:25.770902 \n","[Epoch 69/100] [Batch 50/50] [D loss: 0.104622, acc:  88%] [G loss: 5.672489, adv: 1.016036, recon: 0.162031, id: 0.185521] time: 2:13:59.345834 \n","[Epoch 70/100] [Batch 50/50] [D loss: 0.080172, acc:  93%] [G loss: 5.713738, adv: 0.998525, recon: 0.165683, id: 0.186386] time: 2:15:32.839458 \n","[Epoch 71/100] [Batch 50/50] [D loss: 0.072592, acc:  93%] [G loss: 5.778426, adv: 1.114533, recon: 0.157182, id: 0.205567] time: 2:17:05.405970 \n","[Epoch 72/100] [Batch 50/50] [D loss: 0.063784, acc:  97%] [G loss: 5.555772, adv: 0.994358, recon: 0.158401, id: 0.171428] time: 2:18:38.962749 \n","[Epoch 73/100] [Batch 50/50] [D loss: 0.036990, acc:  98%] [G loss: 5.637615, adv: 1.057881, recon: 0.156847, id: 0.187628] time: 2:20:11.849250 \n","[Epoch 74/100] [Batch 50/50] [D loss: 0.224717, acc:  73%] [G loss: 6.056908, adv: 1.199311, recon: 0.163748, id: 0.189684] time: 2:21:45.334487 \n","[Epoch 75/100] [Batch 50/50] [D loss: 0.169798, acc:  73%] [G loss: 5.027241, adv: 0.633338, recon: 0.167113, id: 0.193831] time: 2:23:18.064893 \n","[Epoch 76/100] [Batch 50/50] [D loss: 0.136640, acc:  81%] [G loss: 5.753989, adv: 0.689732, recon: 0.197009, id: 0.198381] time: 2:24:50.896615 \n","[Epoch 77/100] [Batch 50/50] [D loss: 0.125570, acc:  82%] [G loss: 4.521385, adv: 0.673344, recon: 0.139773, id: 0.179936] time: 2:26:24.362157 \n","[Epoch 78/100] [Batch 50/50] [D loss: 0.138695, acc:  78%] [G loss: 4.943293, adv: 0.731371, recon: 0.153421, id: 0.217996] time: 2:27:56.934488 \n","[Epoch 79/100] [Batch 50/50] [D loss: 0.149308, acc:  75%] [G loss: 4.748581, adv: 0.687278, recon: 0.148816, id: 0.192313] time: 2:29:30.653130 \n","[Epoch 80/100] [Batch 50/50] [D loss: 0.122772, acc:  83%] [G loss: 5.002302, adv: 0.753192, recon: 0.155660, id: 0.181946] time: 2:31:03.564989 \n","Model weights saved. combined_model\n","[Epoch 81/100] [Batch 50/50] [D loss: 0.098979, acc:  87%] [G loss: 5.170589, adv: 0.743831, recon: 0.163426, id: 0.185807] time: 2:32:38.084484 \n","[Epoch 82/100] [Batch 50/50] [D loss: 0.112471, acc:  86%] [G loss: 5.239220, adv: 0.847011, recon: 0.157061, id: 0.183176] time: 2:34:11.231903 \n","[Epoch 83/100] [Batch 50/50] [D loss: 0.096235, acc:  87%] [G loss: 4.855966, adv: 0.840435, recon: 0.140143, id: 0.182089] time: 2:35:44.729565 \n","[Epoch 84/100] [Batch 50/50] [D loss: 0.067741, acc:  94%] [G loss: 5.091462, adv: 0.900831, recon: 0.145043, id: 0.175723] time: 2:37:17.228830 \n","[Epoch 85/100] [Batch 50/50] [D loss: 0.111098, acc:  84%] [G loss: 5.507564, adv: 0.949166, recon: 0.160599, id: 0.186876] time: 2:38:50.748920 \n","[Epoch 86/100] [Batch 50/50] [D loss: 0.057555, acc:  96%] [G loss: 5.434843, adv: 0.919627, recon: 0.159858, id: 0.190383] time: 2:40:23.867488 \n","[Epoch 87/100] [Batch 50/50] [D loss: 0.176556, acc:  82%] [G loss: 5.376940, adv: 1.031946, recon: 0.147872, id: 0.182710] time: 2:41:57.158271 \n","[Epoch 88/100] [Batch 50/50] [D loss: 0.068210, acc:  95%] [G loss: 5.414564, adv: 1.043937, recon: 0.148770, id: 0.158370] time: 2:43:30.210625 \n","[Epoch 89/100] [Batch 50/50] [D loss: 0.100308, acc:  90%] [G loss: 6.237132, adv: 1.100771, recon: 0.179269, id: 0.240907] time: 2:45:03.885036 \n","[Epoch 90/100] [Batch 50/50] [D loss: 0.043627, acc:  98%] [G loss: 5.458602, adv: 0.981157, recon: 0.155861, id: 0.190639] time: 2:46:37.103862 \n","[Epoch 91/100] [Batch 50/50] [D loss: 0.103705, acc:  86%] [G loss: 5.694410, adv: 1.143934, recon: 0.151834, id: 0.177794] time: 2:48:10.359272 \n","[Epoch 92/100] [Batch 50/50] [D loss: 0.050255, acc:  97%] [G loss: 5.597657, adv: 1.077785, recon: 0.153091, id: 0.230894] time: 2:49:43.544130 \n","[Epoch 93/100] [Batch 50/50] [D loss: 0.047005, acc:  97%] [G loss: 6.034994, adv: 1.187534, recon: 0.162522, id: 0.189844] time: 2:51:16.409410 \n","[Epoch 94/100] [Batch 50/50] [D loss: 0.053380, acc:  96%] [G loss: 5.725592, adv: 1.021136, recon: 0.164559, id: 0.182304] time: 2:52:48.328443 \n","[Epoch 95/100] [Batch 50/50] [D loss: 0.054410, acc:  96%] [G loss: 5.832649, adv: 1.111560, recon: 0.160705, id: 0.198206] time: 2:54:21.158981 \n","[Epoch 96/100] [Batch 50/50] [D loss: 0.079492, acc:  95%] [G loss: 5.850822, adv: 1.071710, recon: 0.165218, id: 0.198327] time: 2:55:54.496584 \n","[Epoch 97/100] [Batch 50/50] [D loss: 0.048620, acc:  98%] [G loss: 6.065420, adv: 1.092860, recon: 0.174483, id: 0.177209] time: 2:57:27.584779 \n","[Epoch 98/100] [Batch 50/50] [D loss: 0.064235, acc:  94%] [G loss: 5.304384, adv: 1.057246, recon: 0.140414, id: 0.190710] time: 2:59:01.764009 \n","[Epoch 99/100] [Batch 50/50] [D loss: 0.068686, acc:  95%] [G loss: 5.589157, adv: 1.004596, recon: 0.162114, id: 0.150985] time: 3:00:34.279184 \n","[Epoch 100/100] [Batch 50/50] [D loss: 0.061065, acc:  95%] [G loss: 5.731803, adv: 1.139095, recon: 0.152561, id: 0.214081] time: 3:02:06.779703 \n","Model weights saved. combined_model\n","2020-08-16T08:39:03.134966 End\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"2_AIESZGxUb-","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1597596010060,"user_tz":-540,"elapsed":24060433,"user":{"displayName":"Noboru Koike","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggp8njUb4jc54JrzfM5cQBkfiCdlz6nY17y8-1szg=s64","userId":"05156582812995850159"}},"outputId":"8d967a16-f9e0-4801-e497-f8aed189d92e"},"source":["gan.train(epochs=300, batch_size=8, sample_interval=50, save_interval=50*20)\n","\n","gan.history.to_csv(os.path.join(OUTPUT_DIR_PATH, 'history_2.csv'))"],"execution_count":13,"outputs":[{"output_type":"stream","text":["2020-08-16T08:57:44.955430 Start 3\n","[Epoch 1/300] [Batch 50/50] [D loss: 0.099180, acc:  91%] [G loss: 5.666148, adv: 1.081549, recon: 0.155222, id: 0.185912] time: 0:01:31.458585 \n","[Epoch 2/300] [Batch 50/50] [D loss: 0.063804, acc:  94%] [G loss: 5.605021, adv: 1.100965, recon: 0.152670, id: 0.183680] time: 0:03:04.651748 \n","[Epoch 3/300] [Batch 50/50] [D loss: 0.068072, acc:  92%] [G loss: 5.505540, adv: 0.943051, recon: 0.161693, id: 0.187742] time: 0:04:37.191007 \n","[Epoch 4/300] [Batch 50/50] [D loss: 0.047978, acc:  97%] [G loss: 5.795878, adv: 1.010846, recon: 0.169166, id: 0.173683] time: 0:06:09.683758 \n","[Epoch 5/300] [Batch 50/50] [D loss: 0.072121, acc:  95%] [G loss: 5.729924, adv: 1.171246, recon: 0.151096, id: 0.178314] time: 0:07:42.113515 \n","[Epoch 6/300] [Batch 50/50] [D loss: 0.036677, acc:  98%] [G loss: 5.457141, adv: 0.914210, recon: 0.161571, id: 0.187569] time: 0:09:15.251158 \n","[Epoch 7/300] [Batch 50/50] [D loss: 0.033281, acc:  99%] [G loss: 5.483163, adv: 1.042898, recon: 0.151279, id: 0.189108] time: 0:10:48.004387 \n","[Epoch 8/300] [Batch 50/50] [D loss: 0.039991, acc:  99%] [G loss: 5.606358, adv: 1.064751, recon: 0.152870, id: 0.207095] time: 0:12:20.150300 \n","[Epoch 9/300] [Batch 50/50] [D loss: 0.059252, acc:  97%] [G loss: 5.831630, adv: 1.055380, recon: 0.166399, id: 0.180863] time: 0:13:52.888863 \n","[Epoch 10/300] [Batch 50/50] [D loss: 0.038737, acc:  97%] [G loss: 5.512125, adv: 1.120446, recon: 0.144517, id: 0.198480] time: 0:15:26.498684 \n","[Epoch 11/300] [Batch 50/50] [D loss: 0.128056, acc:  86%] [G loss: 5.777502, adv: 1.252288, recon: 0.146573, id: 0.163421] time: 0:16:59.582810 \n","[Epoch 12/300] [Batch 50/50] [D loss: 0.037465, acc:  98%] [G loss: 5.677720, adv: 1.055874, recon: 0.157738, id: 0.198993] time: 0:18:32.555267 \n","[Epoch 13/300] [Batch 50/50] [D loss: 0.137087, acc:  77%] [G loss: 4.891655, adv: 0.656278, recon: 0.159304, id: 0.200444] time: 0:20:04.976158 \n","[Epoch 14/300] [Batch 50/50] [D loss: 0.142426, acc:  74%] [G loss: 4.674914, adv: 0.676948, recon: 0.147236, id: 0.186227] time: 0:21:38.542399 \n","[Epoch 15/300] [Batch 50/50] [D loss: 0.139428, acc:  77%] [G loss: 4.627629, adv: 0.674784, recon: 0.146056, id: 0.170580] time: 0:23:11.315480 \n","[Epoch 16/300] [Batch 50/50] [D loss: 0.148413, acc:  77%] [G loss: 4.818165, adv: 0.655865, recon: 0.157357, id: 0.156342] time: 0:24:44.995646 \n","[Epoch 17/300] [Batch 50/50] [D loss: 0.146545, acc:  76%] [G loss: 4.836526, adv: 0.792525, recon: 0.144636, id: 0.178811] time: 0:26:17.799834 \n","[Epoch 18/300] [Batch 50/50] [D loss: 0.114843, acc:  84%] [G loss: 4.640097, adv: 0.787364, recon: 0.134080, id: 0.186432] time: 0:27:50.618688 \n","[Epoch 19/300] [Batch 50/50] [D loss: 0.987707, acc:  55%] [G loss: 10.821072, adv: 3.690825, recon: 0.153419, id: 0.178261] time: 0:29:24.281397 \n","[Epoch 20/300] [Batch 50/50] [D loss: 0.215376, acc:  65%] [G loss: 4.247670, adv: 0.652764, recon: 0.130263, id: 0.151200] time: 0:30:57.588700 \n","Model weights saved. combined_model\n","[Epoch 21/300] [Batch 50/50] [D loss: 0.130066, acc:  83%] [G loss: 4.765492, adv: 0.766716, recon: 0.143139, id: 0.178360] time: 0:32:34.075916 \n","[Epoch 22/300] [Batch 50/50] [D loss: 0.163548, acc:  77%] [G loss: 4.410688, adv: 0.723996, recon: 0.131039, id: 0.180579] time: 0:34:07.352676 \n","[Epoch 23/300] [Batch 50/50] [D loss: 0.078412, acc:  92%] [G loss: 5.019096, adv: 0.874678, recon: 0.145093, id: 0.177952] time: 0:35:40.073735 \n","[Epoch 24/300] [Batch 50/50] [D loss: 0.131657, acc:  85%] [G loss: 5.035029, adv: 0.973680, recon: 0.137802, id: 0.160244] time: 0:37:13.198515 \n","[Epoch 25/300] [Batch 50/50] [D loss: 0.050215, acc:  97%] [G loss: 4.876356, adv: 0.914897, recon: 0.134730, id: 0.176561] time: 0:38:44.886826 \n","[Epoch 26/300] [Batch 50/50] [D loss: 0.097211, acc:  90%] [G loss: 5.557606, adv: 1.095100, recon: 0.150879, id: 0.190851] time: 0:40:16.830255 \n","[Epoch 27/300] [Batch 50/50] [D loss: 0.085038, acc:  92%] [G loss: 5.419810, adv: 0.938063, recon: 0.159128, id: 0.194463] time: 0:41:49.287150 \n","[Epoch 28/300] [Batch 50/50] [D loss: 0.072119, acc:  94%] [G loss: 5.354463, adv: 1.067408, recon: 0.144350, id: 0.154185] time: 0:43:21.852336 \n","[Epoch 29/300] [Batch 50/50] [D loss: 0.077728, acc:  94%] [G loss: 5.401137, adv: 1.074384, recon: 0.146238, id: 0.165122] time: 0:44:54.791962 \n","[Epoch 30/300] [Batch 50/50] [D loss: 0.029600, acc:  99%] [G loss: 5.571338, adv: 0.989425, recon: 0.160398, id: 0.193524] time: 0:46:27.809069 \n","[Epoch 31/300] [Batch 50/50] [D loss: 0.045573, acc:  97%] [G loss: 5.426534, adv: 1.053094, recon: 0.147784, id: 0.177653] time: 0:48:00.639969 \n","[Epoch 32/300] [Batch 50/50] [D loss: 0.040482, acc:  97%] [G loss: 5.559355, adv: 1.114499, recon: 0.147687, id: 0.177276] time: 0:49:33.782359 \n","[Epoch 33/300] [Batch 50/50] [D loss: 0.041778, acc:  98%] [G loss: 5.404185, adv: 1.065637, recon: 0.146668, id: 0.156029] time: 0:51:06.611166 \n","[Epoch 34/300] [Batch 50/50] [D loss: 0.028170, acc:  99%] [G loss: 5.422823, adv: 1.076322, recon: 0.145573, id: 0.184663] time: 0:52:39.080182 \n","[Epoch 35/300] [Batch 50/50] [D loss: 0.037521, acc:  98%] [G loss: 5.560259, adv: 1.038792, recon: 0.156821, id: 0.169603] time: 0:54:11.064861 \n","[Epoch 36/300] [Batch 50/50] [D loss: 0.029202, acc:  99%] [G loss: 5.496967, adv: 1.018838, recon: 0.155769, id: 0.165776] time: 0:55:43.836882 \n","[Epoch 37/300] [Batch 50/50] [D loss: 0.036795, acc:  98%] [G loss: 5.158459, adv: 0.923087, recon: 0.148273, id: 0.182563] time: 0:57:15.847568 \n","[Epoch 38/300] [Batch 50/50] [D loss: 0.030312, acc:  99%] [G loss: 5.693715, adv: 1.094908, recon: 0.157726, id: 0.167235] time: 0:58:48.199155 \n","[Epoch 39/300] [Batch 50/50] [D loss: 0.041688, acc:  98%] [G loss: 5.406446, adv: 1.014050, recon: 0.149163, id: 0.231952] time: 1:00:20.671616 \n","[Epoch 40/300] [Batch 50/50] [D loss: 0.063446, acc:  94%] [G loss: 5.487614, adv: 1.144463, recon: 0.142704, id: 0.178297] time: 1:01:53.766970 \n","Model weights saved. combined_model\n","[Epoch 41/300] [Batch 50/50] [D loss: 0.030164, acc:  99%] [G loss: 5.295470, adv: 1.074064, recon: 0.139677, id: 0.186577] time: 1:03:27.761674 \n","[Epoch 42/300] [Batch 50/50] [D loss: 0.034489, acc:  99%] [G loss: 5.587366, adv: 1.078242, recon: 0.154088, id: 0.172158] time: 1:04:59.647147 \n","[Epoch 43/300] [Batch 50/50] [D loss: 0.125418, acc:  85%] [G loss: 5.061263, adv: 0.847717, recon: 0.149815, id: 0.177916] time: 1:06:32.458647 \n","[Epoch 44/300] [Batch 50/50] [D loss: 0.090266, acc:  91%] [G loss: 5.078267, adv: 0.896121, recon: 0.146643, id: 0.176060] time: 1:08:05.282498 \n","[Epoch 45/300] [Batch 50/50] [D loss: 0.041271, acc:  97%] [G loss: 5.333896, adv: 1.000966, recon: 0.149699, id: 0.164146] time: 1:09:38.209738 \n","[Epoch 46/300] [Batch 50/50] [D loss: 0.026371, acc:  99%] [G loss: 5.046629, adv: 0.997085, recon: 0.135734, id: 0.170772] time: 1:11:09.748221 \n","[Epoch 47/300] [Batch 50/50] [D loss: 0.048251, acc:  96%] [G loss: 5.521773, adv: 1.012825, recon: 0.155952, id: 0.174164] time: 1:12:43.118287 \n","[Epoch 48/300] [Batch 50/50] [D loss: 0.038212, acc:  98%] [G loss: 5.185412, adv: 1.052421, recon: 0.137533, id: 0.171051] time: 1:14:16.014601 \n","[Epoch 49/300] [Batch 50/50] [D loss: 0.019740, acc:  99%] [G loss: 5.398412, adv: 1.069388, recon: 0.146990, id: 0.167558] time: 1:15:48.571376 \n","[Epoch 50/300] [Batch 50/50] [D loss: 0.036050, acc:  99%] [G loss: 5.206393, adv: 0.959452, recon: 0.146565, id: 0.190758] time: 1:17:20.697250 \n","[Epoch 51/300] [Batch 50/50] [D loss: 0.040649, acc:  98%] [G loss: 5.082432, adv: 1.114625, recon: 0.126986, id: 0.148969] time: 1:18:53.487879 \n","[Epoch 52/300] [Batch 50/50] [D loss: 0.025239, acc:  99%] [G loss: 5.424126, adv: 1.118099, recon: 0.142316, id: 0.163164] time: 1:20:25.717116 \n","[Epoch 53/300] [Batch 50/50] [D loss: 0.024493, acc:  99%] [G loss: 5.412764, adv: 1.005379, recon: 0.152376, id: 0.200683] time: 1:21:57.824245 \n","[Epoch 54/300] [Batch 50/50] [D loss: 0.023684, acc:  99%] [G loss: 5.281910, adv: 1.059600, recon: 0.141220, id: 0.157843] time: 1:23:29.290910 \n","[Epoch 55/300] [Batch 50/50] [D loss: 0.020113, acc:  99%] [G loss: 5.653082, adv: 0.982635, recon: 0.165425, id: 0.191292] time: 1:25:01.673871 \n","[Epoch 56/300] [Batch 50/50] [D loss: 0.022848, acc:  99%] [G loss: 5.386731, adv: 1.066920, recon: 0.145845, id: 0.157087] time: 1:26:33.900564 \n","[Epoch 57/300] [Batch 50/50] [D loss: 0.017530, acc:  99%] [G loss: 5.385674, adv: 1.054274, recon: 0.146839, id: 0.172865] time: 1:28:06.074272 \n","[Epoch 58/300] [Batch 50/50] [D loss: 0.041695, acc:  96%] [G loss: 5.496791, adv: 1.077230, recon: 0.150089, id: 0.151433] time: 1:29:38.604181 \n","[Epoch 59/300] [Batch 50/50] [D loss: 0.039881, acc:  98%] [G loss: 5.370452, adv: 1.008794, recon: 0.150100, id: 0.171251] time: 1:31:09.834631 \n","[Epoch 60/300] [Batch 50/50] [D loss: 0.026914, acc:  99%] [G loss: 5.240360, adv: 1.009608, recon: 0.144369, id: 0.163908] time: 1:32:41.222687 \n","Model weights saved. combined_model\n","[Epoch 61/300] [Batch 50/50] [D loss: 0.019112, acc:  99%] [G loss: 5.333869, adv: 1.128211, recon: 0.135029, id: 0.169144] time: 1:34:14.568204 \n","[Epoch 62/300] [Batch 50/50] [D loss: 0.060541, acc:  94%] [G loss: 5.409110, adv: 1.062131, recon: 0.148409, id: 0.154745] time: 1:35:45.874928 \n","[Epoch 63/300] [Batch 50/50] [D loss: 0.025722, acc:  99%] [G loss: 4.910941, adv: 0.971901, recon: 0.132935, id: 0.145784] time: 1:37:17.511545 \n","[Epoch 64/300] [Batch 50/50] [D loss: 0.020399, acc:  99%] [G loss: 5.454074, adv: 1.102308, recon: 0.145881, id: 0.163739] time: 1:38:50.207250 \n","[Epoch 65/300] [Batch 50/50] [D loss: 0.017045, acc:  99%] [G loss: 5.327959, adv: 1.051348, recon: 0.143377, id: 0.176501] time: 1:40:21.657205 \n","[Epoch 66/300] [Batch 50/50] [D loss: 0.023715, acc:  99%] [G loss: 5.158260, adv: 1.075207, recon: 0.134307, id: 0.163497] time: 1:41:54.296166 \n","[Epoch 67/300] [Batch 50/50] [D loss: 0.016133, acc:  99%] [G loss: 5.158655, adv: 1.063319, recon: 0.135584, id: 0.145902] time: 1:43:27.306955 \n","[Epoch 68/300] [Batch 50/50] [D loss: 0.014050, acc:  99%] [G loss: 5.167516, adv: 1.022154, recon: 0.139238, id: 0.160379] time: 1:44:59.180600 \n","[Epoch 69/300] [Batch 50/50] [D loss: 0.082594, acc:  90%] [G loss: 5.744184, adv: 1.425111, recon: 0.129355, id: 0.164267] time: 1:46:31.512612 \n","[Epoch 70/300] [Batch 50/50] [D loss: 0.034240, acc:  98%] [G loss: 5.399806, adv: 1.034406, recon: 0.149172, id: 0.164962] time: 1:48:02.919081 \n","[Epoch 71/300] [Batch 50/50] [D loss: 0.022869, acc:  99%] [G loss: 5.116696, adv: 1.079869, recon: 0.132015, id: 0.146766] time: 1:49:34.786478 \n","[Epoch 72/300] [Batch 50/50] [D loss: 0.023102, acc:  99%] [G loss: 5.535043, adv: 1.024093, recon: 0.155859, id: 0.176867] time: 1:51:07.538624 \n","[Epoch 73/300] [Batch 50/50] [D loss: 0.022809, acc:  99%] [G loss: 5.397133, adv: 1.097668, recon: 0.143759, id: 0.158890] time: 1:52:38.982953 \n","[Epoch 74/300] [Batch 50/50] [D loss: 0.030596, acc:  99%] [G loss: 5.056237, adv: 1.048673, recon: 0.132049, id: 0.160986] time: 1:54:10.994453 \n","[Epoch 75/300] [Batch 50/50] [D loss: 0.028195, acc:  98%] [G loss: 5.382110, adv: 1.150791, recon: 0.138071, id: 0.173956] time: 1:55:43.848696 \n","[Epoch 76/300] [Batch 50/50] [D loss: 0.043917, acc:  98%] [G loss: 5.477287, adv: 1.141691, recon: 0.144797, id: 0.140457] time: 1:57:15.899411 \n","[Epoch 77/300] [Batch 50/50] [D loss: 0.016677, acc:  99%] [G loss: 5.155450, adv: 1.046744, recon: 0.137966, id: 0.150203] time: 1:58:48.218268 \n","[Epoch 78/300] [Batch 50/50] [D loss: 0.023255, acc:  98%] [G loss: 5.544162, adv: 1.127239, recon: 0.147127, id: 0.161579] time: 2:00:19.534548 \n","[Epoch 79/300] [Batch 50/50] [D loss: 0.028991, acc:  99%] [G loss: 5.147689, adv: 1.034341, recon: 0.137711, id: 0.152148] time: 2:01:51.542274 \n","[Epoch 80/300] [Batch 50/50] [D loss: 0.012623, acc:  99%] [G loss: 4.981071, adv: 0.992535, recon: 0.133530, id: 0.168747] time: 2:03:24.186545 \n","Model weights saved. combined_model\n","[Epoch 81/300] [Batch 50/50] [D loss: 0.019721, acc:  99%] [G loss: 4.970108, adv: 1.050874, recon: 0.128327, id: 0.138205] time: 2:04:58.269256 \n","[Epoch 82/300] [Batch 50/50] [D loss: 0.049226, acc:  95%] [G loss: 5.368116, adv: 1.175663, recon: 0.134799, id: 0.178148] time: 2:06:30.956949 \n","[Epoch 83/300] [Batch 50/50] [D loss: 0.014515, acc:  99%] [G loss: 5.332999, adv: 1.052686, recon: 0.146054, id: 0.138326] time: 2:08:03.026015 \n","[Epoch 84/300] [Batch 50/50] [D loss: 0.028340, acc:  96%] [G loss: 4.712881, adv: 0.940637, recon: 0.126175, id: 0.157142] time: 2:09:35.838100 \n","[Epoch 85/300] [Batch 50/50] [D loss: 0.026823, acc:  99%] [G loss: 5.210067, adv: 1.042178, recon: 0.140761, id: 0.141620] time: 2:11:07.872414 \n","[Epoch 86/300] [Batch 50/50] [D loss: 0.033278, acc:  99%] [G loss: 5.107076, adv: 1.088263, recon: 0.129866, id: 0.170489] time: 2:12:39.374464 \n","[Epoch 87/300] [Batch 50/50] [D loss: 0.169354, acc:  73%] [G loss: 4.991644, adv: 0.796132, recon: 0.150488, id: 0.194766] time: 2:14:11.710846 \n","[Epoch 88/300] [Batch 50/50] [D loss: 0.136953, acc:  77%] [G loss: 4.101493, adv: 0.695112, recon: 0.119876, id: 0.134983] time: 2:15:43.203196 \n","[Epoch 89/300] [Batch 50/50] [D loss: 0.131209, acc:  78%] [G loss: 4.262438, adv: 0.700446, recon: 0.127695, id: 0.161547] time: 2:17:15.712134 \n","[Epoch 90/300] [Batch 50/50] [D loss: 0.125136, acc:  80%] [G loss: 4.198775, adv: 0.696851, recon: 0.125814, id: 0.139875] time: 2:18:47.661221 \n","[Epoch 91/300] [Batch 50/50] [D loss: 0.153635, acc:  75%] [G loss: 4.344530, adv: 0.868896, recon: 0.116336, id: 0.130492] time: 2:20:19.590411 \n","[Epoch 92/300] [Batch 50/50] [D loss: 0.244626, acc:  56%] [G loss: 3.368837, adv: 0.329635, recon: 0.119837, id: 0.151571] time: 2:21:51.664132 \n","[Epoch 93/300] [Batch 50/50] [D loss: 0.218423, acc:  62%] [G loss: 3.490345, adv: 0.381207, recon: 0.120564, id: 0.158643] time: 2:23:23.227716 \n","[Epoch 94/300] [Batch 50/50] [D loss: 0.224906, acc:  60%] [G loss: 3.405919, adv: 0.324256, recon: 0.122131, id: 0.149472] time: 2:24:56.844270 \n","[Epoch 95/300] [Batch 50/50] [D loss: 0.202416, acc:  70%] [G loss: 3.313055, adv: 0.409237, recon: 0.109233, id: 0.144115] time: 2:26:29.059567 \n","[Epoch 96/300] [Batch 50/50] [D loss: 0.187020, acc:  72%] [G loss: 3.479769, adv: 0.470077, recon: 0.112378, id: 0.133236] time: 2:28:01.119588 \n","[Epoch 97/300] [Batch 50/50] [D loss: 0.227589, acc:  65%] [G loss: 3.450524, adv: 0.462984, recon: 0.110669, id: 0.141967] time: 2:29:34.121873 \n","[Epoch 98/300] [Batch 50/50] [D loss: 0.174776, acc:  75%] [G loss: 3.817243, adv: 0.534320, recon: 0.121897, id: 0.139801] time: 2:31:06.212987 \n","[Epoch 99/300] [Batch 50/50] [D loss: 0.160579, acc:  79%] [G loss: 4.012442, adv: 0.572607, recon: 0.128977, id: 0.142905] time: 2:32:39.230883 \n","[Epoch 100/300] [Batch 50/50] [D loss: 0.179203, acc:  72%] [G loss: 4.715340, adv: 0.617716, recon: 0.157428, id: 0.170389] time: 2:34:12.137754 \n","Model weights saved. combined_model\n","[Epoch 101/300] [Batch 50/50] [D loss: 0.115690, acc:  86%] [G loss: 4.203219, adv: 0.776335, recon: 0.116523, id: 0.150377] time: 2:35:47.385205 \n","[Epoch 102/300] [Batch 50/50] [D loss: 0.100701, acc:  91%] [G loss: 4.355224, adv: 0.836027, recon: 0.119694, id: 0.144785] time: 2:37:19.364033 \n","[Epoch 103/300] [Batch 50/50] [D loss: 0.100877, acc:  89%] [G loss: 4.645782, adv: 0.777365, recon: 0.138230, id: 0.157616] time: 2:38:51.344500 \n","[Epoch 104/300] [Batch 50/50] [D loss: 0.118521, acc:  85%] [G loss: 4.474981, adv: 0.792593, recon: 0.128103, id: 0.141605] time: 2:40:22.829282 \n","[Epoch 105/300] [Batch 50/50] [D loss: 0.113087, acc:  85%] [G loss: 4.393633, adv: 0.773889, recon: 0.125870, id: 0.163070] time: 2:41:55.092419 \n","[Epoch 106/300] [Batch 50/50] [D loss: 0.099207, acc:  89%] [G loss: 5.040165, adv: 0.850225, recon: 0.150800, id: 0.158347] time: 2:43:27.837263 \n","[Epoch 107/300] [Batch 50/50] [D loss: 0.084664, acc:  89%] [G loss: 5.084803, adv: 0.940392, recon: 0.144378, id: 0.166546] time: 2:44:59.954554 \n","[Epoch 108/300] [Batch 50/50] [D loss: 0.066294, acc:  95%] [G loss: 5.056082, adv: 0.869027, recon: 0.149377, id: 0.173364] time: 2:46:32.264335 \n","[Epoch 109/300] [Batch 50/50] [D loss: 0.036206, acc:  98%] [G loss: 4.871869, adv: 0.937334, recon: 0.134487, id: 0.158028] time: 2:48:04.962754 \n","[Epoch 110/300] [Batch 50/50] [D loss: 0.039858, acc:  98%] [G loss: 5.504760, adv: 0.999906, recon: 0.159140, id: 0.171208] time: 2:49:36.482010 \n","[Epoch 111/300] [Batch 50/50] [D loss: 0.061180, acc:  94%] [G loss: 5.130877, adv: 1.034667, recon: 0.137459, id: 0.142620] time: 2:51:07.931143 \n","[Epoch 112/300] [Batch 50/50] [D loss: 0.046119, acc:  97%] [G loss: 4.726760, adv: 0.933022, recon: 0.127852, id: 0.145314] time: 2:52:40.096988 \n","[Epoch 113/300] [Batch 50/50] [D loss: 0.066382, acc:  95%] [G loss: 4.993560, adv: 1.052892, recon: 0.127529, id: 0.157401] time: 2:54:12.372687 \n","[Epoch 114/300] [Batch 50/50] [D loss: 0.071845, acc:  92%] [G loss: 5.120170, adv: 1.009433, recon: 0.138347, id: 0.166729] time: 2:55:45.339724 \n","[Epoch 115/300] [Batch 50/50] [D loss: 0.051662, acc:  96%] [G loss: 5.178148, adv: 1.138464, recon: 0.128787, id: 0.165644] time: 2:57:17.492024 \n","[Epoch 116/300] [Batch 50/50] [D loss: 0.091600, acc:  90%] [G loss: 5.258372, adv: 1.099079, recon: 0.136890, id: 0.159747] time: 2:58:48.962386 \n","[Epoch 117/300] [Batch 50/50] [D loss: 0.041355, acc:  97%] [G loss: 5.070800, adv: 1.025802, recon: 0.134978, id: 0.141807] time: 3:00:21.206027 \n","[Epoch 118/300] [Batch 50/50] [D loss: 0.026486, acc:  98%] [G loss: 5.454839, adv: 1.012431, recon: 0.154146, id: 0.175978] time: 3:01:53.982167 \n","[Epoch 119/300] [Batch 50/50] [D loss: 0.013779, acc:  99%] [G loss: 5.306933, adv: 1.066119, recon: 0.142583, id: 0.165673] time: 3:03:26.266099 \n","[Epoch 120/300] [Batch 50/50] [D loss: 0.037398, acc:  98%] [G loss: 5.329413, adv: 1.102113, recon: 0.141136, id: 0.151714] time: 3:04:58.981090 \n","Model weights saved. combined_model\n","[Epoch 121/300] [Batch 50/50] [D loss: 0.035225, acc:  97%] [G loss: 5.195006, adv: 1.023272, recon: 0.140767, id: 0.167431] time: 3:06:33.036801 \n","[Epoch 122/300] [Batch 50/50] [D loss: 0.019149, acc:  99%] [G loss: 5.555133, adv: 1.032282, recon: 0.158301, id: 0.160643] time: 3:08:04.663690 \n","[Epoch 123/300] [Batch 50/50] [D loss: 0.034192, acc:  99%] [G loss: 4.926009, adv: 1.006437, recon: 0.129818, id: 0.162362] time: 3:09:36.979612 \n","[Epoch 124/300] [Batch 50/50] [D loss: 0.027491, acc:  98%] [G loss: 4.973589, adv: 1.018775, recon: 0.129430, id: 0.187860] time: 3:11:09.706906 \n","[Epoch 125/300] [Batch 50/50] [D loss: 0.014813, acc:  99%] [G loss: 5.025823, adv: 1.066806, recon: 0.129043, id: 0.152001] time: 3:12:41.248957 \n","[Epoch 126/300] [Batch 50/50] [D loss: 0.029324, acc:  98%] [G loss: 4.822497, adv: 0.991421, recon: 0.126632, id: 0.149822] time: 3:14:13.816983 \n","[Epoch 127/300] [Batch 50/50] [D loss: 0.031057, acc:  98%] [G loss: 5.214352, adv: 1.041576, recon: 0.140651, id: 0.147151] time: 3:15:45.875270 \n","[Epoch 128/300] [Batch 50/50] [D loss: 0.092975, acc:  88%] [G loss: 4.980465, adv: 1.007280, recon: 0.131926, id: 0.161005] time: 3:17:19.149201 \n","[Epoch 129/300] [Batch 50/50] [D loss: 0.012200, acc: 100%] [G loss: 5.057785, adv: 1.021840, recon: 0.134789, id: 0.148975] time: 3:18:51.169328 \n","[Epoch 130/300] [Batch 50/50] [D loss: 0.015840, acc:  99%] [G loss: 5.027998, adv: 1.028019, recon: 0.132392, id: 0.160569] time: 3:20:24.213744 \n","[Epoch 131/300] [Batch 50/50] [D loss: 0.012260, acc:  99%] [G loss: 4.853798, adv: 1.009673, recon: 0.126510, id: 0.165365] time: 3:21:56.448717 \n","[Epoch 132/300] [Batch 50/50] [D loss: 0.019162, acc:  99%] [G loss: 5.075726, adv: 1.057947, recon: 0.132056, id: 0.156547] time: 3:23:29.722486 \n","[Epoch 133/300] [Batch 50/50] [D loss: 0.016972, acc:  99%] [G loss: 5.193290, adv: 1.065676, recon: 0.135755, id: 0.184441] time: 3:25:02.659234 \n","[Epoch 134/300] [Batch 50/50] [D loss: 0.019406, acc:  99%] [G loss: 5.754329, adv: 1.102451, recon: 0.160031, id: 0.142562] time: 3:26:34.830793 \n","[Epoch 135/300] [Batch 50/50] [D loss: 0.017360, acc:  99%] [G loss: 5.253170, adv: 1.059478, recon: 0.140369, id: 0.137397] time: 3:28:07.802989 \n","[Epoch 136/300] [Batch 50/50] [D loss: 0.009304, acc: 100%] [G loss: 5.423260, adv: 1.024099, recon: 0.151026, id: 0.173027] time: 3:29:40.926601 \n","[Epoch 137/300] [Batch 50/50] [D loss: 0.017402, acc:  99%] [G loss: 5.151148, adv: 1.004773, recon: 0.140181, id: 0.163777] time: 3:31:12.473331 \n","[Epoch 138/300] [Batch 50/50] [D loss: 0.141430, acc:  75%] [G loss: 3.996880, adv: 0.695488, recon: 0.116061, id: 0.135739] time: 3:32:44.895845 \n","[Epoch 139/300] [Batch 50/50] [D loss: 0.137806, acc:  75%] [G loss: 4.008998, adv: 0.669638, recon: 0.118267, id: 0.164524] time: 3:34:16.287688 \n","[Epoch 140/300] [Batch 50/50] [D loss: 0.117151, acc:  82%] [G loss: 4.049908, adv: 0.725374, recon: 0.115841, id: 0.134714] time: 3:35:48.590370 \n","Model weights saved. combined_model\n","[Epoch 141/300] [Batch 50/50] [D loss: 0.125327, acc:  79%] [G loss: 4.518222, adv: 0.751608, recon: 0.134510, id: 0.150444] time: 3:37:22.998551 \n","[Epoch 142/300] [Batch 50/50] [D loss: 0.094831, acc:  86%] [G loss: 4.569780, adv: 0.889767, recon: 0.123585, id: 0.147477] time: 3:38:56.230891 \n","[Epoch 143/300] [Batch 50/50] [D loss: 0.053524, acc:  94%] [G loss: 4.973193, adv: 0.972778, recon: 0.134009, id: 0.158020] time: 3:40:28.228673 \n","[Epoch 144/300] [Batch 50/50] [D loss: 0.046546, acc:  94%] [G loss: 4.966284, adv: 0.962326, recon: 0.136727, id: 0.145981] time: 3:42:00.485081 \n","[Epoch 145/300] [Batch 50/50] [D loss: 0.017460, acc:  99%] [G loss: 4.802230, adv: 0.996149, recon: 0.124939, id: 0.141108] time: 3:43:32.748096 \n","[Epoch 146/300] [Batch 50/50] [D loss: 0.037841, acc:  96%] [G loss: 4.826219, adv: 1.028779, recon: 0.123548, id: 0.129748] time: 3:45:04.625415 \n","[Epoch 147/300] [Batch 50/50] [D loss: 0.019415, acc:  99%] [G loss: 5.050770, adv: 0.960303, recon: 0.141039, id: 0.169963] time: 3:46:37.496078 \n","[Epoch 148/300] [Batch 50/50] [D loss: 0.016713, acc:  99%] [G loss: 5.250658, adv: 1.057412, recon: 0.140080, id: 0.169787] time: 3:48:09.334650 \n","[Epoch 149/300] [Batch 50/50] [D loss: 0.033604, acc:  98%] [G loss: 4.614706, adv: 0.978884, recon: 0.116904, id: 0.145282] time: 3:49:41.949604 \n","[Epoch 150/300] [Batch 50/50] [D loss: 0.016718, acc:  99%] [G loss: 5.041890, adv: 0.984669, recon: 0.137077, id: 0.180141] time: 3:51:15.184069 \n","[Epoch 151/300] [Batch 50/50] [D loss: 0.014209, acc:  99%] [G loss: 4.900055, adv: 0.998186, recon: 0.128306, id: 0.160501] time: 3:52:46.456854 \n","[Epoch 152/300] [Batch 50/50] [D loss: 0.027693, acc:  99%] [G loss: 4.918123, adv: 1.125572, recon: 0.118174, id: 0.148223] time: 3:54:17.697810 \n","[Epoch 153/300] [Batch 50/50] [D loss: 0.046815, acc:  96%] [G loss: 4.815065, adv: 1.045762, recon: 0.122036, id: 0.155031] time: 3:55:48.923872 \n","[Epoch 154/300] [Batch 50/50] [D loss: 0.011533, acc: 100%] [G loss: 4.796256, adv: 1.002055, recon: 0.124428, id: 0.156920] time: 3:57:20.981815 \n","[Epoch 155/300] [Batch 50/50] [D loss: 0.017644, acc:  99%] [G loss: 5.210363, adv: 1.071595, recon: 0.138239, id: 0.145264] time: 3:58:52.195855 \n","[Epoch 156/300] [Batch 50/50] [D loss: 0.009752, acc:  99%] [G loss: 6.041134, adv: 1.020591, recon: 0.181034, id: 0.211703] time: 4:00:24.963455 \n","[Epoch 157/300] [Batch 50/50] [D loss: 0.007597, acc: 100%] [G loss: 5.310215, adv: 0.995192, recon: 0.149394, id: 0.182785] time: 4:01:56.116818 \n","[Epoch 158/300] [Batch 50/50] [D loss: 0.010037, acc:  99%] [G loss: 4.944882, adv: 0.994442, recon: 0.131322, id: 0.165985] time: 4:03:27.822261 \n","[Epoch 159/300] [Batch 50/50] [D loss: 0.007161, acc: 100%] [G loss: 4.977244, adv: 1.019312, recon: 0.130311, id: 0.190612] time: 4:04:59.618411 \n","[Epoch 160/300] [Batch 50/50] [D loss: 0.011348, acc:  99%] [G loss: 5.267755, adv: 1.003428, recon: 0.145294, id: 0.180227] time: 4:06:31.285766 \n","Model weights saved. combined_model\n","[Epoch 161/300] [Batch 50/50] [D loss: 0.008021, acc: 100%] [G loss: 4.833003, adv: 0.999961, recon: 0.126028, id: 0.165332] time: 4:08:05.902963 \n","[Epoch 162/300] [Batch 50/50] [D loss: 0.011509, acc: 100%] [G loss: 5.247141, adv: 1.008517, recon: 0.145197, id: 0.147972] time: 4:09:37.210282 \n","[Epoch 163/300] [Batch 50/50] [D loss: 0.006761, acc: 100%] [G loss: 4.526675, adv: 0.998110, recon: 0.111271, id: 0.168315] time: 4:11:10.633146 \n","[Epoch 164/300] [Batch 50/50] [D loss: 0.054057, acc:  96%] [G loss: 5.193001, adv: 1.146548, recon: 0.129729, id: 0.146345] time: 4:12:42.947492 \n","[Epoch 165/300] [Batch 50/50] [D loss: 0.013737, acc:  99%] [G loss: 4.545848, adv: 0.975368, recon: 0.115252, id: 0.150960] time: 4:14:15.456826 \n","[Epoch 166/300] [Batch 50/50] [D loss: 0.008353, acc: 100%] [G loss: 4.710172, adv: 1.026093, recon: 0.116614, id: 0.168661] time: 4:15:47.312302 \n","[Epoch 167/300] [Batch 50/50] [D loss: 0.112847, acc:  83%] [G loss: 4.327911, adv: 0.749554, recon: 0.125612, id: 0.160038] time: 4:17:19.132098 \n","[Epoch 168/300] [Batch 50/50] [D loss: 0.116085, acc:  82%] [G loss: 4.067414, adv: 0.685898, recon: 0.119799, id: 0.141100] time: 4:18:50.797947 \n","[Epoch 169/300] [Batch 50/50] [D loss: 0.120627, acc:  81%] [G loss: 3.971255, adv: 0.706130, recon: 0.112621, id: 0.157970] time: 4:20:23.382203 \n","[Epoch 170/300] [Batch 50/50] [D loss: 0.247964, acc:  57%] [G loss: 3.457513, adv: 0.372504, recon: 0.117923, id: 0.187874] time: 4:21:55.563442 \n","[Epoch 171/300] [Batch 50/50] [D loss: 0.179885, acc:  73%] [G loss: 3.478159, adv: 0.524808, recon: 0.108403, id: 0.135560] time: 4:23:27.274910 \n","[Epoch 172/300] [Batch 50/50] [D loss: 0.149081, acc:  81%] [G loss: 4.019767, adv: 0.685473, recon: 0.116621, id: 0.155750] time: 4:25:00.407248 \n","[Epoch 173/300] [Batch 50/50] [D loss: 0.052721, acc:  93%] [G loss: 4.450467, adv: 0.926412, recon: 0.115393, id: 0.141619] time: 4:26:33.416169 \n","[Epoch 174/300] [Batch 50/50] [D loss: 0.060241, acc:  94%] [G loss: 4.602684, adv: 0.917285, recon: 0.122393, id: 0.156770] time: 4:28:05.489473 \n","[Epoch 175/300] [Batch 50/50] [D loss: 0.026868, acc:  99%] [G loss: 4.873166, adv: 0.968278, recon: 0.130783, id: 0.175013] time: 4:29:37.615254 \n","[Epoch 176/300] [Batch 50/50] [D loss: 0.038618, acc:  98%] [G loss: 4.769356, adv: 0.906000, recon: 0.133600, id: 0.149658] time: 4:31:09.748124 \n","[Epoch 177/300] [Batch 50/50] [D loss: 0.019030, acc:  99%] [G loss: 4.886268, adv: 0.966623, recon: 0.131547, id: 0.160781] time: 4:32:43.275603 \n","[Epoch 178/300] [Batch 50/50] [D loss: 0.017673, acc:  99%] [G loss: 5.240554, adv: 0.981989, recon: 0.145616, id: 0.197132] time: 4:34:16.878848 \n","[Epoch 179/300] [Batch 50/50] [D loss: 0.009589, acc: 100%] [G loss: 5.086765, adv: 1.013296, recon: 0.136229, id: 0.157256] time: 4:35:48.477171 \n","[Epoch 180/300] [Batch 50/50] [D loss: 0.013728, acc:  99%] [G loss: 4.955013, adv: 1.001150, recon: 0.132503, id: 0.155183] time: 4:37:21.772939 \n","Model weights saved. combined_model\n","[Epoch 181/300] [Batch 50/50] [D loss: 0.013671, acc:  99%] [G loss: 4.744858, adv: 1.060202, recon: 0.116138, id: 0.166610] time: 4:38:56.422813 \n","[Epoch 182/300] [Batch 50/50] [D loss: 0.014245, acc:  99%] [G loss: 4.989208, adv: 1.002667, recon: 0.133200, id: 0.163663] time: 4:40:28.695665 \n","[Epoch 183/300] [Batch 50/50] [D loss: 0.011810, acc:  99%] [G loss: 5.024610, adv: 0.998051, recon: 0.135264, id: 0.160163] time: 4:42:00.805967 \n","[Epoch 184/300] [Batch 50/50] [D loss: 0.018342, acc:  99%] [G loss: 4.852479, adv: 1.014413, recon: 0.125381, id: 0.153369] time: 4:43:32.561738 \n","[Epoch 185/300] [Batch 50/50] [D loss: 0.010959, acc:  99%] [G loss: 4.638277, adv: 0.986835, recon: 0.117341, id: 0.161891] time: 4:45:04.935648 \n","[Epoch 186/300] [Batch 50/50] [D loss: 0.007589, acc: 100%] [G loss: 4.721866, adv: 0.996196, recon: 0.122021, id: 0.149922] time: 4:46:36.530471 \n","[Epoch 187/300] [Batch 50/50] [D loss: 0.008418, acc: 100%] [G loss: 5.047053, adv: 1.028185, recon: 0.133587, id: 0.156912] time: 4:48:09.082355 \n","[Epoch 188/300] [Batch 50/50] [D loss: 0.014256, acc:  99%] [G loss: 4.807445, adv: 1.053570, recon: 0.119474, id: 0.174147] time: 4:49:41.098107 \n","[Epoch 189/300] [Batch 50/50] [D loss: 0.008945, acc: 100%] [G loss: 4.720879, adv: 1.028920, recon: 0.117968, id: 0.150493] time: 4:51:13.678150 \n","[Epoch 190/300] [Batch 50/50] [D loss: 0.024620, acc:  99%] [G loss: 4.977502, adv: 1.081351, recon: 0.124458, id: 0.165225] time: 4:52:46.076388 \n","[Epoch 191/300] [Batch 50/50] [D loss: 0.008945, acc: 100%] [G loss: 4.756165, adv: 1.048065, recon: 0.118238, id: 0.155504] time: 4:54:20.168431 \n","[Epoch 192/300] [Batch 50/50] [D loss: 0.011502, acc:  99%] [G loss: 4.791754, adv: 1.025985, recon: 0.122545, id: 0.142827] time: 4:55:52.982077 \n","[Epoch 193/300] [Batch 50/50] [D loss: 0.014280, acc:  99%] [G loss: 4.846436, adv: 1.020219, recon: 0.123202, id: 0.148761] time: 4:57:26.311309 \n","[Epoch 194/300] [Batch 50/50] [D loss: 0.008736, acc: 100%] [G loss: 4.850258, adv: 1.042634, recon: 0.121231, id: 0.174229] time: 4:58:58.230501 \n","[Epoch 195/300] [Batch 50/50] [D loss: 0.006319, acc: 100%] [G loss: 4.418179, adv: 0.996724, recon: 0.106313, id: 0.157521] time: 5:00:30.830721 \n","[Epoch 196/300] [Batch 50/50] [D loss: 0.010268, acc: 100%] [G loss: 4.596589, adv: 1.002742, recon: 0.115574, id: 0.129560] time: 5:02:03.897516 \n","[Epoch 197/300] [Batch 50/50] [D loss: 0.010642, acc:  99%] [G loss: 4.822031, adv: 1.003665, recon: 0.125096, id: 0.150203] time: 5:03:36.713325 \n","[Epoch 198/300] [Batch 50/50] [D loss: 0.010099, acc:  99%] [G loss: 4.603581, adv: 0.997349, recon: 0.115621, id: 0.147270] time: 5:05:07.845214 \n","[Epoch 199/300] [Batch 50/50] [D loss: 0.008244, acc:  99%] [G loss: 4.939947, adv: 1.019673, recon: 0.129941, id: 0.144840] time: 5:06:40.366230 \n","[Epoch 200/300] [Batch 50/50] [D loss: 0.014210, acc:  99%] [G loss: 4.805836, adv: 0.982147, recon: 0.127630, id: 0.146214] time: 5:08:11.939819 \n","Model weights saved. combined_model\n","[Epoch 201/300] [Batch 50/50] [D loss: 0.009349, acc:  99%] [G loss: 4.611559, adv: 0.986450, recon: 0.118199, id: 0.142470] time: 5:09:46.082630 \n","[Epoch 202/300] [Batch 50/50] [D loss: 0.006325, acc: 100%] [G loss: 4.443273, adv: 1.005134, recon: 0.107228, id: 0.141598] time: 5:11:17.800289 \n","[Epoch 203/300] [Batch 50/50] [D loss: 0.007935, acc: 100%] [G loss: 4.603757, adv: 1.032473, recon: 0.112160, id: 0.136469] time: 5:12:49.560691 \n","[Epoch 204/300] [Batch 50/50] [D loss: 0.021383, acc:  99%] [G loss: 4.968867, adv: 1.115221, recon: 0.120367, id: 0.167645] time: 5:14:22.807270 \n","[Epoch 205/300] [Batch 50/50] [D loss: 0.004949, acc: 100%] [G loss: 4.667387, adv: 1.006351, recon: 0.117839, id: 0.153961] time: 5:15:55.134369 \n","[Epoch 206/300] [Batch 50/50] [D loss: 0.007378, acc: 100%] [G loss: 4.554597, adv: 1.042972, recon: 0.109374, id: 0.151959] time: 5:17:27.800688 \n","[Epoch 207/300] [Batch 50/50] [D loss: 0.099064, acc:  86%] [G loss: 4.233098, adv: 0.814300, recon: 0.115822, id: 0.134243] time: 5:18:59.909196 \n","[Epoch 208/300] [Batch 50/50] [D loss: 0.019116, acc:  99%] [G loss: 4.537500, adv: 1.004862, recon: 0.112369, id: 0.131895] time: 5:20:32.099453 \n","[Epoch 209/300] [Batch 50/50] [D loss: 0.019360, acc:  99%] [G loss: 4.717225, adv: 1.003419, recon: 0.119398, id: 0.169873] time: 5:22:04.364781 \n","[Epoch 210/300] [Batch 50/50] [D loss: 0.013416, acc:  99%] [G loss: 4.487165, adv: 0.998765, recon: 0.109324, id: 0.157313] time: 5:23:37.209343 \n","[Epoch 211/300] [Batch 50/50] [D loss: 0.023855, acc:  99%] [G loss: 4.679846, adv: 1.032843, recon: 0.114824, id: 0.159634] time: 5:25:08.675302 \n","[Epoch 212/300] [Batch 50/50] [D loss: 0.007191, acc:  99%] [G loss: 4.526243, adv: 1.018180, recon: 0.111362, id: 0.133323] time: 5:26:41.600260 \n","[Epoch 213/300] [Batch 50/50] [D loss: 0.006695, acc: 100%] [G loss: 4.772103, adv: 1.013501, recon: 0.121039, id: 0.153303] time: 5:28:13.099221 \n","[Epoch 214/300] [Batch 50/50] [D loss: 0.007735, acc:  99%] [G loss: 4.571406, adv: 1.019754, recon: 0.112202, id: 0.141658] time: 5:29:46.457138 \n","[Epoch 215/300] [Batch 50/50] [D loss: 0.005854, acc: 100%] [G loss: 4.493471, adv: 1.008606, recon: 0.108732, id: 0.141001] time: 5:31:18.805173 \n","[Epoch 216/300] [Batch 50/50] [D loss: 0.024756, acc:  98%] [G loss: 4.655411, adv: 1.035150, recon: 0.114665, id: 0.135192] time: 5:32:50.660794 \n","[Epoch 217/300] [Batch 50/50] [D loss: 0.008227, acc: 100%] [G loss: 4.751994, adv: 1.059307, recon: 0.116837, id: 0.141818] time: 5:34:22.388714 \n","[Epoch 218/300] [Batch 50/50] [D loss: 0.006327, acc: 100%] [G loss: 4.398939, adv: 1.049050, recon: 0.101912, id: 0.134273] time: 5:35:54.408936 \n","[Epoch 219/300] [Batch 50/50] [D loss: 0.028152, acc:  98%] [G loss: 4.338534, adv: 1.034858, recon: 0.099950, id: 0.137121] time: 5:37:26.805793 \n","[Epoch 220/300] [Batch 50/50] [D loss: 0.006544, acc: 100%] [G loss: 4.415334, adv: 1.002016, recon: 0.107339, id: 0.132698] time: 5:38:59.443915 \n","Model weights saved. combined_model\n","[Epoch 221/300] [Batch 50/50] [D loss: 0.004826, acc: 100%] [G loss: 4.462732, adv: 1.043926, recon: 0.104483, id: 0.140463] time: 5:40:33.122927 \n","[Epoch 222/300] [Batch 50/50] [D loss: 0.004899, acc: 100%] [G loss: 4.372295, adv: 0.992685, recon: 0.105081, id: 0.132599] time: 5:42:04.575965 \n","[Epoch 223/300] [Batch 50/50] [D loss: 0.006316, acc:  99%] [G loss: 4.290656, adv: 1.016560, recon: 0.099884, id: 0.128955] time: 5:43:35.974841 \n","[Epoch 224/300] [Batch 50/50] [D loss: 0.167281, acc:  73%] [G loss: 3.674072, adv: 0.656819, recon: 0.104462, id: 0.132327] time: 5:45:07.466734 \n","[Epoch 225/300] [Batch 50/50] [D loss: 0.133178, acc:  76%] [G loss: 3.970923, adv: 0.677809, recon: 0.115454, id: 0.150924] time: 5:46:39.799425 \n","[Epoch 226/300] [Batch 50/50] [D loss: 0.124857, acc:  78%] [G loss: 3.784570, adv: 0.691183, recon: 0.105219, id: 0.133608] time: 5:48:12.672350 \n","[Epoch 227/300] [Batch 50/50] [D loss: 0.089416, acc:  88%] [G loss: 3.965088, adv: 0.780370, recon: 0.105687, id: 0.152120] time: 5:49:44.414967 \n","[Epoch 228/300] [Batch 50/50] [D loss: 0.073985, acc:  90%] [G loss: 3.976231, adv: 0.783065, recon: 0.106580, id: 0.140398] time: 5:51:15.821210 \n","[Epoch 229/300] [Batch 50/50] [D loss: 0.037315, acc:  97%] [G loss: 4.379621, adv: 0.943767, recon: 0.110450, id: 0.144656] time: 5:52:48.183531 \n","[Epoch 230/300] [Batch 50/50] [D loss: 0.026033, acc:  99%] [G loss: 4.407198, adv: 1.014022, recon: 0.104785, id: 0.132733] time: 5:54:20.690260 \n","[Epoch 231/300] [Batch 50/50] [D loss: 0.185814, acc:  73%] [G loss: 4.874947, adv: 1.086445, recon: 0.118895, id: 0.174402] time: 5:55:52.163713 \n","[Epoch 232/300] [Batch 50/50] [D loss: 0.031800, acc:  98%] [G loss: 4.407553, adv: 0.978763, recon: 0.107791, id: 0.138982] time: 5:57:23.922117 \n","[Epoch 233/300] [Batch 50/50] [D loss: 0.012311, acc:  99%] [G loss: 4.690041, adv: 1.012185, recon: 0.118768, id: 0.133563] time: 5:58:56.158649 \n","[Epoch 234/300] [Batch 50/50] [D loss: 0.012222, acc:  99%] [G loss: 4.367702, adv: 0.975521, recon: 0.105940, id: 0.146290] time: 6:00:28.472166 \n","[Epoch 235/300] [Batch 50/50] [D loss: 0.009382, acc: 100%] [G loss: 4.669803, adv: 1.045567, recon: 0.114944, id: 0.133514] time: 6:01:59.735268 \n","[Epoch 236/300] [Batch 50/50] [D loss: 0.014295, acc:  99%] [G loss: 4.429197, adv: 1.010293, recon: 0.105850, id: 0.137212] time: 6:03:31.072518 \n","[Epoch 237/300] [Batch 50/50] [D loss: 0.018341, acc:  99%] [G loss: 4.392725, adv: 1.011325, recon: 0.105130, id: 0.141737] time: 6:05:07.361247 \n","[Epoch 238/300] [Batch 50/50] [D loss: 0.017560, acc:  99%] [G loss: 4.364247, adv: 0.956648, recon: 0.108513, id: 0.142534] time: 6:06:40.752246 \n","[Epoch 239/300] [Batch 50/50] [D loss: 0.018123, acc:  99%] [G loss: 4.698117, adv: 1.051834, recon: 0.115854, id: 0.146694] time: 6:08:13.040896 \n","[Epoch 240/300] [Batch 50/50] [D loss: 0.009181, acc: 100%] [G loss: 4.863401, adv: 1.028655, recon: 0.125477, id: 0.140211] time: 6:09:45.352080 \n","Model weights saved. combined_model\n","[Epoch 241/300] [Batch 50/50] [D loss: 0.005035, acc: 100%] [G loss: 4.739581, adv: 1.002852, recon: 0.121249, id: 0.139431] time: 6:11:19.919388 \n","[Epoch 242/300] [Batch 50/50] [D loss: 0.007091, acc: 100%] [G loss: 5.011867, adv: 1.009835, recon: 0.132357, id: 0.177874] time: 6:12:52.358258 \n","[Epoch 243/300] [Batch 50/50] [D loss: 0.007732, acc:  99%] [G loss: 4.708320, adv: 1.019474, recon: 0.117999, id: 0.154668] time: 6:14:25.131012 \n","[Epoch 244/300] [Batch 50/50] [D loss: 0.006475, acc: 100%] [G loss: 4.627228, adv: 0.995487, recon: 0.117591, id: 0.143136] time: 6:15:57.309971 \n","[Epoch 245/300] [Batch 50/50] [D loss: 0.006651, acc: 100%] [G loss: 4.627742, adv: 0.999431, recon: 0.116357, id: 0.148368] time: 6:17:30.437436 \n","[Epoch 246/300] [Batch 50/50] [D loss: 0.005804, acc: 100%] [G loss: 4.565071, adv: 0.999812, recon: 0.113080, id: 0.141440] time: 6:19:03.683725 \n","[Epoch 247/300] [Batch 50/50] [D loss: 0.006918, acc: 100%] [G loss: 4.397473, adv: 1.048304, recon: 0.102737, id: 0.122374] time: 6:20:35.976704 \n","[Epoch 248/300] [Batch 50/50] [D loss: 0.009388, acc: 100%] [G loss: 4.607384, adv: 0.977019, recon: 0.117301, id: 0.144676] time: 6:22:09.060554 \n","[Epoch 249/300] [Batch 50/50] [D loss: 0.005571, acc: 100%] [G loss: 4.754476, adv: 1.038921, recon: 0.118669, id: 0.145593] time: 6:23:41.413985 \n","[Epoch 250/300] [Batch 50/50] [D loss: 0.007632, acc: 100%] [G loss: 4.360829, adv: 1.009362, recon: 0.103986, id: 0.122622] time: 6:25:13.266265 \n","[Epoch 251/300] [Batch 50/50] [D loss: 0.005249, acc: 100%] [G loss: 4.866298, adv: 1.034088, recon: 0.125128, id: 0.135968] time: 6:26:45.129790 \n","[Epoch 252/300] [Batch 50/50] [D loss: 0.004981, acc: 100%] [G loss: 4.403128, adv: 0.982778, recon: 0.106811, id: 0.139090] time: 6:28:16.799980 \n","[Epoch 253/300] [Batch 50/50] [D loss: 0.004775, acc: 100%] [G loss: 5.165933, adv: 1.015977, recon: 0.141378, id: 0.130815] time: 6:29:51.661273 \n","[Epoch 254/300] [Batch 50/50] [D loss: 0.004546, acc: 100%] [G loss: 4.440485, adv: 1.017850, recon: 0.105580, id: 0.139611] time: 6:31:23.294346 \n","[Epoch 255/300] [Batch 50/50] [D loss: 0.004524, acc: 100%] [G loss: 4.275428, adv: 1.011677, recon: 0.098439, id: 0.140895] time: 6:32:56.850121 \n","[Epoch 256/300] [Batch 50/50] [D loss: 0.005578, acc:  99%] [G loss: 4.544712, adv: 0.984811, recon: 0.113739, id: 0.134160] time: 6:34:29.209867 \n","[Epoch 257/300] [Batch 50/50] [D loss: 0.003688, acc: 100%] [G loss: 4.456974, adv: 0.992484, recon: 0.108708, id: 0.123726] time: 6:36:01.544339 \n","[Epoch 258/300] [Batch 50/50] [D loss: 0.003169, acc: 100%] [G loss: 4.460362, adv: 1.006878, recon: 0.107611, id: 0.127559] time: 6:37:33.396585 \n","[Epoch 259/300] [Batch 50/50] [D loss: 0.004040, acc:  99%] [G loss: 4.443681, adv: 1.040396, recon: 0.102659, id: 0.143146] time: 6:39:06.750300 \n","[Epoch 260/300] [Batch 50/50] [D loss: 0.008485, acc:  99%] [G loss: 4.192200, adv: 1.037496, recon: 0.093116, id: 0.127395] time: 6:40:39.550016 \n","Model weights saved. combined_model\n","[Epoch 261/300] [Batch 50/50] [D loss: 0.004487, acc: 100%] [G loss: 4.330184, adv: 1.004152, recon: 0.100899, id: 0.124031] time: 6:42:17.871120 \n","[Epoch 262/300] [Batch 50/50] [D loss: 0.111003, acc:  83%] [G loss: 3.873294, adv: 0.683423, recon: 0.111705, id: 0.122627] time: 6:43:50.419264 \n","[Epoch 263/300] [Batch 50/50] [D loss: 0.060947, acc:  93%] [G loss: 4.049508, adv: 0.850796, recon: 0.102673, id: 0.129713] time: 6:45:22.800507 \n","[Epoch 264/300] [Batch 50/50] [D loss: 0.028482, acc:  97%] [G loss: 4.292801, adv: 0.945534, recon: 0.106440, id: 0.128270] time: 6:46:54.537654 \n","[Epoch 265/300] [Batch 50/50] [D loss: 0.012473, acc: 100%] [G loss: 4.376719, adv: 1.005497, recon: 0.104696, id: 0.125880] time: 6:48:26.319125 \n","[Epoch 266/300] [Batch 50/50] [D loss: 0.048600, acc:  96%] [G loss: 4.323105, adv: 0.996403, recon: 0.101542, id: 0.140771] time: 6:49:58.799598 \n","[Epoch 267/300] [Batch 50/50] [D loss: 0.048430, acc:  96%] [G loss: 4.317022, adv: 0.988468, recon: 0.102419, id: 0.122372] time: 6:51:30.936905 \n","[Epoch 268/300] [Batch 50/50] [D loss: 0.007226, acc: 100%] [G loss: 4.464489, adv: 1.013921, recon: 0.108109, id: 0.126988] time: 6:53:03.377975 \n","[Epoch 269/300] [Batch 50/50] [D loss: 0.009256, acc:  99%] [G loss: 4.591255, adv: 1.040849, recon: 0.111781, id: 0.126169] time: 6:54:35.029549 \n","[Epoch 270/300] [Batch 50/50] [D loss: 0.029613, acc:  96%] [G loss: 4.326541, adv: 0.934927, recon: 0.108610, id: 0.136390] time: 6:56:07.459864 \n","[Epoch 271/300] [Batch 50/50] [D loss: 0.033948, acc:  96%] [G loss: 4.392098, adv: 0.951433, recon: 0.110424, id: 0.129791] time: 6:57:41.289673 \n","[Epoch 272/300] [Batch 50/50] [D loss: 0.009096, acc: 100%] [G loss: 4.660404, adv: 1.015957, recon: 0.116167, id: 0.144565] time: 6:59:14.012930 \n","[Epoch 273/300] [Batch 50/50] [D loss: 0.006224, acc: 100%] [G loss: 4.579635, adv: 1.018516, recon: 0.113039, id: 0.131241] time: 7:00:46.125027 \n","[Epoch 274/300] [Batch 50/50] [D loss: 0.011623, acc:  99%] [G loss: 4.677565, adv: 1.012454, recon: 0.118597, id: 0.137144] time: 7:02:18.264780 \n","[Epoch 275/300] [Batch 50/50] [D loss: 0.005315, acc: 100%] [G loss: 4.609293, adv: 1.019578, recon: 0.115283, id: 0.124919] time: 7:03:52.134103 \n","[Epoch 276/300] [Batch 50/50] [D loss: 0.009261, acc:  99%] [G loss: 4.700491, adv: 1.101187, recon: 0.110035, id: 0.146269] time: 7:05:25.493201 \n","[Epoch 277/300] [Batch 50/50] [D loss: 0.010641, acc: 100%] [G loss: 4.541612, adv: 1.036265, recon: 0.108912, id: 0.119202] time: 7:06:57.135545 \n","[Epoch 278/300] [Batch 50/50] [D loss: 0.023610, acc:  99%] [G loss: 4.627629, adv: 1.093684, recon: 0.107516, id: 0.131471] time: 7:08:30.760063 \n","[Epoch 279/300] [Batch 50/50] [D loss: 0.007040, acc:  99%] [G loss: 4.475123, adv: 1.002222, recon: 0.110619, id: 0.117139] time: 7:10:02.241606 \n","[Epoch 280/300] [Batch 50/50] [D loss: 0.005462, acc: 100%] [G loss: 4.425785, adv: 1.035919, recon: 0.103639, id: 0.134879] time: 7:11:36.097630 \n","Model weights saved. combined_model\n","[Epoch 281/300] [Batch 50/50] [D loss: 0.003249, acc: 100%] [G loss: 4.277486, adv: 0.991050, recon: 0.100930, id: 0.135125] time: 7:13:10.519416 \n","[Epoch 282/300] [Batch 50/50] [D loss: 0.006933, acc: 100%] [G loss: 4.741789, adv: 1.014571, recon: 0.121883, id: 0.130787] time: 7:14:43.727864 \n","[Epoch 283/300] [Batch 50/50] [D loss: 0.050140, acc:  94%] [G loss: 4.542357, adv: 1.039260, recon: 0.108747, id: 0.150711] time: 7:16:15.423291 \n","[Epoch 284/300] [Batch 50/50] [D loss: 0.027300, acc:  99%] [G loss: 4.559645, adv: 1.026377, recon: 0.112086, id: 0.115431] time: 7:17:47.697239 \n","[Epoch 285/300] [Batch 50/50] [D loss: 0.007368, acc:  99%] [G loss: 5.026687, adv: 1.008279, recon: 0.133655, id: 0.167133] time: 7:19:19.537711 \n","[Epoch 286/300] [Batch 50/50] [D loss: 0.003547, acc: 100%] [G loss: 4.603010, adv: 1.028278, recon: 0.112469, id: 0.138107] time: 7:20:53.216686 \n","[Epoch 287/300] [Batch 50/50] [D loss: 0.002442, acc: 100%] [G loss: 4.295950, adv: 1.014639, recon: 0.098929, id: 0.127066] time: 7:22:25.755916 \n","[Epoch 288/300] [Batch 50/50] [D loss: 0.007553, acc:  99%] [G loss: 4.424643, adv: 0.997268, recon: 0.108205, id: 0.124923] time: 7:23:57.267066 \n","[Epoch 289/300] [Batch 50/50] [D loss: 0.003159, acc: 100%] [G loss: 4.172663, adv: 0.990465, recon: 0.095464, id: 0.125301] time: 7:25:29.499679 \n","[Epoch 290/300] [Batch 50/50] [D loss: 0.003692, acc: 100%] [G loss: 4.351691, adv: 1.018934, recon: 0.101967, id: 0.121208] time: 7:27:00.865748 \n","[Epoch 291/300] [Batch 50/50] [D loss: 0.004231, acc:  99%] [G loss: 4.148767, adv: 0.993253, recon: 0.095168, id: 0.120027] time: 7:28:33.059528 \n","[Epoch 292/300] [Batch 50/50] [D loss: 0.003551, acc: 100%] [G loss: 4.068270, adv: 1.008068, recon: 0.090488, id: 0.113838] time: 7:30:05.753718 \n","[Epoch 293/300] [Batch 50/50] [D loss: 0.006030, acc:  99%] [G loss: 4.113225, adv: 0.992759, recon: 0.092384, id: 0.122065] time: 7:31:38.224586 \n","[Epoch 294/300] [Batch 50/50] [D loss: 0.004880, acc: 100%] [G loss: 4.408678, adv: 1.016643, recon: 0.104988, id: 0.126672] time: 7:33:09.499944 \n","[Epoch 295/300] [Batch 50/50] [D loss: 0.004667, acc: 100%] [G loss: 4.205160, adv: 1.013040, recon: 0.095969, id: 0.131946] time: 7:34:41.665534 \n","[Epoch 296/300] [Batch 50/50] [D loss: 0.069830, acc:  91%] [G loss: 4.085061, adv: 0.880940, recon: 0.101392, id: 0.146164] time: 7:36:13.471165 \n","[Epoch 297/300] [Batch 50/50] [D loss: 0.003698, acc: 100%] [G loss: 4.427163, adv: 1.025857, recon: 0.105186, id: 0.135897] time: 7:37:46.335282 \n","[Epoch 298/300] [Batch 50/50] [D loss: 0.002033, acc: 100%] [G loss: 4.218627, adv: 0.989186, recon: 0.098102, id: 0.122030] time: 7:39:18.155372 \n","[Epoch 299/300] [Batch 50/50] [D loss: 0.005135, acc: 100%] [G loss: 4.376041, adv: 1.012426, recon: 0.102734, id: 0.127157] time: 7:40:49.321231 \n","[Epoch 300/300] [Batch 50/50] [D loss: 0.002166, acc: 100%] [G loss: 4.259141, adv: 0.995641, recon: 0.100943, id: 0.114173] time: 7:42:21.566471 \n","Model weights saved. combined_model\n","2020-08-16T16:40:09.188960 End\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"iXhGHg5TfSmz","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}